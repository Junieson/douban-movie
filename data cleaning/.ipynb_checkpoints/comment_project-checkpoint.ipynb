{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amazing-beijing",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 数据读取和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "peaceful-compression",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba   # 分词包\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyecharts.charts import Bar,Grid,Line,Pie\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.globals import ThemeType\n",
    "from pyecharts.commons.utils import JsCode\n",
    "from wordcloud import WordCloud # 词云包\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prepared-bristol",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movies_b = pd.read_csv(\"movies_piaofang.csv\")\n",
    "movies_m = pd.read_csv(\"movies_pingfen.csv\")\n",
    "movies = pd.concat([movies_b,movies_m]).drop_duplicates(subset=\"movie_id\").reset_index(drop=True)\n",
    "movies['movie_id'] = movies['movie_id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "naked-teddy",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 导入、分词、去停用词\n",
    "def lcut(Intro_movie):\n",
    "    segment=[]\n",
    "    segs = jieba.lcut(Intro_movie) # 将一段话分成词语列表\n",
    "    for seg in segs:# 单个子的去除\n",
    "        if len(seg)>1 and seg!='\\r\\n':\n",
    "            segment.append(seg)\n",
    "    return segment\n",
    "\n",
    "stopwords = pd.read_csv(\"stopwords.txt\" \n",
    "                  ,index_col=False\n",
    "                  ,quoting=3\n",
    "                  ,sep=\"\\t\"\n",
    "                  ,names=['stopword']\n",
    "                  ,encoding='utf-8') # quoting=3 全不引用    \n",
    "\n",
    "def dropstopword(segment):\n",
    "    # 去停用词,停用词是指在信息检索中，为节省存储空间和提高搜索效率，在处理自然语言数据（或文本）之前或之后会自动过滤掉某些字或词，这些字或词即被称为Stop Words（停用词）\n",
    "    words_df = pd.DataFrame({'segment':segment})\n",
    "\n",
    "    #stopwords.head()\n",
    "    return words_df[~words_df.segment.isin(stopwords.stopword)].segment.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-transition",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disabled-florida",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # 基于TextRank算法的关键词抽取(仅动词和动名词)\n",
    "import jieba.analyse as analyse\n",
    "\n",
    "# movies_b['keywords'] = movies_b.intro.apply(lcut)\\\n",
    "#                 .apply(dropstopword)\\\n",
    "#                 .apply(lambda x : \" \".join(x))\\\n",
    "#                 .apply(lambda x:\" \".join(analyse.textrank(x, topK=8, withWeight=False, allowPOS=('n','vn', 'v','a','z'))))\n",
    "# movies_b.sort_values('rating_num', ascending=False)[['movie_title','keywords']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "formed-alias",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\11514\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.811 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>灭霸 复仇者 队长 宇宙 无限 响指 冰释 找到</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>阿凡达 Avatar</td>\n",
       "      <td>最佳 部落 人类基因 西格 视觉效果 混血 电影史 砍伐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>泰坦尼克号 Titanic</td>\n",
       "      <td>处女航 温丝 头等舱 投海 未婚夫 船票 驶往 救起</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>星球大战7：原力觉醒 Star Wars: The Force Awakens</td>\n",
       "      <td>军团 秩序 地图 天行者 死星 星者 原力 蛮荒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>复仇者联盟3：无限战争 Avengers: Infinity War</td>\n",
       "      <td>灭霸 星爵 落入 阻止 蜘蛛侠 遭遇 外星 幻视</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>侏罗纪世界 Jurassic World</td>\n",
       "      <td>暴虐 游客 吸引 生物 速度 骗过 惨剧 精密仪器</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>狮子王 The Lion King</td>\n",
       "      <td>配音 木法 刀疤 王位 迎来 肉中刺 奋进 国度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>复仇者联盟 The Avengers</td>\n",
       "      <td>地球 复仇者 鹰眼 发威 抵挡 指挥官 侵袭 致命</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>速度与激情7 Furious 7</td>\n",
       "      <td>复仇 探长 对决 世外桃源 死对头 干掉 利刃 王牌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>冰雪奇缘2 Frozen II</td>\n",
       "      <td>配音 公主 魔法 吟唱 征途 旅程 丧生 追寻</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie_title                      keywords\n",
       "0            复仇者联盟4：终局之战 Avengers: Endgame      灭霸 复仇者 队长 宇宙 无限 响指 冰释 找到\n",
       "1                               阿凡达 Avatar  最佳 部落 人类基因 西格 视觉效果 混血 电影史 砍伐\n",
       "2                            泰坦尼克号 Titanic    处女航 温丝 头等舱 投海 未婚夫 船票 驶往 救起\n",
       "3  星球大战7：原力觉醒 Star Wars: The Force Awakens      军团 秩序 地图 天行者 死星 星者 原力 蛮荒\n",
       "4       复仇者联盟3：无限战争 Avengers: Infinity War      灭霸 星爵 落入 阻止 蜘蛛侠 遭遇 外星 幻视\n",
       "5                     侏罗纪世界 Jurassic World     暴虐 游客 吸引 生物 速度 骗过 惨剧 精密仪器\n",
       "6                        狮子王 The Lion King      配音 木法 刀疤 王位 迎来 肉中刺 奋进 国度\n",
       "7                       复仇者联盟 The Avengers     地球 复仇者 鹰眼 发威 抵挡 指挥官 侵袭 致命\n",
       "8                         速度与激情7 Furious 7    复仇 探长 对决 世外桃源 死对头 干掉 利刃 王牌\n",
       "9                          冰雪奇缘2 Frozen II       配音 公主 魔法 吟唱 征途 旅程 丧生 追寻"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_b['keywords'] = movies_b.intro.apply(lcut)\\\n",
    "                .apply(dropstopword)\\\n",
    "                .apply(lambda x : \" \".join(x))\\\n",
    "                .apply(lambda x:\" \".join(analyse.extract_tags(x, topK=8, withWeight=False, allowPOS=('n' ,'v','z'))))\n",
    "movies_b.sort_values('box_office', ascending=False)[['movie_title','keywords']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "global-mileage",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>灭霸 复仇者 队长 宇宙 无限 响指 冰释 找到</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>阿凡达 Avatar</td>\n",
       "      <td>最佳 部落 人类基因 西格 视觉效果 混血 电影史 砍伐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>泰坦尼克号 Titanic</td>\n",
       "      <td>处女航 温丝 头等舱 投海 未婚夫 船票 驶往 救起</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>星球大战7：原力觉醒 Star Wars: The Force Awakens</td>\n",
       "      <td>军团 秩序 地图 天行者 死星 星者 原力 蛮荒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>复仇者联盟3：无限战争 Avengers: Infinity War</td>\n",
       "      <td>灭霸 星爵 落入 阻止 蜘蛛侠 遭遇 外星 幻视</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>侏罗纪世界 Jurassic World</td>\n",
       "      <td>暴虐 游客 吸引 生物 速度 骗过 惨剧 精密仪器</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>狮子王 The Lion King</td>\n",
       "      <td>配音 木法 刀疤 王位 迎来 肉中刺 奋进 国度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>复仇者联盟 The Avengers</td>\n",
       "      <td>地球 复仇者 鹰眼 发威 抵挡 指挥官 侵袭 致命</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>速度与激情7 Furious 7</td>\n",
       "      <td>复仇 探长 对决 世外桃源 死对头 干掉 利刃 王牌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>冰雪奇缘2 Frozen II</td>\n",
       "      <td>配音 公主 魔法 吟唱 征途 旅程 丧生 追寻</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie_title                      keywords\n",
       "0            复仇者联盟4：终局之战 Avengers: Endgame      灭霸 复仇者 队长 宇宙 无限 响指 冰释 找到\n",
       "1                               阿凡达 Avatar  最佳 部落 人类基因 西格 视觉效果 混血 电影史 砍伐\n",
       "2                            泰坦尼克号 Titanic    处女航 温丝 头等舱 投海 未婚夫 船票 驶往 救起\n",
       "3  星球大战7：原力觉醒 Star Wars: The Force Awakens      军团 秩序 地图 天行者 死星 星者 原力 蛮荒\n",
       "4       复仇者联盟3：无限战争 Avengers: Infinity War      灭霸 星爵 落入 阻止 蜘蛛侠 遭遇 外星 幻视\n",
       "5                     侏罗纪世界 Jurassic World     暴虐 游客 吸引 生物 速度 骗过 惨剧 精密仪器\n",
       "6                        狮子王 The Lion King      配音 木法 刀疤 王位 迎来 肉中刺 奋进 国度\n",
       "7                       复仇者联盟 The Avengers     地球 复仇者 鹰眼 发威 抵挡 指挥官 侵袭 致命\n",
       "8                         速度与激情7 Furious 7    复仇 探长 对决 世外桃源 死对头 干掉 利刃 王牌\n",
       "9                          冰雪奇缘2 Frozen II       配音 公主 魔法 吟唱 征途 旅程 丧生 追寻"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_b['keywords'] = movies_b.intro.apply(lcut)\\\n",
    "                .apply(dropstopword)\\\n",
    "                .apply(lambda x : \" \".join(x))\\\n",
    "                .apply(lambda x:\" \".join(analyse.extract_tags(x, topK=8, withWeight=False, allowPOS=('n' ,'v','z'))))\n",
    "movies_b.sort_values('box_office', ascending=False)[['movie_title','keywords']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beneficial-composer",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eb9f892080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keywords= movies_b.intro.apply(lcut)\\\n",
    "                .apply(dropstopword)\\\n",
    "                .apply(lambda x : \" \".join(x))\\\n",
    "                .apply(lambda x: (analyse.extract_tags(x, topK=50, withWeight=True)))\n",
    "word_fre  = {x:y for x, y in keywords[0]}\n",
    "cloud = WordCloud(\n",
    " # 设置字体，不指定就会出现乱码\n",
    " font_path=\"simhei.ttf\", #这个路径是pc中的字体路径\n",
    " # 设置背景色\n",
    " background_color='white',\n",
    "mode=\"RGBA\",\n",
    "    scale  =5,\n",
    " # 允许最大词汇\n",
    " max_words=200,\n",
    " # 最大号字体\n",
    " max_font_size=40\n",
    ")\n",
    "wc = cloud.fit_words(word_fre)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "functioning-error",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_json(\"../data/top_office/movie_comment20.json\", lines=True,encoding='utf-8')\n",
    "data2 = pd.read_json(\"../data/top_office/movie_comment40.json\", lines=True,encoding='utf-8')\n",
    "data3 = pd.read_json(\"../data/top_office/movie_comment60.json\", lines=True,encoding='utf-8')\n",
    "data4 = pd.read_json(\"../data/top_office/movie_comment80.json\", lines=True,encoding='utf-8')\n",
    "data5 = pd.read_json(\"../data/top_office/movie_comment110.json\", lines=True,encoding='utf-8')\n",
    "data6 = pd.read_json(\"../data/top_office/movie_comment140.json\", lines=True,encoding='utf-8')\n",
    "data7 = pd.read_json(\"../data/top_office/movie_comment170.json\", lines=True,encoding='utf-8')\n",
    "data8 = pd.read_json(\"../data/top_office/movie_comment200.json\", lines=True,encoding='utf-8')\n",
    "data9 = pd.read_json(\"../data/top_office/movie_comment230.json\", lines=True,encoding='utf-8')\n",
    "data10 = pd.read_json(\"../data/top_office/movie_comment250.json\", lines=True,encoding='utf-8')\n",
    "datas = [data1,data2,data3,data4,data5,data6,data7,data8,data9,data10]\n",
    "comm1 = pd.concat(datas).drop_duplicates(subset=\"comment_id\").reset_index(drop=True)\n",
    "file = ['../data/top_mark/movie_comment%s.json' %j for j in [ i for i in range(20,220,20)] +[225,250]]\n",
    "datas = []\n",
    "for sr in file:\n",
    "    datas.append(pd.read_json(sr, lines=True,encoding='utf-8'))\n",
    "comm2 = pd.concat(datas).drop_duplicates(subset=\"comment_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "super-generator",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kingfish'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm2.people[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sunrise-arthur",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comm2['movie_id'] = comm2['movie_id'].apply(lambda x: int(x[0][5:]))\n",
    "comm2['content'] = comm2.content.apply(lambda x: x[0].strip())\n",
    "# comm2['people'] = comm2.people.apply(lambda x: x.strip())\n",
    "# 用url中的名称替代\n",
    "comm2['people'] = comm2.people_url.apply(lambda x: x[30:-1])\n",
    "comm2['useful_num'] = comm2.useful_num.apply(lambda x: int(x))\n",
    "def regular_nonstar(x):\n",
    "    if x == 'comment-time':\n",
    "        return 'allstar00 rating'\n",
    "    else:\n",
    "        return x\n",
    "comm2['star'] = comm2.star.apply(regular_nonstar).apply(lambda x: int(x[7]))\n",
    "comm2['time'] = pd.to_datetime(comm2.time.apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "square-klein",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>URL</th>\n",
       "      <th>star</th>\n",
       "      <th>content</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>people</th>\n",
       "      <th>useful_num</th>\n",
       "      <th>time</th>\n",
       "      <th>people_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1292052</td>\n",
       "      <td>https://movie.douban.com/subject/1292052/comments</td>\n",
       "      <td>5</td>\n",
       "      <td>不需要女主角的好电影</td>\n",
       "      <td>2050003</td>\n",
       "      <td>kingfish</td>\n",
       "      <td>11314</td>\n",
       "      <td>2006-03-22 12:38:09</td>\n",
       "      <td>https://www.douban.com/people/kingfish/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                                URL  star  \\\n",
       "0   1292052  https://movie.douban.com/subject/1292052/comments     5   \n",
       "\n",
       "      content  comment_id    people  useful_num                time  \\\n",
       "0  不需要女主角的好电影     2050003  kingfish       11314 2006-03-22 12:38:09   \n",
       "\n",
       "                                people_url  \n",
       "0  https://www.douban.com/people/kingfish/  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quarterly-process",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comm1['movie_id'] = comm1['movie_id'].apply(lambda x: int(x))\n",
    "# comm1['content'] = comm1.content.apply(lambda x: \"\".join(x).strip())\n",
    "comm1[\"content\"] = comm1.content.apply(lambda x: \"\".join(x).strip())\n",
    "comm1['people'] = comm1.people_url.apply(lambda x: x[30:-1])\n",
    "comm1['useful_num'] = comm1.useful_num.apply(lambda x: int(x))\n",
    "comm1['star'] = comm1.star.apply(regular_nonstar).apply(lambda x: int(x[7]))\n",
    "comm1['time'] = pd.to_datetime(comm1.time.apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "convinced-disposition",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comm1.head(1)\n",
    "comm = pd.concat([comm1,comm2])\n",
    "comm = comm.drop_duplicates(subset=\"comment_id\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excess-institution",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1292720</th>\n",
       "      <th>阿甘正传 Forrest Gump</th>\n",
       "      <td>1740.0</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.422404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291843</th>\n",
       "      <th>黑客帝国 The Matrix</th>\n",
       "      <td>1666.0</td>\n",
       "      <td>3.751501</td>\n",
       "      <td>1.347029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131459</th>\n",
       "      <th>机器人总动员 WALL·E</th>\n",
       "      <td>1665.0</td>\n",
       "      <td>3.896096</td>\n",
       "      <td>1.301124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301753</th>\n",
       "      <th>狮子王 The Lion King</th>\n",
       "      <td>1660.0</td>\n",
       "      <td>3.718675</td>\n",
       "      <td>1.360251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291552</th>\n",
       "      <th>指环王3：王者无敌 The Lord of the Rings: The Return of the King</th>\n",
       "      <td>1639.0</td>\n",
       "      <td>3.799878</td>\n",
       "      <td>1.367323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541415</th>\n",
       "      <th>盗梦空间 Inception</th>\n",
       "      <td>1639.0</td>\n",
       "      <td>3.716290</td>\n",
       "      <td>1.420475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851857</th>\n",
       "      <th>蝙蝠侠：黑暗骑士 The Dark Knight</th>\n",
       "      <td>1637.0</td>\n",
       "      <td>3.777642</td>\n",
       "      <td>1.329803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292849</th>\n",
       "      <th>拯救大兵瑞恩 Saving Private Ryan</th>\n",
       "      <td>1625.0</td>\n",
       "      <td>3.648615</td>\n",
       "      <td>1.346945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297630</th>\n",
       "      <th>第六感 The Sixth Sense</th>\n",
       "      <td>1624.0</td>\n",
       "      <td>3.717365</td>\n",
       "      <td>1.263564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295038</th>\n",
       "      <th>哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone</th>\n",
       "      <td>1619.0</td>\n",
       "      <td>3.589253</td>\n",
       "      <td>1.252403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291571</th>\n",
       "      <th>指环王1：魔戒再现 The Lord of the Rings: The Fellowship of the Ring</th>\n",
       "      <td>1618.0</td>\n",
       "      <td>3.691595</td>\n",
       "      <td>1.313341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25662329</th>\n",
       "      <th>疯狂动物城 Zootopia</th>\n",
       "      <td>1604.0</td>\n",
       "      <td>3.645885</td>\n",
       "      <td>1.353091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858711</th>\n",
       "      <th>玩具总动员3 Toy Story 3</th>\n",
       "      <td>1602.0</td>\n",
       "      <td>3.833958</td>\n",
       "      <td>1.282134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294638</th>\n",
       "      <th>E.T. 外星人 E.T.: The Extra-Terrestrial</th>\n",
       "      <td>1597.0</td>\n",
       "      <td>3.574828</td>\n",
       "      <td>1.281815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533913</th>\n",
       "      <th>头脑特工队 Inside Out</th>\n",
       "      <td>1595.0</td>\n",
       "      <td>3.645768</td>\n",
       "      <td>1.310334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298070</th>\n",
       "      <th>加勒比海盗 Pirates of the Caribbean: The Curse of the Black Pearl</th>\n",
       "      <td>1588.0</td>\n",
       "      <td>3.627204</td>\n",
       "      <td>1.234176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292722</th>\n",
       "      <th>泰坦尼克号 Titanic</th>\n",
       "      <td>1587.0</td>\n",
       "      <td>3.873346</td>\n",
       "      <td>1.411434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652587</th>\n",
       "      <th>阿凡达 Avatar</th>\n",
       "      <td>1570.0</td>\n",
       "      <td>3.668790</td>\n",
       "      <td>1.344860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353023</th>\n",
       "      <th>驯龙高手 How to Train Your Dragon</th>\n",
       "      <td>1569.0</td>\n",
       "      <td>3.697259</td>\n",
       "      <td>1.263498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929463</th>\n",
       "      <th>少年派的奇幻漂流 Life of Pi</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>3.648787</td>\n",
       "      <td>1.329641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              count      mean  \\\n",
       "movie_id movie_title                                                            \n",
       "1292720  阿甘正传 Forrest Gump                                   1740.0  3.800000   \n",
       "1291843  黑客帝国 The Matrix                                     1666.0  3.751501   \n",
       "2131459  机器人总动员 WALL·E                                       1665.0  3.896096   \n",
       "1301753  狮子王 The Lion King                                   1660.0  3.718675   \n",
       "1291552  指环王3：王者无敌 The Lord of the Rings: The Return of ...  1639.0  3.799878   \n",
       "3541415  盗梦空间 Inception                                      1639.0  3.716290   \n",
       "1851857  蝙蝠侠：黑暗骑士 The Dark Knight                            1637.0  3.777642   \n",
       "1292849  拯救大兵瑞恩 Saving Private Ryan                          1625.0  3.648615   \n",
       "1297630  第六感 The Sixth Sense                                 1624.0  3.717365   \n",
       "1295038  哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone     1619.0  3.589253   \n",
       "1291571  指环王1：魔戒再现 The Lord of the Rings: The Fellowship...  1618.0  3.691595   \n",
       "25662329 疯狂动物城 Zootopia                                      1604.0  3.645885   \n",
       "1858711  玩具总动员3 Toy Story 3                                  1602.0  3.833958   \n",
       "1294638  E.T. 外星人 E.T.: The Extra-Terrestrial                1597.0  3.574828   \n",
       "10533913 头脑特工队 Inside Out                                    1595.0  3.645768   \n",
       "1298070  加勒比海盗 Pirates of the Caribbean: The Curse of th...  1588.0  3.627204   \n",
       "1292722  泰坦尼克号 Titanic                                       1587.0  3.873346   \n",
       "1652587  阿凡达 Avatar                                          1570.0  3.668790   \n",
       "2353023  驯龙高手 How to Train Your Dragon                       1569.0  3.697259   \n",
       "1929463  少年派的奇幻漂流 Life of Pi                                 1566.0  3.648787   \n",
       "\n",
       "                                                                  std  min  \\\n",
       "movie_id movie_title                                                         \n",
       "1292720  阿甘正传 Forrest Gump                                   1.422404  0.0   \n",
       "1291843  黑客帝国 The Matrix                                     1.347029  0.0   \n",
       "2131459  机器人总动员 WALL·E                                       1.301124  0.0   \n",
       "1301753  狮子王 The Lion King                                   1.360251  0.0   \n",
       "1291552  指环王3：王者无敌 The Lord of the Rings: The Return of ...  1.367323  0.0   \n",
       "3541415  盗梦空间 Inception                                      1.420475  0.0   \n",
       "1851857  蝙蝠侠：黑暗骑士 The Dark Knight                            1.329803  0.0   \n",
       "1292849  拯救大兵瑞恩 Saving Private Ryan                          1.346945  0.0   \n",
       "1297630  第六感 The Sixth Sense                                 1.263564  0.0   \n",
       "1295038  哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone     1.252403  0.0   \n",
       "1291571  指环王1：魔戒再现 The Lord of the Rings: The Fellowship...  1.313341  0.0   \n",
       "25662329 疯狂动物城 Zootopia                                      1.353091  0.0   \n",
       "1858711  玩具总动员3 Toy Story 3                                  1.282134  0.0   \n",
       "1294638  E.T. 外星人 E.T.: The Extra-Terrestrial                1.281815  0.0   \n",
       "10533913 头脑特工队 Inside Out                                    1.310334  0.0   \n",
       "1298070  加勒比海盗 Pirates of the Caribbean: The Curse of th...  1.234176  0.0   \n",
       "1292722  泰坦尼克号 Titanic                                       1.411434  0.0   \n",
       "1652587  阿凡达 Avatar                                          1.344860  0.0   \n",
       "2353023  驯龙高手 How to Train Your Dragon                       1.263498  0.0   \n",
       "1929463  少年派的奇幻漂流 Life of Pi                                 1.329641  0.0   \n",
       "\n",
       "                                                             25%  50%  75%  \\\n",
       "movie_id movie_title                                                         \n",
       "1292720  阿甘正传 Forrest Gump                                   3.0  4.0  5.0   \n",
       "1291843  黑客帝国 The Matrix                                     3.0  4.0  5.0   \n",
       "2131459  机器人总动员 WALL·E                                       3.0  4.0  5.0   \n",
       "1301753  狮子王 The Lion King                                   3.0  4.0  5.0   \n",
       "1291552  指环王3：王者无敌 The Lord of the Rings: The Return of ...  3.0  4.0  5.0   \n",
       "3541415  盗梦空间 Inception                                      3.0  4.0  5.0   \n",
       "1851857  蝙蝠侠：黑暗骑士 The Dark Knight                            3.0  4.0  5.0   \n",
       "1292849  拯救大兵瑞恩 Saving Private Ryan                          3.0  4.0  5.0   \n",
       "1297630  第六感 The Sixth Sense                                 3.0  4.0  5.0   \n",
       "1295038  哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone     3.0  4.0  5.0   \n",
       "1291571  指环王1：魔戒再现 The Lord of the Rings: The Fellowship...  3.0  4.0  5.0   \n",
       "25662329 疯狂动物城 Zootopia                                      3.0  4.0  5.0   \n",
       "1858711  玩具总动员3 Toy Story 3                                  3.0  4.0  5.0   \n",
       "1294638  E.T. 外星人 E.T.: The Extra-Terrestrial                3.0  4.0  5.0   \n",
       "10533913 头脑特工队 Inside Out                                    3.0  4.0  5.0   \n",
       "1298070  加勒比海盗 Pirates of the Caribbean: The Curse of th...  3.0  4.0  5.0   \n",
       "1292722  泰坦尼克号 Titanic                                       3.0  5.0  5.0   \n",
       "1652587  阿凡达 Avatar                                          3.0  4.0  5.0   \n",
       "2353023  驯龙高手 How to Train Your Dragon                       3.0  4.0  5.0   \n",
       "1929463  少年派的奇幻漂流 Life of Pi                                 3.0  4.0  5.0   \n",
       "\n",
       "                                                             max  \n",
       "movie_id movie_title                                              \n",
       "1292720  阿甘正传 Forrest Gump                                   5.0  \n",
       "1291843  黑客帝国 The Matrix                                     5.0  \n",
       "2131459  机器人总动员 WALL·E                                       5.0  \n",
       "1301753  狮子王 The Lion King                                   5.0  \n",
       "1291552  指环王3：王者无敌 The Lord of the Rings: The Return of ...  5.0  \n",
       "3541415  盗梦空间 Inception                                      5.0  \n",
       "1851857  蝙蝠侠：黑暗骑士 The Dark Knight                            5.0  \n",
       "1292849  拯救大兵瑞恩 Saving Private Ryan                          5.0  \n",
       "1297630  第六感 The Sixth Sense                                 5.0  \n",
       "1295038  哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone     5.0  \n",
       "1291571  指环王1：魔戒再现 The Lord of the Rings: The Fellowship...  5.0  \n",
       "25662329 疯狂动物城 Zootopia                                      5.0  \n",
       "1858711  玩具总动员3 Toy Story 3                                  5.0  \n",
       "1294638  E.T. 外星人 E.T.: The Extra-Terrestrial                5.0  \n",
       "10533913 头脑特工队 Inside Out                                    5.0  \n",
       "1298070  加勒比海盗 Pirates of the Caribbean: The Curse of th...  5.0  \n",
       "1292722  泰坦尼克号 Titanic                                       5.0  \n",
       "1652587  阿凡达 Avatar                                          5.0  \n",
       "2353023  驯龙高手 How to Train Your Dragon                       5.0  \n",
       "1929463  少年派的奇幻漂流 Life of Pi                                 5.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = movies[[\"movie_id\",\"movie_title\",\"rating_num\"]]\n",
    "comm = pd.merge(comm,temp,on=['movie_id'])\n",
    "comment = comm\n",
    "comment.groupby([\"movie_id\",\"movie_title\"])[\"star\"].describe().sort_values(\"count\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compatible-pride",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>URL</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>useful_num</th>\n",
       "      <th>star</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "      <th>people</th>\n",
       "      <th>people_url</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>rating_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1364011224</td>\n",
       "      <td>37274</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-24 02:23:59</td>\n",
       "      <td>如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的</td>\n",
       "      <td>146803809</td>\n",
       "      <td>https://www.douban.com/people/146803809/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762639519</td>\n",
       "      <td>20741</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-24 00:11:06</td>\n",
       "      <td>我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落幕...</td>\n",
       "      <td>164105540</td>\n",
       "      <td>https://www.douban.com/people/164105540/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762628760</td>\n",
       "      <td>16016</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-24 00:01:17</td>\n",
       "      <td>托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”。...</td>\n",
       "      <td>lingrui1995</td>\n",
       "      <td>https://www.douban.com/people/lingrui1995/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762741840</td>\n",
       "      <td>14352</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-24 03:05:48</td>\n",
       "      <td>钢铁侠成为了美队，美队活成了钢铁侠。</td>\n",
       "      <td>Rafe0323</td>\n",
       "      <td>https://www.douban.com/people/Rafe0323/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762795339</td>\n",
       "      <td>12817</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-24 04:52:12</td>\n",
       "      <td>谁能想到是一只老鼠拯救了地球呢？</td>\n",
       "      <td>karsa</td>\n",
       "      <td>https://www.douban.com/people/karsa/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450917</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>232767186</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-03-24 19:30:51</td>\n",
       "      <td>喜欢里面的奇思妙想，空灵而优美的音乐，因此还把它刻成光盘珍藏了</td>\n",
       "      <td>echozhanglijun</td>\n",
       "      <td>https://www.douban.com/people/echozhanglijun/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450918</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>453274665</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-11-03 16:10:50</td>\n",
       "      <td>忘不了那优美的音乐</td>\n",
       "      <td>ponyoicy</td>\n",
       "      <td>https://www.douban.com/people/ponyoicy/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450919</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>34553643</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008-03-22 10:37:49</td>\n",
       "      <td>看的第一部宫崎骏的作品 之后坚定了我要看全宫崎骏全部作品的决心</td>\n",
       "      <td>1900555</td>\n",
       "      <td>https://www.douban.com/people/1900555/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450920</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>576096444</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-09-03 13:09:16</td>\n",
       "      <td>谁愿陪伴我身旁 找到它的方向...探访天际的家乡 你是我的翅膀.</td>\n",
       "      <td>38355555</td>\n",
       "      <td>https://www.douban.com/people/38355555/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450921</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>279050212</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-08-06 08:45:35</td>\n",
       "      <td>竟然是1986年的片片……膜拜一下</td>\n",
       "      <td>amanda_wong</td>\n",
       "      <td>https://www.douban.com/people/amanda_wong/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450922 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        movie_id                                                URL  \\\n",
       "0       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "1       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "2       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "3       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "4       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "...          ...                                                ...   \n",
       "450917   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "450918   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "450919   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "450920   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "450921   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "\n",
       "        comment_id  useful_num  star                time  \\\n",
       "0       1364011224       37274     5 2019-04-24 02:23:59   \n",
       "1       1762639519       20741     4 2019-04-24 00:11:06   \n",
       "2       1762628760       16016     5 2019-04-24 00:01:17   \n",
       "3       1762741840       14352     5 2019-04-24 03:05:48   \n",
       "4       1762795339       12817     5 2019-04-24 04:52:12   \n",
       "...            ...         ...   ...                 ...   \n",
       "450917   232767186           0     5 2010-03-24 19:30:51   \n",
       "450918   453274665           0     5 2011-11-03 16:10:50   \n",
       "450919    34553643           0     5 2008-03-22 10:37:49   \n",
       "450920   576096444           0     5 2012-09-03 13:09:16   \n",
       "450921   279050212           0     4 2010-08-06 08:45:35   \n",
       "\n",
       "                                                  content          people  \\\n",
       "0                  如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的       146803809   \n",
       "1       我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落幕...       164105540   \n",
       "2       托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”。...     lingrui1995   \n",
       "3                                      钢铁侠成为了美队，美队活成了钢铁侠。        Rafe0323   \n",
       "4                                        谁能想到是一只老鼠拯救了地球呢？           karsa   \n",
       "...                                                   ...             ...   \n",
       "450917                    喜欢里面的奇思妙想，空灵而优美的音乐，因此还把它刻成光盘珍藏了  echozhanglijun   \n",
       "450918                                          忘不了那优美的音乐        ponyoicy   \n",
       "450919                    看的第一部宫崎骏的作品 之后坚定了我要看全宫崎骏全部作品的决心         1900555   \n",
       "450920                   谁愿陪伴我身旁 找到它的方向...探访天际的家乡 你是我的翅膀.        38355555   \n",
       "450921                                  竟然是1986年的片片……膜拜一下     amanda_wong   \n",
       "\n",
       "                                           people_url  \\\n",
       "0            https://www.douban.com/people/146803809/   \n",
       "1            https://www.douban.com/people/164105540/   \n",
       "2          https://www.douban.com/people/lingrui1995/   \n",
       "3             https://www.douban.com/people/Rafe0323/   \n",
       "4                https://www.douban.com/people/karsa/   \n",
       "...                                               ...   \n",
       "450917  https://www.douban.com/people/echozhanglijun/   \n",
       "450918        https://www.douban.com/people/ponyoicy/   \n",
       "450919         https://www.douban.com/people/1900555/   \n",
       "450920        https://www.douban.com/people/38355555/   \n",
       "450921     https://www.douban.com/people/amanda_wong/   \n",
       "\n",
       "                          movie_title  rating_num  \n",
       "0       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "1       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "2       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "3       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "4       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "...                               ...         ...  \n",
       "450917                  天空之城 天空の城ラピュタ         9.0  \n",
       "450918                  天空之城 天空の城ラピュタ         9.0  \n",
       "450919                  天空之城 天空の城ラピュタ         9.0  \n",
       "450920                  天空之城 天空の城ラピュタ         9.0  \n",
       "450921                  天空之城 天空の城ラピュタ         9.0  \n",
       "\n",
       "[450922 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-insight",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 评论合并(运行上面代码生成训练所需的数据)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "religious-yemen",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27119724</td>\n",
       "      <td>小丑 Joker</td>\n",
       "      <td>漫威 制造 大坏蛋 超高 智慧 强大 肉体 技能 无限 宝石 DC 糟糕 人生 年前 制造 ...</td>\n",
       "      <td>84058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26266893</td>\n",
       "      <td>流浪地球</td>\n",
       "      <td>北京 道路 提醒 道路 千万条 第一条 行车 规范 亲人 两行 这句 广播 洗脑 押点 哈哈...</td>\n",
       "      <td>81080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26754233</td>\n",
       "      <td>八佰</td>\n",
       "      <td>王千源 没有碰过 女人 飞机 特别 厉害 电影 结束 全场 静默 仿佛 观众 沉浸 那种 悲...</td>\n",
       "      <td>79871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889243</td>\n",
       "      <td>星际穿越 Interstellar</td>\n",
       "      <td>诺兰 活得够 豆瓣 TOP250 承包 时间 伸缩 折叠 唯独 倒退 鹤发 童颜 呼吸 抵过...</td>\n",
       "      <td>76984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26794435</td>\n",
       "      <td>哪吒之魔童降世</td>\n",
       "      <td>实名 反对 最赞 烂片 评论 这是 人类 逃脱 真香 定律 不值 票钱 快乐 星球 邓超救 ...</td>\n",
       "      <td>73807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1457217</td>\n",
       "      <td>哈利·波特与凤凰社 Harry Potter and the Order of the Ph...</td>\n",
       "      <td>没什么 场面 精彩 特效 政治 斗争 阴谋诡计 幼稚 没边 三徐 看不下去 只好 杀人 游戏...</td>\n",
       "      <td>10236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>1315574</td>\n",
       "      <td>加勒比海盗2：聚魂棺 Pirates of the Caribbean: Dead Man'...</td>\n",
       "      <td>土著 那段 惨爹 哈哈哈 树林 打来打去 一场 欢乐 野人 一段 搞笑 编剧 极尽 所能 这...</td>\n",
       "      <td>7017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2973079</td>\n",
       "      <td>霍比特人3：五军之战 The Hobbit: The Battle of the Five ...</td>\n",
       "      <td>笑点 拉斯 超级玛丽 阿佐格 阿尔弗雷 卷福 那条 死于 甘道夫 女王 公主 片尾 素描 分...</td>\n",
       "      <td>4105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>11606328</td>\n",
       "      <td>霍比特人2：史矛革之战 The Hobbit: The Desolation of Smaug</td>\n",
       "      <td>矮人 食人妖 抓走 矮人 哥不林 抓走 矮人 蜘蛛 抓走 矮人 精灵 抓走 矮人 人类 抓走...</td>\n",
       "      <td>3668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1418192</td>\n",
       "      <td>加勒比海盗3：世界的尽头 Pirates of the Caribbean: At Worl...</td>\n",
       "      <td>难看 发哥 个杯 可爱 一群 海盗 手一松 四星 比前 两部 两部 铺垫 故事 线略 一点 ...</td>\n",
       "      <td>2136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id                                        movie_title  \\\n",
       "0    27119724                                           小丑 Joker   \n",
       "1    26266893                                               流浪地球   \n",
       "2    26754233                                                 八佰   \n",
       "3     1889243                                  星际穿越 Interstellar   \n",
       "4    26794435                                            哪吒之魔童降世   \n",
       "..        ...                                                ...   \n",
       "458   1457217  哈利·波特与凤凰社 Harry Potter and the Order of the Ph...   \n",
       "459   1315574  加勒比海盗2：聚魂棺 Pirates of the Caribbean: Dead Man'...   \n",
       "460   2973079  霍比特人3：五军之战 The Hobbit: The Battle of the Five ...   \n",
       "461  11606328    霍比特人2：史矛革之战 The Hobbit: The Desolation of Smaug   \n",
       "462   1418192  加勒比海盗3：世界的尽头 Pirates of the Caribbean: At Worl...   \n",
       "\n",
       "                                               content  length  \n",
       "0    漫威 制造 大坏蛋 超高 智慧 强大 肉体 技能 无限 宝石 DC 糟糕 人生 年前 制造 ...   84058  \n",
       "1    北京 道路 提醒 道路 千万条 第一条 行车 规范 亲人 两行 这句 广播 洗脑 押点 哈哈...   81080  \n",
       "2    王千源 没有碰过 女人 飞机 特别 厉害 电影 结束 全场 静默 仿佛 观众 沉浸 那种 悲...   79871  \n",
       "3    诺兰 活得够 豆瓣 TOP250 承包 时间 伸缩 折叠 唯独 倒退 鹤发 童颜 呼吸 抵过...   76984  \n",
       "4    实名 反对 最赞 烂片 评论 这是 人类 逃脱 真香 定律 不值 票钱 快乐 星球 邓超救 ...   73807  \n",
       "..                                                 ...     ...  \n",
       "458  没什么 场面 精彩 特效 政治 斗争 阴谋诡计 幼稚 没边 三徐 看不下去 只好 杀人 游戏...   10236  \n",
       "459  土著 那段 惨爹 哈哈哈 树林 打来打去 一场 欢乐 野人 一段 搞笑 编剧 极尽 所能 这...    7017  \n",
       "460  笑点 拉斯 超级玛丽 阿佐格 阿尔弗雷 卷福 那条 死于 甘道夫 女王 公主 片尾 素描 分...    4105  \n",
       "461  矮人 食人妖 抓走 矮人 哥不林 抓走 矮人 蜘蛛 抓走 矮人 精灵 抓走 矮人 人类 抓走...    3668  \n",
       "462  难看 发哥 个杯 可爱 一群 海盗 手一松 四星 比前 两部 两部 铺垫 故事 线略 一点 ...    2136  \n",
       "\n",
       "[463 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ls_str(x):\n",
    "    return \" \".join(x.content.values.tolist())\n",
    "# comment 合并同个电影所有影评\n",
    "comment = comment.groupby([\"movie_id\",\"movie_title\"]).apply(ls_str)\n",
    "comment = comment.reset_index().rename(columns ={0:\"content\"})\n",
    "comment[\"content\"] = comment.content.apply(lcut).apply(dropstopword).apply(lambda x : \" \".join(x))\n",
    "comment[\"length\"] = comment['content'].str.len()\n",
    "comment = comment.sort_values(\"length\",ascending=False).reset_index(drop=True)\n",
    "corpus=comment.content.tolist()\n",
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-nomination",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 关键词提取 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-honduras",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wrapped-favor",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()#该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "transformer=TfidfTransformer()#该类会统计每个词语的tf-idf权值\n",
    "tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "word=vectorizer.get_feature_names()#获取词袋模型中的所有词语\n",
    "weight=tfidf.toarray()#将tf-idf矩阵抽取出来，元素a[i][j]表示j词在i类文本中的tf-idf权重\n",
    "info= {}\n",
    "for j in range(len(word)):\n",
    "    info[word[j]] = weight[1][j]\n",
    "data = pd.DataFrame(pd.Series(info)).reset_index()\n",
    "data.columns = [\"world\",\"tfidf\"]\n",
    "data = data.sort_values(\"tfidf\",ascending = False)\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "breathing-allah",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>科幻</td>\n",
       "      <td>0.350719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>地球</td>\n",
       "      <td>0.310135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>流浪</td>\n",
       "      <td>0.270352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>吴京</td>\n",
       "      <td>0.232492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>中国</td>\n",
       "      <td>0.202006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>电影</td>\n",
       "      <td>0.196852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>木星</td>\n",
       "      <td>0.194055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>特效</td>\n",
       "      <td>0.186893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>科幻电影</td>\n",
       "      <td>0.170765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>刘慈欣</td>\n",
       "      <td>0.155628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  world     tfidf\n",
       "0    科幻  0.350719\n",
       "1    地球  0.310135\n",
       "2    流浪  0.270352\n",
       "3    吴京  0.232492\n",
       "4    中国  0.202006\n",
       "5    电影  0.196852\n",
       "6    木星  0.194055\n",
       "7    特效  0.186893\n",
       "8  科幻电影  0.170765\n",
       "9   刘慈欣  0.155628"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf = data.iloc[:60]\n",
    "data_tfidf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-maple",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## TextTrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceramic-syndicate",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>trank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>地球</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>电影</td>\n",
       "      <td>0.996673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>科幻</td>\n",
       "      <td>0.975426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>中国</td>\n",
       "      <td>0.958317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>流浪</td>\n",
       "      <td>0.489865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>煽情</td>\n",
       "      <td>0.396438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>人物</td>\n",
       "      <td>0.374241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>科幻片</td>\n",
       "      <td>0.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>台词</td>\n",
       "      <td>0.360245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>人类</td>\n",
       "      <td>0.358842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  world     trank\n",
       "0    地球  1.000000\n",
       "1    电影  0.996673\n",
       "2    科幻  0.975426\n",
       "3    中国  0.958317\n",
       "4    流浪  0.489865\n",
       "5    煽情  0.396438\n",
       "6    人物  0.374241\n",
       "7   科幻片  0.369000\n",
       "8    台词  0.360245\n",
       "9    人类  0.358842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = jieba.analyse.textrank(corpus[1], topK=60, withWeight=True)\n",
    "info= {}\n",
    "for item in keywords:\n",
    "    info[item[0]] = item[1]\n",
    "data = pd.DataFrame(pd.Series(info)).reset_index()\n",
    "data.columns = [\"world\",\"trank\"]\n",
    "data_trank = data.sort_values(\"trank\",ascending = False).reset_index(drop = True).iloc[:60]\n",
    "data_trank.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-benefit",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "virtual-texture",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>电影</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>科幻</td>\n",
       "      <td>0.010787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>中国</td>\n",
       "      <td>0.010514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>地球</td>\n",
       "      <td>0.009876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>特效</td>\n",
       "      <td>0.007232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>流浪</td>\n",
       "      <td>0.004923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>煽情</td>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>科幻片</td>\n",
       "      <td>0.004193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>人物</td>\n",
       "      <td>0.004011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>故事</td>\n",
       "      <td>0.003889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  world       lda\n",
       "0    电影  0.011000\n",
       "1    科幻  0.010787\n",
       "2    中国  0.010514\n",
       "3    地球  0.009876\n",
       "4    特效  0.007232\n",
       "5    流浪  0.004923\n",
       "6    煽情  0.004224\n",
       "7   科幻片  0.004193\n",
       "8    人物  0.004011\n",
       "9    故事  0.003889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "import jieba.posseg as jp\n",
    "import jieba\n",
    "\n",
    "def LDA_model(words_list):\n",
    "    # 构造词典\n",
    "    # Dictionary()方法遍历所有的文本，为每个不重复的单词分配一个单独的整数ID，同时收集该单词出现次数以及相关的统计信息\n",
    "    dictionary = corpora.Dictionary(words_list)\n",
    "    # print('打印查看每个单词的id:')\n",
    "    # print(dictionary.token2id)  # 打印查看每个单词的id\n",
    "    # 将dictionary转化为一个词袋\n",
    "    # doc2bow()方法将dictionary转化为一个词袋。得到的结果corpus是一个向量的列表，向量的个数就是文档数。\n",
    "    # 在每个文档向量中都包含一系列元组,元组的形式是（单词 ID，词频）\n",
    "    corpus = [dictionary.doc2bow(words) for words in words_list]\n",
    "    # print('输出每个文档的向量:')\n",
    "    # print(corpus)  # 输出每个文档的向量\n",
    "    # LDA主题模型\n",
    "    # num_topics -- 必须，要生成的主题个数。\n",
    "    # id2word    -- 必须，LdaModel类要求我们之前的dictionary把id都映射成为字符串。\n",
    "    # passes     -- 可选，模型遍历语料库的次数。遍历的次数越多，模型越精确。但是对于非常大的语料库，遍历太多次会花费很长的时间。\n",
    "    lda_model = models.ldamodel.LdaModel(corpus=corpus, num_topics=1, id2word=dictionary, passes=50)\n",
    "    return lda_model\n",
    "\n",
    "# 获取分词后的文本列表\n",
    "words_list =  comm[comm[\"movie_id\"]==26266893].content.apply(lcut).apply(dropstopword).tolist()\n",
    "\n",
    "# 获取训练后的LDA模型\n",
    "lda_model = LDA_model(words_list)\n",
    "# 可以用 print_topic 和 print_topics 方法来查看主题\n",
    "# 打印所有主题，每个主题显示5个词\n",
    "topic_words = lda_model.print_topics(num_topics=1, num_words=60)\n",
    "# print('打印所有主题，每个主题显示5个词:')\n",
    "# print(topic_words)\n",
    "# 输出该主题的的词及其词的权重\n",
    "words_list = lda_model.show_topic(0, 60)\n",
    "info= {}\n",
    "for item in words_list:\n",
    "    info[item[0]] = item[1]\n",
    "data = pd.DataFrame(pd.Series(info)).reset_index()\n",
    "data.columns = [\"world\",\"lda\"]\n",
    "data_lda = data.sort_values(\"lda\",ascending = False).reset_index(drop = True).iloc[:60]\n",
    "data_lda.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-headset",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "friendly-dialogue",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>郭帆</td>\n",
       "      <td>-1757.133688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>联合政府</td>\n",
       "      <td>-1774.407979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>地下城</td>\n",
       "      <td>-1783.770349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>刘慈欣</td>\n",
       "      <td>-1812.050486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>救援队</td>\n",
       "      <td>-1827.208292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>元年</td>\n",
       "      <td>-1869.175104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>朵朵</td>\n",
       "      <td>-1877.624687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>木星</td>\n",
       "      <td>-1912.290113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>可惜</td>\n",
       "      <td>-1937.365457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>至少</td>\n",
       "      <td>-1951.742979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  world          w2v\n",
       "0    郭帆 -1757.133688\n",
       "1  联合政府 -1774.407979\n",
       "2   地下城 -1783.770349\n",
       "3   刘慈欣 -1812.050486\n",
       "4   救援队 -1827.208292\n",
       "5    元年 -1869.175104\n",
       "6    朵朵 -1877.624687\n",
       "7    木星 -1912.290113\n",
       "8    可惜 -1937.365457\n",
       "9    至少 -1951.742979"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sg=1是skip—gram算法，对低频词敏感，默认sg=0为CBOW算法\n",
    "#size是神经网络层数，值太大则会耗内存并使算法计算变慢，一般值取为100到200之间。\n",
    "#window是句子中当前词与目标词之间的最大距离，3表示在目标词前看3-b个词，后面看b个词（b在0-3之间随机）\n",
    "#min_count是对词进行过滤，频率小于min-count的单词则会被忽视，默认值为5。\n",
    "#negative和sample可根据训练结果进行微调，sample表示更高频率的词被随机下采样到所设置的阈值，默认值为1e-3,\n",
    "#negative: 如果>0,则会采用negativesamping，用于设置多少个noise words\n",
    "#hs=1表示层级softmax将会被使用，默认hs=0且negative不为0，则负采样将会被选择使用。\n",
    "import gensim\n",
    "# sentences = comment.content.str.split(\" \").tolist()\n",
    "# model=gensim.models.Word2Vec(sentences,sg=0,size=150,window=3,min_count=2,negative=3,sample=0.001,hs=1,workers=4)\n",
    "# model.save(\"word2vec_modle\")\n",
    "model = gensim.models.Word2Vec.load(\"word2vec_modle\")\n",
    "# 此函数计算某词对于模型中各个词的转移概率p(wk|wi)\n",
    "def predict_proba(oword, iword):\n",
    "    #获取输入词的词向量\n",
    "    iword_vec = model[iword]\n",
    "    #获取保存权重的词的词库\n",
    "    oword = model.wv.vocab[oword]\n",
    "    oword_l = model.trainables.syn1[oword.point].T\n",
    "    dot = np.dot(iword_vec, oword_l)\n",
    "    lprob = -sum(np.logaddexp(0, -dot) + oword.code*dot) \n",
    "    return lprob\n",
    "from collections import Counter\n",
    "def keywords(s):\n",
    "    #抽出s中和与训练的model重叠的词\n",
    "    s = [w for w in s if w in model]\n",
    "    ws = {w:sum([predict_proba(u, w) for u in s]) for w in s}\n",
    "    return Counter(ws).most_common()\n",
    "\n",
    "frequency = pd.DataFrame(comment.content.str.split(\" \")[1])\n",
    "frequency[\"num\"] = 1\n",
    "frequency  = frequency.groupby(0).sum().sort_values(\"num\",ascending=False)\n",
    "sentence = frequency[frequency['num']>15].index.tolist()\n",
    "x = pd.Series(keywords(sentence))\n",
    "# 输出最重要的前60个词\n",
    "words_list = x[:60]\n",
    "info= {}\n",
    "for item in words_list:\n",
    "    info[item[0]] = item[1]\n",
    "data = pd.DataFrame(pd.Series(info)).reset_index()\n",
    "data.columns = [\"world\",\"w2v\"]\n",
    "data_w2v = data.sort_values(\"w2v\",ascending = False).reset_index(drop = True).iloc[:60]\n",
    "data_w2v.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-tractor",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 展示和分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "assumed-moldova",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min', 'echarts-wordcloud':'https://assets.pyecharts.org/assets/echarts-wordcloud.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"a71d091918ac44f8b4c13cdb79b2ebef\" style=\"width:950px; height:900px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts', 'echarts-wordcloud'], function(echarts) {\n",
       "                var chart_a71d091918ac44f8b4c13cdb79b2ebef = echarts.init(\n",
       "                    document.getElementById('a71d091918ac44f8b4c13cdb79b2ebef'), 'white', {renderer: 'canvas'});\n",
       "                var option_a71d091918ac44f8b4c13cdb79b2ebef = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"wordCloud\",\n",
       "            \"name\": \"tfidf\",\n",
       "            \"shape\": \"circle\",\n",
       "            \"rotationRange\": [\n",
       "                -90,\n",
       "                90\n",
       "            ],\n",
       "            \"rotationStep\": 45,\n",
       "            \"girdSize\": 20,\n",
       "            \"sizeRange\": [\n",
       "                10,\n",
       "                60\n",
       "            ],\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\",\n",
       "                    \"value\": 0.3507194627500583,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(124,39,158)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u7403\",\n",
       "                    \"value\": 0.31013455799942974,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(135,104,146)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6d41\\u6d6a\",\n",
       "                    \"value\": 0.2703519449160141,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(67,97,132)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u4eac\",\n",
       "                    \"value\": 0.23249229770419616,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(90,4,43)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e2d\\u56fd\",\n",
       "                    \"value\": 0.2020061692151813,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(117,137,114)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7535\\u5f71\",\n",
       "                    \"value\": 0.19685155963273912,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(10,81,41)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6728\\u661f\",\n",
       "                    \"value\": 0.19405502322709736,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(101,121,51)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7279\\u6548\",\n",
       "                    \"value\": 0.18689344558900603,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(119,4,66)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7535\\u5f71\",\n",
       "                    \"value\": 0.1707651086401221,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(33,12,81)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5218\\u6148\\u6b23\",\n",
       "                    \"value\": 0.15562760840628112,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(75,142,81)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7247\",\n",
       "                    \"value\": 0.14971613408661352,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(116,67,67)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6218\\u72fc\",\n",
       "                    \"value\": 0.114499461218671,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(126,160,84)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5143\\u5e74\",\n",
       "                    \"value\": 0.10860292351113165,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(107,45,57)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\\u7247\",\n",
       "                    \"value\": 0.10807604865685719,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(124,102,2)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u717d\\u60c5\",\n",
       "                    \"value\": 0.10731896674447655,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(146,148,46)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u592a\\u7a7a\",\n",
       "                    \"value\": 0.0983555461287162,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(53,36,21)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u56fd\\u4ea7\",\n",
       "                    \"value\": 0.09572538786997965,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(22,20,155)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u4e0b\\u57ce\",\n",
       "                    \"value\": 0.08830192567832965,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(80,106,57)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7a7a\\u95f4\\u7ad9\",\n",
       "                    \"value\": 0.08624667698982105,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(8,106,2)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6735\\u6735\",\n",
       "                    \"value\": 0.08444032493696497,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(123,154,1)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u661f\\u9645\",\n",
       "                    \"value\": 0.08346138440135242,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(105,7,106)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u539f\\u8457\",\n",
       "                    \"value\": 0.0800637041127792,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(119,102,136)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7c7b\",\n",
       "                    \"value\": 0.07950612730164099,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(82,86,143)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u90ed\\u5e06\",\n",
       "                    \"value\": 0.07733824580447071,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(1,58,135)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5c34\\u5c2c\",\n",
       "                    \"value\": 0.07640110328391096,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(134,64,58)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53f0\\u8bcd\",\n",
       "                    \"value\": 0.07516978081561924,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(115,29,89)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7269\",\n",
       "                    \"value\": 0.07251954317269492,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(47,100,160)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u9f13\\u52b1\",\n",
       "                    \"value\": 0.06966416132571909,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(27,103,118)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6545\\u4e8b\",\n",
       "                    \"value\": 0.06925248773783343,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(129,84,70)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u771f\\u7684\",\n",
       "                    \"value\": 0.06543542148456702,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(14,153,28)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8bbe\\u5b9a\",\n",
       "                    \"value\": 0.06538314577656854,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(48,62,146)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6551\\u63f4\",\n",
       "                    \"value\": 0.064932399053562,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(78,138,139)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5b87\\u5b99\",\n",
       "                    \"value\": 0.06435014428505274,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(143,15,85)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8054\\u5408\\u653f\\u5e9c\",\n",
       "                    \"value\": 0.06327674656729422,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(26,137,96)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u597d\\u83b1\\u575e\",\n",
       "                    \"value\": 0.0629033291239096,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(121,113,76)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6625\\u8282\",\n",
       "                    \"value\": 0.05772818907485669,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(84,77,91)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u60c5\",\n",
       "                    \"value\": 0.05750332029070034,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(47,82,66)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6551\\u63f4\\u961f\",\n",
       "                    \"value\": 0.05729879192151195,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(129,152,110)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\",\n",
       "                    \"value\": 0.0572472420347372,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(123,57,49)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53d1\\u52a8\\u673a\",\n",
       "                    \"value\": 0.05238849222845158,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(145,116,76)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5e0c\\u671b\",\n",
       "                    \"value\": 0.05045143979767551,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(34,60,140)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8fd9\\u90e8\",\n",
       "                    \"value\": 0.04962186129246332,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(68,38,77)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u62ef\\u6551\",\n",
       "                    \"value\": 0.04937168226459944,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(150,8,109)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5927\\u7247\",\n",
       "                    \"value\": 0.04864900759340445,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(59,67,51)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u5fc3\\u5f15\\u529b\",\n",
       "                    \"value\": 0.04804288114302772,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(63,156,83)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u90e8\",\n",
       "                    \"value\": 0.04689538539727303,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(145,31,58)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786c\\u6838\",\n",
       "                    \"value\": 0.04670879200582564,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(40,130,70)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e09\\u4f53\",\n",
       "                    \"value\": 0.04525783774007544,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(30,83,55)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5b8f\\u5927\",\n",
       "                    \"value\": 0.04470297439626555,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(25,48,74)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7a7f\\u8d8a\",\n",
       "                    \"value\": 0.044670000619156935,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(131,17,150)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u5b5f\\u8fbe\",\n",
       "                    \"value\": 0.042483738031442876,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(109,26,49)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5c48\\u695a\",\n",
       "                    \"value\": 0.04218449771152948,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(141,157,123)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8ba1\\u5212\",\n",
       "                    \"value\": 0.042105477632293394,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(103,29,99)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u611f\",\n",
       "                    \"value\": 0.04205812585957073,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(43,83,156)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5e7f\\u64ad\",\n",
       "                    \"value\": 0.04201530143762426,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(79,59,107)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u727a\\u7272\",\n",
       "                    \"value\": 0.04100043846469013,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(68,68,6)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u611f\\u89c9\",\n",
       "                    \"value\": 0.04089713842785439,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(158,33,13)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"2001\",\n",
       "                    \"value\": 0.040015018455147114,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(105,77,60)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u70b9\\u71c3\",\n",
       "                    \"value\": 0.0400136502631621,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(18,89,33)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5de5\\u4e1a\",\n",
       "                    \"value\": 0.03972522136593252,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(92,87,116)\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            ],\n",
       "            \"left\": \"-10%\",\n",
       "            \"top\": \"-10%\",\n",
       "            \"drawOutOfBound\": false,\n",
       "            \"textStyle\": {\n",
       "                \"emphasis\": {}\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"wordCloud\",\n",
       "            \"name\": \"textrank\",\n",
       "            \"shape\": \"circle\",\n",
       "            \"rotationRange\": [\n",
       "                -90,\n",
       "                90\n",
       "            ],\n",
       "            \"rotationStep\": 45,\n",
       "            \"girdSize\": 20,\n",
       "            \"sizeRange\": [\n",
       "                10,\n",
       "                60\n",
       "            ],\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u7403\",\n",
       "                    \"value\": 1.0,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(47,66,48)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7535\\u5f71\",\n",
       "                    \"value\": 0.996673087448874,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(149,47,87)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\",\n",
       "                    \"value\": 0.9754260881022752,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(31,67,11)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e2d\\u56fd\",\n",
       "                    \"value\": 0.9583168640857961,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(136,24,49)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6d41\\u6d6a\",\n",
       "                    \"value\": 0.48986504120696994,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(114,99,151)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u717d\\u60c5\",\n",
       "                    \"value\": 0.39643839721356705,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(67,81,1)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7269\",\n",
       "                    \"value\": 0.3742408821996431,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(66,148,38)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7247\",\n",
       "                    \"value\": 0.3689999844335871,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(40,14,137)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53f0\\u8bcd\",\n",
       "                    \"value\": 0.36024505590926087,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(94,16,49)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7c7b\",\n",
       "                    \"value\": 0.3588422390094141,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(110,50,112)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6545\\u4e8b\",\n",
       "                    \"value\": 0.3551532417840374,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(152,45,121)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7535\\u5f71\",\n",
       "                    \"value\": 0.31403344073615386,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(76,28,102)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u4eac\",\n",
       "                    \"value\": 0.31230056725449706,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(23,14,34)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u60c5\",\n",
       "                    \"value\": 0.2760973525818965,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(94,134,7)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u597d\\u83b1\\u575e\",\n",
       "                    \"value\": 0.273861934180611,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(62,116,90)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8bbe\\u5b9a\",\n",
       "                    \"value\": 0.270650747197413,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(48,43,3)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6728\\u661f\",\n",
       "                    \"value\": 0.24564425983732835,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(92,112,107)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5e0c\\u671b\",\n",
       "                    \"value\": 0.24474388717786663,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(44,100,43)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u56fd\\u4ea7\",\n",
       "                    \"value\": 0.23910885448109495,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(93,84,35)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u611f\\u89c9\",\n",
       "                    \"value\": 0.22151369086048697,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(50,135,148)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u62ef\\u6551\",\n",
       "                    \"value\": 0.22120880325962464,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(71,132,98)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u611f\",\n",
       "                    \"value\": 0.21049713036467563,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(102,72,79)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u89c2\\u4f17\",\n",
       "                    \"value\": 0.21041226313890893,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(26,80,150)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u539f\\u8457\",\n",
       "                    \"value\": 0.2046662068769043,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(33,13,48)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5b87\\u5b99\",\n",
       "                    \"value\": 0.20240290165407196,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(12,114,74)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5927\\u7247\",\n",
       "                    \"value\": 0.2012766595246156,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(36,83,69)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5bfc\\u6f14\",\n",
       "                    \"value\": 0.20046582638950994,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(129,32,134)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u592a\\u7a7a\",\n",
       "                    \"value\": 0.1992468219314784,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(26,123,33)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\\u7247\",\n",
       "                    \"value\": 0.19446275334238458,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(38,134,50)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u89d2\\u8272\",\n",
       "                    \"value\": 0.1926279108567905,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(105,144,89)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6f14\\u5458\",\n",
       "                    \"value\": 0.1738286097420517,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(48,16,123)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u8282\",\n",
       "                    \"value\": 0.16857306641299083,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(150,11,154)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u661f\\u9645\",\n",
       "                    \"value\": 0.15861159106201883,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(6,123,155)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6218\\u72fc\",\n",
       "                    \"value\": 0.15655208226710693,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(18,78,42)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\",\n",
       "                    \"value\": 0.15418358907789959,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(38,36,153)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7a7f\\u8d8a\",\n",
       "                    \"value\": 0.15147751064746248,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(137,87,130)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7247\\u5b50\",\n",
       "                    \"value\": 0.15110840028977818,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(64,109,56)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u727a\\u7272\",\n",
       "                    \"value\": 0.1503068182000741,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(84,8,122)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u503c\\u5f97\",\n",
       "                    \"value\": 0.1501974557236288,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(92,57,130)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e16\\u754c\",\n",
       "                    \"value\": 0.14784771004627362,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(48,155,34)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53d9\\u4e8b\",\n",
       "                    \"value\": 0.146725964596363,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(126,121,35)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u610f\\u4e49\",\n",
       "                    \"value\": 0.1462941916364683,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(76,152,78)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u9f13\\u52b1\",\n",
       "                    \"value\": 0.14470596085085782,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(127,88,104)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7ec6\\u8282\",\n",
       "                    \"value\": 0.14332385434101488,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,78,28)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7c7b\\u578b\",\n",
       "                    \"value\": 0.13791616557744749,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(74,138,10)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u672c\",\n",
       "                    \"value\": 0.1359218021461008,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(122,19,3)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u573a\\u666f\",\n",
       "                    \"value\": 0.13274650486957998,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(42,61,135)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u526a\\u8f91\",\n",
       "                    \"value\": 0.12995993009508466,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(90,23,124)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u903b\\u8f91\",\n",
       "                    \"value\": 0.12605892398518126,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(72,142,89)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u65b9\",\n",
       "                    \"value\": 0.1259389226499488,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(13,88,81)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6280\\u672f\",\n",
       "                    \"value\": 0.12324011679669852,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(26,8,53)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5f71\\u7247\",\n",
       "                    \"value\": 0.12288923086677457,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(29,64,26)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8868\\u6f14\",\n",
       "                    \"value\": 0.12192202026338059,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(145,120,93)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4f5c\\u54c1\",\n",
       "                    \"value\": 0.11924584718057449,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(134,0,148)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6c34\\u51c6\",\n",
       "                    \"value\": 0.11896478982127279,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(155,146,92)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u955c\\u5934\",\n",
       "                    \"value\": 0.11759503554914624,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(5,84,157)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6f14\\u6280\",\n",
       "                    \"value\": 0.11743768750807877,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(72,105,70)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8ba1\\u5212\",\n",
       "                    \"value\": 0.11343083494164627,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(38,115,88)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u6027\",\n",
       "                    \"value\": 0.11284558793336648,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(34,101,100)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5c0f\\u8bf4\",\n",
       "                    \"value\": 0.11034462399387983,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(3,135,106)\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            ],\n",
       "            \"left\": \"40%\",\n",
       "            \"top\": \"-10%\",\n",
       "            \"drawOutOfBound\": false,\n",
       "            \"textStyle\": {\n",
       "                \"emphasis\": {}\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"wordCloud\",\n",
       "            \"name\": \"lda\",\n",
       "            \"shape\": \"circle\",\n",
       "            \"rotationRange\": [\n",
       "                -90,\n",
       "                90\n",
       "            ],\n",
       "            \"rotationStep\": 45,\n",
       "            \"girdSize\": 20,\n",
       "            \"sizeRange\": [\n",
       "                10,\n",
       "                60\n",
       "            ],\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u7535\\u5f71\",\n",
       "                    \"value\": 0.011000045575201511,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(34,13,126)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\",\n",
       "                    \"value\": 0.010787355713546276,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(89,154,125)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e2d\\u56fd\",\n",
       "                    \"value\": 0.010513871908187866,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(59,144,80)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u7403\",\n",
       "                    \"value\": 0.009875745512545109,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(157,15,14)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7279\\u6548\",\n",
       "                    \"value\": 0.00723205367103219,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(158,14,21)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6d41\\u6d6a\",\n",
       "                    \"value\": 0.00492261303588748,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(159,153,42)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u717d\\u60c5\",\n",
       "                    \"value\": 0.004223708063364029,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(14,122,94)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7247\",\n",
       "                    \"value\": 0.004193319007754326,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(142,59,128)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7269\",\n",
       "                    \"value\": 0.004010995849967003,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(101,101,157)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6545\\u4e8b\",\n",
       "                    \"value\": 0.003889447543770075,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(10,93,7)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53f0\\u8bcd\",\n",
       "                    \"value\": 0.003889447543770075,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(103,89,14)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7c7b\",\n",
       "                    \"value\": 0.0037071227561682463,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(140,46,120)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u771f\\u7684\",\n",
       "                    \"value\": 0.003676737891510129,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(28,66,159)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7535\\u5f71\",\n",
       "                    \"value\": 0.0034336368553340435,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(1,112,3)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u60c5\",\n",
       "                    \"value\": 0.0032209292985498905,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(8,20,62)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u4eac\",\n",
       "                    \"value\": 0.0030386000871658325,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(158,115,68)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u597d\\u83b1\\u575e\",\n",
       "                    \"value\": 0.0029778301250189543,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(37,55,75)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8bbe\\u5b9a\",\n",
       "                    \"value\": 0.0029170531779527664,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(64,20,45)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u56fd\\u4ea7\",\n",
       "                    \"value\": 0.002856278093531728,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(87,44,24)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8fd9\\u90e8\",\n",
       "                    \"value\": 0.0027955046389251947,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(14,19,159)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5e0c\\u671b\",\n",
       "                    \"value\": 0.0027347297873347998,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(6,47,136)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5c34\\u5c2c\",\n",
       "                    \"value\": 0.0026739556342363358,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(46,79,88)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u90e8\",\n",
       "                    \"value\": 0.002643567742779851,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(150,67,78)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u539f\\u8457\",\n",
       "                    \"value\": 0.002400472294539213,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(127,127,2)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u611f\\u89c9\",\n",
       "                    \"value\": 0.002309308620169759,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(43,100,9)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u592a\\u7a7a\",\n",
       "                    \"value\": 0.002218149369582534,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(20,85,157)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6728\\u661f\",\n",
       "                    \"value\": 0.00221814913675189,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(36,21,104)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5927\\u7247\",\n",
       "                    \"value\": 0.0021877605468034744,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(47,99,41)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u62ef\\u6551\",\n",
       "                    \"value\": 0.00215737521648407,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(100,97,142)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u89c2\\u4f17\",\n",
       "                    \"value\": 0.0020662129390984774,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(121,84,85)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u611f\",\n",
       "                    \"value\": 0.00203582551330328,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(68,116,156)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5b87\\u5b99\",\n",
       "                    \"value\": 0.00203582551330328,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(135,117,102)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5bfc\\u6f14\",\n",
       "                    \"value\": 0.0020054387860000134,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(140,119,3)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\\u7247\",\n",
       "                    \"value\": 0.001975052058696747,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(87,1,123)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u89d2\\u8272\",\n",
       "                    \"value\": 0.0019446639344096184,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(90,14,76)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u9519\",\n",
       "                    \"value\": 0.00191427581012249,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,85,53)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u9f13\\u52b1\",\n",
       "                    \"value\": 0.0018535020062699914,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(57,6,46)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6f14\\u5458\",\n",
       "                    \"value\": 0.0018231153953820467,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(52,148,40)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u8282\",\n",
       "                    \"value\": 0.0018231153953820467,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(61,51,119)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5218\\u6148\\u6b23\",\n",
       "                    \"value\": 0.0018231153953820467,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(55,74,91)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7247\\u5b50\",\n",
       "                    \"value\": 0.0017623400781303644,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(109,3,154)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e09\\u661f\",\n",
       "                    \"value\": 0.0017319535836577415,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,21,34)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u661f\\u9645\",\n",
       "                    \"value\": 0.0017319534672424197,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(109,64,78)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u503c\\u5f97\",\n",
       "                    \"value\": 0.001671178499236703,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(45,154,99)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\",\n",
       "                    \"value\": 0.0016407921211794019,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(119,152,33)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6218\\u72fc\",\n",
       "                    \"value\": 0.00164079200476408,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(82,46,154)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7a7f\\u8d8a\",\n",
       "                    \"value\": 0.001610403647646308,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(154,42,5)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u70b9\",\n",
       "                    \"value\": 0.0015800177352502942,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(77,60,43)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7ec6\\u8282\",\n",
       "                    \"value\": 0.0015800177352502942,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(120,35,97)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53d9\\u4e8b\",\n",
       "                    \"value\": 0.0015496297273784876,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(2,96,81)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u610f\\u4e49\",\n",
       "                    \"value\": 0.0015496297273784876,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(30,37,145)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u672c\",\n",
       "                    \"value\": 0.0014888558071106672,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(80,29,42)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u526a\\u8f91\",\n",
       "                    \"value\": 0.0014888558071106672,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(159,54,13)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6f14\\u6280\",\n",
       "                    \"value\": 0.0014888558071106672,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(5,98,103)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5f71\\u7247\",\n",
       "                    \"value\": 0.0014584680320695043,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(72,138,149)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e16\\u754c\",\n",
       "                    \"value\": 0.0014280813047662377,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(82,160,62)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u727a\\u7272\",\n",
       "                    \"value\": 0.0014280813047662377,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(19,120,22)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7c7b\\u578b\",\n",
       "                    \"value\": 0.001397694111801684,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(62,0,110)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u65b9\",\n",
       "                    \"value\": 0.001397694111801684,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(123,132,128)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786e\\u5b9e\",\n",
       "                    \"value\": 0.001397694111801684,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(117,17,91)\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            ],\n",
       "            \"left\": \"-10%\",\n",
       "            \"top\": \"35%\",\n",
       "            \"drawOutOfBound\": false,\n",
       "            \"textStyle\": {\n",
       "                \"emphasis\": {}\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"wordCloud\",\n",
       "            \"name\": \"word2vec\",\n",
       "            \"shape\": \"circle\",\n",
       "            \"rotationRange\": [\n",
       "                -90,\n",
       "                90\n",
       "            ],\n",
       "            \"rotationStep\": 45,\n",
       "            \"girdSize\": 20,\n",
       "            \"sizeRange\": [\n",
       "                10,\n",
       "                60\n",
       "            ],\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u90ed\\u5e06\",\n",
       "                    \"value\": -1757.1336878985167,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(55,84,138)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8054\\u5408\\u653f\\u5e9c\",\n",
       "                    \"value\": -1774.4079785346985,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(106,144,19)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u4e0b\\u57ce\",\n",
       "                    \"value\": -1783.770349264145,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(152,129,25)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5218\\u6148\\u6b23\",\n",
       "                    \"value\": -1812.0504857748747,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(39,99,12)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6551\\u63f4\\u961f\",\n",
       "                    \"value\": -1827.208292067051,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(14,113,143)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5143\\u5e74\",\n",
       "                    \"value\": -1869.1751044355333,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(133,71,73)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6735\\u6735\",\n",
       "                    \"value\": -1877.6246874779463,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(108,139,50)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6728\\u661f\",\n",
       "                    \"value\": -1912.2901126630604,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(70,101,32)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53ef\\u60dc\",\n",
       "                    \"value\": -1937.3654574956745,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(149,105,12)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u81f3\\u5c11\",\n",
       "                    \"value\": -1951.7429789002053,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(29,33,160)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53ea\\u80fd\",\n",
       "                    \"value\": -1956.3698825156316,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(136,44,98)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53d1\\u52a8\\u673a\",\n",
       "                    \"value\": -1973.0470940843225,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(5,94,70)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786c\\u6838\",\n",
       "                    \"value\": -1977.5962551534176,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(86,17,138)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u70b9\\u71c3\",\n",
       "                    \"value\": -1991.1569873727858,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(16,81,89)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e09\\u4f53\",\n",
       "                    \"value\": -1996.2133169118315,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(121,48,86)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786e\\u5b9e\",\n",
       "                    \"value\": -1996.6248589493334,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,109,113)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5f71\\u7247\",\n",
       "                    \"value\": -1998.3930413899943,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(138,135,157)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u57fa\\u7840\",\n",
       "                    \"value\": -1998.6483534417057,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(92,130,90)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u5fc3\\u5f15\\u529b\",\n",
       "                    \"value\": -2001.5776877321769,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(85,35,14)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u50cf\\u662f\",\n",
       "                    \"value\": -2019.4596791984513,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(73,79,14)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u80af\\u5b9a\",\n",
       "                    \"value\": -2035.7619176302105,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,71,57)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7535\\u5f71\",\n",
       "                    \"value\": -2036.0707702818327,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(4,45,148)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u9519\",\n",
       "                    \"value\": -2045.9975019949488,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(82,47,3)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4f9d\\u7136\",\n",
       "                    \"value\": -2048.935940299183,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(40,0,56)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6210\\u529f\",\n",
       "                    \"value\": -2052.9916877134237,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(93,116,145)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u611f\\u89c9\",\n",
       "                    \"value\": -2067.8701943299384,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(32,149,99)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7247\",\n",
       "                    \"value\": -2070.9574657734447,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(84,36,143)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6982\\u5ff5\",\n",
       "                    \"value\": -2073.729540048833,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(62,85,74)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8fd9\\u662f\",\n",
       "                    \"value\": -2076.105830639135,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(50,84,39)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7535\\u5f71\",\n",
       "                    \"value\": -2079.090236918215,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(11,139,95)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u672b\\u65e5\",\n",
       "                    \"value\": -2081.124973738857,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(45,159,127)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6218\\u72fc\",\n",
       "                    \"value\": -2081.9974810163258,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(126,156,47)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u672c\",\n",
       "                    \"value\": -2089.2734922707314,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(136,157,42)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7406\\u89e3\",\n",
       "                    \"value\": -2089.29617554383,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(49,151,32)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7247\\u5b50\",\n",
       "                    \"value\": -2089.3166226574685,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(51,10,64)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u70b9\",\n",
       "                    \"value\": -2089.851214717375,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(57,91,5)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u771f\\u7684\",\n",
       "                    \"value\": -2097.196458680555,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(42,125,3)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7c97\\u7cd9\",\n",
       "                    \"value\": -2097.653156610406,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(52,111,114)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u884c\",\n",
       "                    \"value\": -2100.6055776875583,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(121,112,129)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u4eac\",\n",
       "                    \"value\": -2102.1245884622913,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(73,131,9)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7279\\u522b\",\n",
       "                    \"value\": -2104.0539271162997,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(70,156,64)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\",\n",
       "                    \"value\": -2104.664778503844,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(45,156,107)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u597d\",\n",
       "                    \"value\": -2105.109005513601,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(149,82,18)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786c\\u4f24\",\n",
       "                    \"value\": -2107.2725463265087,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(57,15,19)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u6000\",\n",
       "                    \"value\": -2109.406559197814,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(48,71,127)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6551\\u63f4\",\n",
       "                    \"value\": -2110.429212840856,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(158,75,22)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7c7b\\u578b\",\n",
       "                    \"value\": -2111.064899618781,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(121,134,23)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"bug\",\n",
       "                    \"value\": -2111.1685410763093,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(11,155,9)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e09\\u661f\",\n",
       "                    \"value\": -2113.4292630583514,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(146,143,109)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6c34\\u5e73\",\n",
       "                    \"value\": -2114.837322113912,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(54,49,37)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7f3a\\u70b9\",\n",
       "                    \"value\": -2115.2823285037884,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(51,30,45)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u90e8\",\n",
       "                    \"value\": -2121.911513410625,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(19,149,111)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6545\\u4e8b\",\n",
       "                    \"value\": -2122.131462634774,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(32,40,95)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8fd9\\u90e8\",\n",
       "                    \"value\": -2125.268442822271,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(71,56,37)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u660e\\u767d\",\n",
       "                    \"value\": -2125.415136915515,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(157,59,103)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7279\\u6548\",\n",
       "                    \"value\": -2129.765435821151,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(35,156,114)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5957\\u8def\",\n",
       "                    \"value\": -2130.204747956479,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(27,124,118)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7f16\\u5267\",\n",
       "                    \"value\": -2132.8593144352344,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(8,130,148)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6807\\u51c6\",\n",
       "                    \"value\": -2133.408374204999,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(80,138,113)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u56fd\\u4ea7\\u7535\\u5f71\",\n",
       "                    \"value\": -2135.906498065917,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(15,92,78)\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            ],\n",
       "            \"left\": \"40%\",\n",
       "            \"top\": \"35%\",\n",
       "            \"drawOutOfBound\": false,\n",
       "            \"textStyle\": {\n",
       "                \"emphasis\": {}\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [],\n",
       "            \"selected\": {},\n",
       "            \"show\": true,\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"itemWidth\": 25,\n",
       "            \"itemHeight\": 14\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"showContent\": true,\n",
       "        \"alwaysShowContent\": false,\n",
       "        \"showDelay\": 0,\n",
       "        \"hideDelay\": 100,\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0,\n",
       "        \"padding\": 5\n",
       "    },\n",
       "    \"title\": [\n",
       "        {\n",
       "            \"text\": \"\\u6d41\\u6d6a\\u5730\\u7403\",\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"textStyle\": {\n",
       "                \"fontSize\": 24\n",
       "            }\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_a71d091918ac44f8b4c13cdb79b2ebef.setOption(option_a71d091918ac44f8b4c13cdb79b2ebef);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x1ebcbf2b780>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import WordCloud,Page\n",
    "word1 = data_tfidf.world.values.tolist()\n",
    "value1 = data_tfidf.tfidf.values.tolist()\n",
    "datas1 = [(x,y) for x,y in zip(word1,value1)]\n",
    "word2 = data_trank.world.values.tolist()\n",
    "value2 = data_trank.trank.values.tolist()\n",
    "datas2 = [(x,y) for x,y in zip(word2,value2)]\n",
    "word3 = data_lda.world.values.tolist()\n",
    "value3 = data_lda.lda.values.tolist()\n",
    "datas3 = [(x,y) for x,y in zip(word3,value3)]\n",
    "word4 = data_w2v.world.values.tolist()\n",
    "value4 = data_w2v.w2v.values.tolist()\n",
    "datas4 = [(x,y) for x,y in zip(word4,value4)]\n",
    "clo = (\n",
    "    WordCloud(init_opts=opts.InitOpts(width=\"950px\", height=\"900px\"))\n",
    "    .add(series_name=\"tfidf\", data_pair=datas1, word_size_range=[10, 60],shape = \"circle\",pos_top=\"-10%\",pos_left=\"-10%\")\n",
    "    .add(series_name=\"textrank\", data_pair=datas2, word_size_range=[10, 60],shape = \"circle\",pos_top=\"-10%\",pos_left=\"40%\")\n",
    "    .add(series_name=\"lda\", data_pair=datas3, word_size_range=[10, 60],shape = \"circle\",pos_top=\"35%\",pos_left=\"-10%\")\n",
    "     .add(series_name=\"word2vec\", data_pair=datas4, word_size_range=[10, 60],shape = \"circle\",pos_top=\"35%\",pos_left=\"40%\")\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            title=\"流浪地球\", title_textstyle_opts=opts.TextStyleOpts(font_size=24)\n",
    "        ),\n",
    "        tooltip_opts=opts.TooltipOpts(is_show=True),\n",
    "    )\n",
    ")\n",
    "\n",
    "clo.render_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "stunning-cycle",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>lda</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>texttrank</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>电影</td>\n",
       "      <td>电影</td>\n",
       "      <td>科幻</td>\n",
       "      <td>地球</td>\n",
       "      <td>郭帆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>科幻</td>\n",
       "      <td>科幻</td>\n",
       "      <td>地球</td>\n",
       "      <td>电影</td>\n",
       "      <td>联合政府</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>中国</td>\n",
       "      <td>中国</td>\n",
       "      <td>流浪</td>\n",
       "      <td>科幻</td>\n",
       "      <td>地下城</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>地球</td>\n",
       "      <td>地球</td>\n",
       "      <td>吴京</td>\n",
       "      <td>中国</td>\n",
       "      <td>刘慈欣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>特效</td>\n",
       "      <td>特效</td>\n",
       "      <td>中国</td>\n",
       "      <td>流浪</td>\n",
       "      <td>救援队</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>流浪</td>\n",
       "      <td>流浪</td>\n",
       "      <td>电影</td>\n",
       "      <td>煽情</td>\n",
       "      <td>元年</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>煽情</td>\n",
       "      <td>煽情</td>\n",
       "      <td>木星</td>\n",
       "      <td>人物</td>\n",
       "      <td>朵朵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>科幻片</td>\n",
       "      <td>科幻片</td>\n",
       "      <td>特效</td>\n",
       "      <td>科幻片</td>\n",
       "      <td>木星</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>人物</td>\n",
       "      <td>人物</td>\n",
       "      <td>科幻电影</td>\n",
       "      <td>台词</td>\n",
       "      <td>可惜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>故事</td>\n",
       "      <td>故事</td>\n",
       "      <td>刘慈欣</td>\n",
       "      <td>人类</td>\n",
       "      <td>至少</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  frequency  lda tfidf texttrank word2vec\n",
       "0        电影   电影    科幻        地球       郭帆\n",
       "1        科幻   科幻    地球        电影     联合政府\n",
       "2        中国   中国    流浪        科幻      地下城\n",
       "3        地球   地球    吴京        中国      刘慈欣\n",
       "4        特效   特效    中国        流浪      救援队\n",
       "5        流浪   流浪    电影        煽情       元年\n",
       "6        煽情   煽情    木星        人物       朵朵\n",
       "7       科幻片  科幻片    特效       科幻片       木星\n",
       "8        人物   人物  科幻电影        台词       可惜\n",
       "9        故事   故事   刘慈欣        人类       至少"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp = pd.concat([frequency.reset_index()[0],data_lda.world,data_tfidf.world,data_trank.world,data_w2v.world],axis = 1)\n",
    "cmp.columns = [\"frequency\",\"lda\",\"tfidf\",\"texttrank\",\"word2vec\"]\n",
    "cmp.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-privilege",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nuclear-devices",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th colspan=\"6\" halign=\"left\">star</th>\n",
       "      <th>low</th>\n",
       "      <th>mid</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291544</td>\n",
       "      <td>哈利·波特与阿兹卡班的囚徒 Harry Potter and the Prisoner of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.336667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291545</td>\n",
       "      <td>大鱼 Big Fish</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.095945</td>\n",
       "      <td>0.891197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1291548</td>\n",
       "      <td>死亡诗社 Dead Poets Society</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>0.107004</td>\n",
       "      <td>0.874514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1291549</td>\n",
       "      <td>放牛班的春天 Les choristes</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.067061</td>\n",
       "      <td>0.919132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1291552</td>\n",
       "      <td>指环王3：王者无敌 The Lord of the Rings: The Return of...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>0.186957</td>\n",
       "      <td>0.194410</td>\n",
       "      <td>0.618634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>26931786</td>\n",
       "      <td>蜘蛛侠：英雄远征 Spider-Man: Far from Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.332222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.334444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>27119724</td>\n",
       "      <td>小丑 Joker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>27133569</td>\n",
       "      <td>小丑回魂2 It: Chapter Two</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.337778</td>\n",
       "      <td>0.332222</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>27163278</td>\n",
       "      <td>速度与激情：特别行动 Fast &amp; Furious Presents: Hobbs &amp; Shaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.333704</td>\n",
       "      <td>0.332592</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>30128985</td>\n",
       "      <td>勇敢者游戏2：再战巅峰 Jumanji: The Next Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id                                        movie_title  star         \\\n",
       "                                                                     0      1   \n",
       "0     1291544  哈利·波特与阿兹卡班的囚徒 Harry Potter and the Prisoner of...   NaN   38.0   \n",
       "1     1291545                                        大鱼 Big Fish  29.0    4.0   \n",
       "2     1291548                            死亡诗社 Dead Poets Society  12.0    3.0   \n",
       "3     1291549                               放牛班的春天 Les choristes  25.0    3.0   \n",
       "4     1291552  指环王3：王者无敌 The Lord of the Rings: The Return of...  29.0   74.0   \n",
       "..        ...                                                ...   ...    ...   \n",
       "458  26931786                 蜘蛛侠：英雄远征 Spider-Man: Far from Home   NaN   64.0   \n",
       "459  27119724                                           小丑 Joker   NaN  104.0   \n",
       "460  27133569                              小丑回魂2 It: Chapter Two   NaN   55.0   \n",
       "461  27163278   速度与激情：特别行动 Fast & Furious Presents: Hobbs & Shaw   NaN   51.0   \n",
       "462  30128985                勇敢者游戏2：再战巅峰 Jumanji: The Next Level   NaN   57.0   \n",
       "\n",
       "                                      low       mid      high  \n",
       "         2      3      4      5                                \n",
       "0    262.0  297.0  173.0  130.0  0.333333  0.330000  0.336667  \n",
       "1      9.0   97.0  325.0  576.0  0.012859  0.095945  0.891197  \n",
       "2     16.0  110.0  335.0  564.0  0.018482  0.107004  0.874514  \n",
       "3     11.0   68.0  276.0  656.0  0.013807  0.067061  0.919132  \n",
       "4    227.0  313.0  219.0  777.0  0.186957  0.194410  0.618634  \n",
       "..     ...    ...    ...    ...       ...       ...       ...  \n",
       "458  235.0  300.0  200.0  101.0  0.332222  0.333333  0.334444  \n",
       "459  196.0  300.0  124.0  176.0  0.333333  0.333333  0.333333  \n",
       "460  249.0  299.0  253.0   44.0  0.337778  0.332222  0.330000  \n",
       "461  249.0  299.0  257.0   43.0  0.333704  0.332592  0.333704  \n",
       "462  243.0  300.0  257.0   43.0  0.333333  0.333333  0.333333  \n",
       "\n",
       "[463 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_star = comm.groupby(['movie_id','movie_title'])['star'].apply(pd.Series.value_counts).to_frame().unstack().reset_index()\n",
    "comm_star[\"low\"] = (comm_star.star[1]+comm_star.star[2])/(comm_star.star[1]+comm_star.star[2]+comm_star.star[3]+comm_star.star[4]+comm_star.star[5])\n",
    "comm_star[\"mid\"] = (comm_star.star[3])/(comm_star.star[1]+comm_star.star[2]+comm_star.star[3]+comm_star.star[4]+comm_star.star[5])\n",
    "comm_star[\"high\"] = (comm_star.star[4]+comm_star.star[5])/(comm_star.star[1]+comm_star.star[2]+comm_star.star[3]+comm_star.star[4]+comm_star.star[5])\n",
    "comm_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "necessary-fruit",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    273857\n",
       "-1     95992\n",
       " 0     74222\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1234)\n",
    "comm[\"label\"] = comm['star'].apply(lambda x :  0 if x<3 else 1 if x>3 else -1)\n",
    "comm_data = comm[comm.star !=0]\n",
    "comm_data \n",
    "comm_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "native-orange",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~生成数据已经保存~~~~~~~~~~~~~~~\n",
    "# # 中评比较模棱两可\n",
    "# like = comm_data[comm_data.label==1].content.values.tolist()\n",
    "# dislike = comm_data[comm_data.label==0].content.values.tolist()\n",
    "# def preprocess_text(content_lines, sentences, category):\n",
    "#     for line in content_lines:\n",
    "#         try:\n",
    "#             segs=jieba.lcut(line)\n",
    "#             segs = filter(lambda x:len(x)>1, segs)\n",
    "#             segs = filter(lambda x:x not in stopwords.stopword, segs)\n",
    "#             sentences.append((\" \".join(segs), category))\n",
    "#         except:\n",
    "#             print (line)\n",
    "#             continue\n",
    "# sen = []\n",
    "# # 上采样,解决样本不均衡\n",
    "# preprocess_text(like, sen, 'like')\n",
    "# preprocess_text(dislike, sen, 'dislike')\n",
    "# preprocess_text(dislike, sen, 'dislike')\n",
    "# preprocess_text(dislike, sen, 'dislike')\n",
    "# # 存sen\n",
    "# temp_file = pd.DataFrame(pd.Series(sen).reset_index(drop = True))\n",
    "# temp_file.to_csv(\"temp_filem_ML.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "binding-lightning",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 将元组字符串解构成元组\n",
    "sen = pd.read_csv(\"temp_filem_ML.csv\")['0'].apply(lambda x: tuple(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "amber-anthropology",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               (如果 喜欢 这部 电影 说明 不是 准备 故事 终章 读过 故事 准备, like)\n",
       "1         (一个 90 曾经 羡慕 一代人 40 年前 观众 他们 影院 星战 正传 三部曲 落幕 2...\n",
       "2         (托尼 说好 回归 家庭 陪伴 家人 最终 还是 选择 重出江湖 因为 责任 使命 因为 钢...\n",
       "3                                 (钢铁 成为 美队 美队 活成 钢铁, like)\n",
       "4                                    (想到 一只 老鼠 拯救 地球, like)\n",
       "                                ...                        \n",
       "496518                          (宮崎駿 動畫 太超 現實 不喜歡, dislike)\n",
       "496519    (大师 作品 较差 一部 无聊 俗气 没法 产生共鸣 以及 喜欢 男女 主角 喜欢 笨人 喜...\n",
       "496520                (观测 爱看 动漫 比较 乐观 可惜 告诉 什么 好看, dislike)\n",
       "496521              (个人 虫子 有关 电影 看好 比较 喜欢 后来 幽灵公主, dislike)\n",
       "496522         (這是 唯一 宮崎駿 系列 喜歡 片子 知道 喜歡 就是 沒有 好感, dislike)\n",
       "Name: 0, Length: 496523, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-thing",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lasting-metadata",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(sen)# 所有元素随机排列\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sen[:200000]) # 带星号的用来解压\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "class TextClassifier():\n",
    "\n",
    "    def __init__(self, classifier=MultinomialNB()):\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,4), max_features=20000)\n",
    "\n",
    "    def features(self, X):\n",
    "        return TfidfTransformer().fit_transform(self.vectorizer.transform(X))\n",
    "#         return self.vectorizer.transform(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.classifier.fit(self.features(X), y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(self.features(X))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.classifier.score(self.features(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "further-police",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_classifier = TextClassifier()\n",
    "text_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "illegal-estonia",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like' 'like']\n",
      "0.81138\n"
     ]
    }
   ],
   "source": [
    "print(text_classifier.predict([\"特效不错,但是剧情硬伤\",\n",
    "                        \"真难看,我喜欢\"]))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "speaking-inspiration",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#预测\n",
    "# comm[comm.star ==0].content[:10].values.tolist()\n",
    "# show_train = pd.DataFrame(pd.Series(comm[comm.star ==0].content[:50].values.tolist())).reset_index(drop = True)\n",
    "# show_pre = pd.DataFrame(pd.Series(text_classifier.predict(comm[comm.star ==0].content[:50].values.tolist()))).reset_index(drop = True)\n",
    "# show = pd.concat([show_train,show_pre],axis=1)\n",
    "# show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-night",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## SVM支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "anonymous-building",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cf7a4e17589e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtext_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-bc65dacbd56c>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \"\"\"\n\u001b[0;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1165\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                     \"max_df corresponds to < documents than min_df\")\n\u001b[0;32m   1215\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0;32m   1218\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_sort_features\u001b[1;34m(self, X, vocabulary)\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m             \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[0mmap_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mold_val\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'clip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "x, y = zip(*sen[:50000]) # 带星号的用来解压\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234)\n",
    "svm = SVC(kernel='linear')\n",
    "text_classifier = TextClassifier(svm)\n",
    "text_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "marked-lobby",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like' 'like']\n",
      "0.79416\n"
     ]
    }
   ],
   "source": [
    "print(text_classifier.predict([\"特效不错,但是剧情硬伤\",\n",
    "                        \"我喜欢\"]))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-stocks",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "intellectual-sandwich",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like' 'like']\n",
      "0.8225906502001917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x, y = zip(*sen) # 带星号的用来解压\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234)\n",
    "lgr = LogisticRegression(solver='sag')\n",
    "text_classifier = TextClassifier(lgr)\n",
    "text_classifier.fit(x_train, y_train)\n",
    "print(text_classifier.predict([\"特效不错,但是剧情硬伤\",\n",
    "                        \"我觉得还行\"]))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-alaska",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##  FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sustainable-breath",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74222"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# like = comm_data[comm_data.label==1].content.values.tolist()\n",
    "# dislike = comm_data[comm_data.label==0].content.values.tolist()\n",
    "# len(dislike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stock-burning",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # ~~~~~~~~已经生成数据文件~~~~~~~~~~~~~~~~~\n",
    "# import jieba \n",
    "# import pandas as pd \n",
    "# import random\n",
    "# like = comm_data[comm_data.label==1].content.values.tolist()\n",
    "# dislike = comm_data[comm_data.label==0].content.values.tolist()\n",
    "\n",
    "# def preprocess_text(content_lines,sentences,category): \n",
    "#     for line in content_lines:\n",
    "#         try:\n",
    "#             segs=jieba.lcut(line)\n",
    "#             segs = filter(lambda x:len(x)>1, segs)\n",
    "#             segs = filter(lambda x:x not in stopwords, segs)\n",
    "#             sentences.append(\"__label__\"+str(category)+\" , \"+\" \".join(segs))\n",
    "#         except:\n",
    "#             print(line)\n",
    "#             continue\n",
    "            \n",
    "# # 生成训练数据            \n",
    "# senten=[]\n",
    "# preprocess_text(like,senten ,'like')\n",
    "# preprocess_text(dislike,senten ,'dislike')\n",
    "# preprocess_text(dislike,senten ,'dislike')\n",
    "# preprocess_text(dislike,senten ,'dislike')\n",
    "\n",
    "# random.shuffle(senten)\n",
    "\n",
    "# print(\"writing data to fasttext supervised learning format...\")\n",
    "# out = open('train_data_supervised_fasttext.txt','w' )#,encoding='utf-8') \n",
    "# for sentence in senten:\n",
    "#     out.write(sentence+\"\\n\") \n",
    "# print(\"done!\")\n",
    "# out = open('train_data_supervised_fasttext.txt','w' )#,encoding='utf-8') \n",
    "# for sentence in senten[:372392]:\n",
    "#     out.write(sentence+\"\\n\") \n",
    "\n",
    "# out1 = open('test_data_supervised_fasttext.txt','w' )#,encoding='utf-8') \n",
    "# for sentence in senten[372393:]:\n",
    "#     out1.write(sentence+\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "macro-stress",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9351486344960928\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "# 有监督\n",
    "classifier=fasttext.train_supervised('train_data_supervised_fasttext.txt',lr=1.0,dim=200,wordNgrams=4,epoch=30)\n",
    "# 对模型进行评估\n",
    "result = classifier.test('test_data_supervised_fasttext.txt')\n",
    "# print('P@1:',result.precision)\n",
    "# print('R@1:',result.recall)\n",
    "# print('Number of examples:',result.nexamples)\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-rapid",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "texts = \"特效不错,但是剧情硬伤\"\n",
    "labels=classifier.predict(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-bicycle",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dress-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = pd.read_csv(\"temp_filem_ML.csv\")['0'].apply(lambda x: tuple(eval(x)))\n",
    "random.shuffle(sen)     \n",
    "x,y=zip(*sen)\n",
    "train_data,test_data,train_target,test_target=train_test_split(x, y, random_state=1234)\n",
    "cate_dic={'like':1,'dislike':0}\n",
    "y_train = pd.Series(train_target).apply(lambda x:cate_dic[x] , train_target)\n",
    "y_test = pd.Series(test_target).apply(lambda x:cate_dic[x] , test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-peace",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "widespread-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "基于卷积神经网络的中文文本分类\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "learn = tf.contrib.learn\n",
    "FLAGS = None\n",
    "# 文档最长长度\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "# 最小词频数\n",
    "MIN_WORD_FREQUENCE = 2\n",
    "# 词嵌入的维度\n",
    "EMBEDDING_SIZE = 20\n",
    "# filter个数\n",
    "N_FILTERS = 10 # 10个神经元\n",
    "# 感知野大小\n",
    "WINDOW_SIZE = 20\n",
    "#filter的形状\n",
    "FILTER_SHAPE1 = [WINDOW_SIZE, EMBEDDING_SIZE]\n",
    "FILTER_SHAPE2 = [WINDOW_SIZE, N_FILTERS] \n",
    "# 池化\n",
    "POOLING_WINDOW = 4\n",
    "POOLING_STRIDE = 2\n",
    "n_words = 0\n",
    "\n",
    "def cnn_model(features, target):\n",
    "    \"\"\"\n",
    "    2层的卷积神经网络，用于短文本分类\n",
    "    \"\"\"\n",
    "    # 先把词转成词嵌入\n",
    "    # 我们得到一个形状为[n_words, EMBEDDING_SIZE]的词表映射矩阵\n",
    "    # 接着我们可以把一批文本映射成[batch_size, sequence_length,EMBEDDING_SIZE]的矩阵形式\n",
    "    \n",
    "    target = tf.one_hot(target, 15, 1, 0) #对词编码最大选前15个标签,在的为1,不在的为0\n",
    "    print(target)\n",
    "    # 把词变成词嵌入, feature 词矩阵, vocab_size输入数据的总词汇量, embed_dim嵌入矩阵的维度大小\n",
    "    # 输出是 [句子数,词数,嵌入维度数]\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(features\n",
    "                                                    ,vocab_size=n_words\n",
    "                                                    ,embed_dim=EMBEDDING_SIZE\n",
    "                                                    ,scope='words')\n",
    "    # 增加一维\n",
    "    word_vectors = tf.expand_dims(word_vectors, 3)\n",
    "    print(word_vectors)\n",
    "    \n",
    "    with tf.variable_scope('CNN_Layer1'):\n",
    "        # 添加卷积层做滤波\n",
    "        conv1 = tf.contrib.layers.convolution2d(word_vectors\n",
    "                                                ,N_FILTERS\n",
    "                                                ,FILTER_SHAPE1\n",
    "                                                ,padding='VALID')# 不够了舍弃\n",
    "        # 添加RELU非线性\n",
    "        conv1 = tf.nn.relu(conv1) \n",
    "        # 最大池化\n",
    "        pool1 = tf.nn.max_pool(conv1\n",
    "                               ,ksize=[1, POOLING_WINDOW, 1, 1]\n",
    "                               ,strides=[1, POOLING_STRIDE, 1, 1]\n",
    "                               ,padding='SAME')# 不够了填充\n",
    "        # 对矩阵进行转置，以满足形状\n",
    "        pool1 = tf.transpose(pool1, [0, 1, 3, 2])\n",
    "        \n",
    "    with tf.variable_scope('CNN_Layer2'):\n",
    "        # 第2卷积层\n",
    "        conv2 = tf.contrib.layers.convolution2d(pool1\n",
    "                                                ,N_FILTERS\n",
    "                                                ,FILTER_SHAPE2\n",
    "                                                ,padding='VALID') \n",
    "        # 抽取特征\n",
    "        pool2 = tf.squeeze(tf.reduce_max(conv2, 1), squeeze_dims=[1])\n",
    "        \n",
    "    # 全连接层\n",
    "    logits = tf.contrib.layers.fully_connected(pool2, 15, activation_fn=None)\n",
    "    loss = tf.losses.softmax_cross_entropy(target, logits) \n",
    "    # 优化器\n",
    "    train_op = tf.contrib.layers.optimize_loss(loss\n",
    "                                               ,tf.contrib.framework.get_global_step()\n",
    "                                               ,optimizer='Adam'\n",
    "                                               ,learning_rate=0.01)\n",
    "    \n",
    "    return ({\n",
    "            'class': tf.argmax(logits, 1),\n",
    "            'prob': tf.nn.softmax(logits)\n",
    "    }, loss, train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lucky-conviction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words:72648\n"
     ]
    }
   ],
   "source": [
    "global n_words\n",
    "# 处理词汇\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH# 最大长度和最小词频\n",
    "                                                          ,min_frequency=MIN_WORD_FREQUENCE) \n",
    "x_train = np.array(list(vocab_processor.fit_transform(train_data)))\n",
    "x_test = np.array(list(vocab_processor.transform(test_data)))\n",
    "n_words=len(vocab_processor.vocabulary_) \n",
    "print('Total words:%d'%n_words)# 不重复的单词数量\n",
    "\n",
    "# cate_dic={'like':1,'dislike':0}\n",
    "# y_train = pd.Series(train_target).apply(lambda x:cate_dic[x] , train_target)\n",
    "# y_test = pd.Series(test_target).apply(lambda x:cate_dic[x] , test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "invisible-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [step, loss_train, loss_test, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_cnn=pd.DataFrame(columns=('step','loss_train','loss_test','score'))\n",
    "# result_cnn.to_csv(\"./DL_model/cnn_loss.csv\",index=False)\n",
    "result_cnn = pd.read_csv(\"./DL_model/cnn_loss.csv\")\n",
    "result_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A4B07D080>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/cnn_model'}\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./DL_model/cnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.7076654, step = 1\n",
      "INFO:tensorflow:global_step/sec: 21.8189\n",
      "INFO:tensorflow:loss = 0.66579205, step = 101 (4.585 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into ./DL_model/cnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.53151697.\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/cnn_model\\model.ckpt-200\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-17:11:42\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/cnn_model\\model.ckpt-200\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    classifier1=learn.Estimator(model_fn=cnn_model,model_dir='./DL_model/cnn_model')\n",
    "    #Train and predict\n",
    "    classifier1_skl = learn.SKCompat(classifier1)\n",
    "    classifier1_skl.fit(x_train,y_train,steps=200)\n",
    "    y_predicted=classifier1_skl.predict(x_test)['class']\n",
    "    score=metrics.accuracy_score(y_test,y_predicted)\n",
    "    loss_train = classifier1.evaluate(x_train,y_train)\n",
    "    loss_test = classifier1.evaluate(x_test,y_test) \n",
    "    result_rnn = result_rnn.append({\"loss_test\":loss_test[\"loss\"],\n",
    "                                                        \"loss_train\":loss_train[\"loss\"],\n",
    "                                                        \"score\":score,\n",
    "                                                        \"step\":loss_train[\"global_step\"]\n",
    "                                                        },ignore_index=True)\n",
    "    result_rnn.to_csv(\"./DL_model/cnn_loss.csv\",index=False)\n",
    "    print(\"我存了第%d次\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "standard-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EBCF28B080>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\11514\\\\AppData\\\\Local\\\\Temp\\\\tmp1nu516dc'}\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-40-e7ee6796035b>:85: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.7078671, step = 1\n",
      "INFO:tensorflow:global_step/sec: 18.0318\n",
      "INFO:tensorflow:loss = 0.6899018, step = 101 (5.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9513\n",
      "INFO:tensorflow:loss = 0.4858918, step = 201 (6.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4824\n",
      "INFO:tensorflow:loss = 0.42110074, step = 301 (6.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9548\n",
      "INFO:tensorflow:loss = 0.46961197, step = 401 (7.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7101\n",
      "INFO:tensorflow:loss = 0.48979077, step = 501 (5.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.817\n",
      "INFO:tensorflow:loss = 0.45768446, step = 601 (6.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8585\n",
      "INFO:tensorflow:loss = 0.42910954, step = 701 (6.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1342\n",
      "INFO:tensorflow:loss = 0.43446928, step = 801 (6.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5572\n",
      "INFO:tensorflow:loss = 0.29818732, step = 901 (6.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5411\n",
      "INFO:tensorflow:loss = 0.41014272, step = 1001 (6.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2513\n",
      "INFO:tensorflow:loss = 0.38491175, step = 1101 (6.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8984\n",
      "INFO:tensorflow:loss = 0.37527162, step = 1201 (6.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7959\n",
      "INFO:tensorflow:loss = 0.35982987, step = 1301 (6.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2677\n",
      "INFO:tensorflow:loss = 0.33398935, step = 1401 (6.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6663\n",
      "INFO:tensorflow:loss = 0.3292506, step = 1501 (5.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4541\n",
      "INFO:tensorflow:loss = 0.3198082, step = 1601 (7.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5756\n",
      "INFO:tensorflow:loss = 0.3407227, step = 1701 (6.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5287\n",
      "INFO:tensorflow:loss = 0.3638414, step = 1801 (5.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3906\n",
      "INFO:tensorflow:loss = 0.39531487, step = 1901 (6.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7097\n",
      "INFO:tensorflow:loss = 0.30084682, step = 2001 (6.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8349\n",
      "INFO:tensorflow:loss = 0.40575224, step = 2101 (6.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9234\n",
      "INFO:tensorflow:loss = 0.36836702, step = 2201 (6.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4717\n",
      "INFO:tensorflow:loss = 0.24819532, step = 2301 (6.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4761\n",
      "INFO:tensorflow:loss = 0.5281279, step = 2401 (5.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6053\n",
      "INFO:tensorflow:loss = 0.29806727, step = 2501 (6.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9264\n",
      "INFO:tensorflow:loss = 0.42572406, step = 2601 (7.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7105\n",
      "INFO:tensorflow:loss = 0.35385308, step = 2701 (5.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1982\n",
      "INFO:tensorflow:loss = 0.38960323, step = 2801 (6.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9647\n",
      "INFO:tensorflow:loss = 0.41185445, step = 2901 (7.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2905\n",
      "INFO:tensorflow:loss = 0.20753959, step = 3001 (5.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1344\n",
      "INFO:tensorflow:loss = 0.27730978, step = 3101 (7.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.191\n",
      "INFO:tensorflow:loss = 0.2607367, step = 3201 (6.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3402\n",
      "INFO:tensorflow:loss = 0.24805868, step = 3301 (5.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.095\n",
      "INFO:tensorflow:loss = 0.3096096, step = 3401 (7.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7319\n",
      "INFO:tensorflow:loss = 0.2754598, step = 3501 (5.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2405\n",
      "INFO:tensorflow:loss = 0.2855526, step = 3601 (6.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3013\n",
      "INFO:tensorflow:loss = 0.2338152, step = 3701 (6.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.253\n",
      "INFO:tensorflow:loss = 0.27424306, step = 3801 (5.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9344\n",
      "INFO:tensorflow:loss = 0.37035728, step = 3901 (7.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2705\n",
      "INFO:tensorflow:loss = 0.26395684, step = 4001 (6.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4489\n",
      "INFO:tensorflow:loss = 0.21789171, step = 4101 (6.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9615\n",
      "INFO:tensorflow:loss = 0.34686205, step = 4201 (7.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.853\n",
      "INFO:tensorflow:loss = 0.28254864, step = 4301 (5.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3969\n",
      "INFO:tensorflow:loss = 0.25868064, step = 4401 (6.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5071\n",
      "INFO:tensorflow:loss = 0.36394304, step = 4501 (7.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1307\n",
      "INFO:tensorflow:loss = 0.20551907, step = 4601 (5.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0045\n",
      "INFO:tensorflow:loss = 0.2782653, step = 4701 (6.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1983\n",
      "INFO:tensorflow:loss = 0.28766826, step = 4801 (7.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1639\n",
      "INFO:tensorflow:loss = 0.22719195, step = 4901 (5.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4689\n",
      "INFO:tensorflow:loss = 0.2148499, step = 5001 (8.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3268\n",
      "INFO:tensorflow:loss = 0.28339148, step = 5101 (5.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3574\n",
      "INFO:tensorflow:loss = 0.22932327, step = 5201 (6.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4013\n",
      "INFO:tensorflow:loss = 0.22226042, step = 5301 (6.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2737\n",
      "INFO:tensorflow:loss = 0.18930739, step = 5401 (5.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0914\n",
      "INFO:tensorflow:loss = 0.29172716, step = 5501 (7.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1508\n",
      "INFO:tensorflow:loss = 0.24056655, step = 5601 (5.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2943\n",
      "INFO:tensorflow:loss = 0.3210176, step = 5701 (6.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4684\n",
      "INFO:tensorflow:loss = 0.25626594, step = 5801 (7.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1343\n",
      "INFO:tensorflow:loss = 0.2137895, step = 5901 (5.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8522\n",
      "INFO:tensorflow:loss = 0.21135557, step = 6001 (7.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9248\n",
      "INFO:tensorflow:loss = 0.12426661, step = 6101 (7.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2002\n",
      "INFO:tensorflow:loss = 0.118051425, step = 6201 (5.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2299\n",
      "INFO:tensorflow:loss = 0.25618765, step = 6301 (6.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9714\n",
      "INFO:tensorflow:loss = 0.14428098, step = 6401 (7.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.998\n",
      "INFO:tensorflow:loss = 0.1470037, step = 6501 (6.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8493\n",
      "INFO:tensorflow:loss = 0.25082153, step = 6601 (6.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3807\n",
      "INFO:tensorflow:loss = 0.22133633, step = 6701 (6.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0345\n",
      "INFO:tensorflow:loss = 0.16929515, step = 6801 (7.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.18874155, step = 6901 (5.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8919\n",
      "INFO:tensorflow:loss = 0.16936122, step = 7001 (6.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8225\n",
      "INFO:tensorflow:loss = 0.14647682, step = 7101 (7.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2067\n",
      "INFO:tensorflow:loss = 0.27741238, step = 7201 (5.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7019\n",
      "INFO:tensorflow:loss = 0.23521332, step = 7301 (7.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2394\n",
      "INFO:tensorflow:loss = 0.20307465, step = 7401 (5.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0531\n",
      "INFO:tensorflow:loss = 0.25825047, step = 7501 (6.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7013\n",
      "INFO:tensorflow:loss = 0.20991428, step = 7601 (7.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7186\n",
      "INFO:tensorflow:loss = 0.18756741, step = 7701 (5.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0914\n",
      "INFO:tensorflow:loss = 0.21992138, step = 7801 (7.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5965\n",
      "INFO:tensorflow:loss = 0.2509961, step = 7901 (5.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9175\n",
      "INFO:tensorflow:loss = 0.19572367, step = 8001 (6.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6826\n",
      "INFO:tensorflow:loss = 0.32052872, step = 8101 (7.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5001\n",
      "INFO:tensorflow:loss = 0.19149062, step = 8201 (5.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5041\n",
      "INFO:tensorflow:loss = 0.24442646, step = 8301 (6.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1474\n",
      "INFO:tensorflow:loss = 0.17669842, step = 8401 (6.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1798\n",
      "INFO:tensorflow:loss = 0.20040336, step = 8501 (5.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2678\n",
      "INFO:tensorflow:loss = 0.12437916, step = 8601 (7.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7319\n",
      "INFO:tensorflow:loss = 0.18743, step = 8701 (5.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6101\n",
      "INFO:tensorflow:loss = 0.1087505, step = 8801 (6.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9894\n",
      "INFO:tensorflow:loss = 0.08741075, step = 8901 (7.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3016\n",
      "INFO:tensorflow:loss = 0.14850695, step = 9001 (5.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.176\n",
      "INFO:tensorflow:loss = 0.194421, step = 9101 (6.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7064\n",
      "INFO:tensorflow:loss = 0.28330153, step = 9201 (7.297 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9284 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 17.3197\n",
      "INFO:tensorflow:loss = 0.124481805, step = 9301 (5.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6483\n",
      "INFO:tensorflow:loss = 0.18923119, step = 9401 (7.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3004\n",
      "INFO:tensorflow:loss = 0.14374949, step = 9501 (6.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2248\n",
      "INFO:tensorflow:loss = 0.14119884, step = 9601 (5.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1247\n",
      "INFO:tensorflow:loss = 0.13279039, step = 9701 (7.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0198\n",
      "INFO:tensorflow:loss = 0.138975, step = 9801 (5.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3931\n",
      "INFO:tensorflow:loss = 0.13512483, step = 9901 (6.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9481\n",
      "INFO:tensorflow:loss = 0.1738125, step = 10001 (7.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6549\n",
      "INFO:tensorflow:loss = 0.16594133, step = 10101 (5.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7757\n",
      "INFO:tensorflow:loss = 0.2010909, step = 10201 (6.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6197\n",
      "INFO:tensorflow:loss = 0.19208309, step = 10301 (6.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1194\n",
      "INFO:tensorflow:loss = 0.17159021, step = 10401 (5.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.666\n",
      "INFO:tensorflow:loss = 0.22995928, step = 10501 (7.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3289\n",
      "INFO:tensorflow:loss = 0.17649795, step = 10601 (6.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1638\n",
      "INFO:tensorflow:loss = 0.18545277, step = 10701 (5.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0943\n",
      "INFO:tensorflow:loss = 0.18850903, step = 10801 (7.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0724\n",
      "INFO:tensorflow:loss = 0.16928896, step = 10901 (5.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2707\n",
      "INFO:tensorflow:loss = 0.16428867, step = 11001 (7.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1992\n",
      "INFO:tensorflow:loss = 0.11621071, step = 11101 (6.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4623\n",
      "INFO:tensorflow:loss = 0.13722739, step = 11201 (5.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0973\n",
      "INFO:tensorflow:loss = 0.1373578, step = 11301 (7.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5471\n",
      "INFO:tensorflow:loss = 0.18540841, step = 11401 (6.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5009\n",
      "INFO:tensorflow:loss = 0.105079815, step = 11501 (6.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3621\n",
      "INFO:tensorflow:loss = 0.13735917, step = 11601 (7.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3045\n",
      "INFO:tensorflow:loss = 0.17423752, step = 11701 (5.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0669\n",
      "INFO:tensorflow:loss = 0.091914, step = 11801 (7.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7614\n",
      "INFO:tensorflow:loss = 0.09404072, step = 11901 (6.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3691\n",
      "INFO:tensorflow:loss = 0.09935269, step = 12001 (6.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5163\n",
      "INFO:tensorflow:loss = 0.12702847, step = 12101 (7.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3615\n",
      "INFO:tensorflow:loss = 0.18527108, step = 12201 (5.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8608\n",
      "INFO:tensorflow:loss = 0.136145, step = 12301 (7.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.027\n",
      "INFO:tensorflow:loss = 0.16396837, step = 12401 (6.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.339\n",
      "INFO:tensorflow:loss = 0.095932566, step = 12501 (5.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.693\n",
      "INFO:tensorflow:loss = 0.11480027, step = 12601 (7.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8268\n",
      "INFO:tensorflow:loss = 0.16383204, step = 12701 (5.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6627\n",
      "INFO:tensorflow:loss = 0.28071666, step = 12801 (6.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1005\n",
      "INFO:tensorflow:loss = 0.119679146, step = 12901 (7.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5229\n",
      "INFO:tensorflow:loss = 0.1423207, step = 13001 (5.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2849\n",
      "INFO:tensorflow:loss = 0.15234719, step = 13101 (7.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5729\n",
      "INFO:tensorflow:loss = 0.3396297, step = 13201 (6.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7915\n",
      "INFO:tensorflow:loss = 0.13993178, step = 13301 (6.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7246\n",
      "INFO:tensorflow:loss = 0.14805126, step = 13401 (6.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1901\n",
      "INFO:tensorflow:loss = 0.08647241, step = 13501 (6.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.18\n",
      "INFO:tensorflow:loss = 0.15065715, step = 13601 (5.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3202\n",
      "INFO:tensorflow:loss = 0.21929988, step = 13701 (7.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8208\n",
      "INFO:tensorflow:loss = 0.16278464, step = 13801 (5.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5733\n",
      "INFO:tensorflow:loss = 0.14661676, step = 13901 (6.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2819\n",
      "INFO:tensorflow:loss = 0.111120075, step = 14001 (7.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4173\n",
      "INFO:tensorflow:loss = 0.27729982, step = 14101 (5.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0508\n",
      "INFO:tensorflow:loss = 0.110700436, step = 14201 (6.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.633\n",
      "INFO:tensorflow:loss = 0.07546778, step = 14301 (6.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9401\n",
      "INFO:tensorflow:loss = 0.15034346, step = 14401 (5.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7158\n",
      "INFO:tensorflow:loss = 0.163347, step = 14501 (7.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.573\n",
      "INFO:tensorflow:loss = 0.07234891, step = 14601 (5.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7858\n",
      "INFO:tensorflow:loss = 0.15934902, step = 14701 (6.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8586\n",
      "INFO:tensorflow:loss = 0.071025014, step = 14801 (6.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5831\n",
      "INFO:tensorflow:loss = 0.17890598, step = 14901 (5.685 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 13.0916\n",
      "INFO:tensorflow:loss = 0.13788596, step = 15001 (7.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6395\n",
      "INFO:tensorflow:loss = 0.11842463, step = 15101 (5.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7296\n",
      "INFO:tensorflow:loss = 0.08229959, step = 15201 (6.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9662\n",
      "INFO:tensorflow:loss = 0.10862084, step = 15301 (7.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3867\n",
      "INFO:tensorflow:loss = 0.11852706, step = 15401 (5.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6148\n",
      "INFO:tensorflow:loss = 0.08802329, step = 15501 (7.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 18\n",
      "INFO:tensorflow:loss = 0.13354497, step = 15601 (5.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.407\n",
      "INFO:tensorflow:loss = 0.15665507, step = 15701 (6.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1333\n",
      "INFO:tensorflow:loss = 0.11645973, step = 15801 (7.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3352\n",
      "INFO:tensorflow:loss = 0.10839909, step = 15901 (5.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5418\n",
      "INFO:tensorflow:loss = 0.058093905, step = 16001 (7.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3486\n",
      "INFO:tensorflow:loss = 0.118138194, step = 16101 (5.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3175\n",
      "INFO:tensorflow:loss = 0.07605679, step = 16201 (6.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2579\n",
      "INFO:tensorflow:loss = 0.21055181, step = 16301 (6.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5449\n",
      "INFO:tensorflow:loss = 0.112975925, step = 16401 (6.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0331\n",
      "INFO:tensorflow:loss = 0.17869991, step = 16501 (6.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7059\n",
      "INFO:tensorflow:loss = 0.12738614, step = 16601 (7.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3635\n",
      "INFO:tensorflow:loss = 0.1005056, step = 16701 (5.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1181\n",
      "INFO:tensorflow:loss = 0.1542013, step = 16801 (7.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9977\n",
      "INFO:tensorflow:loss = 0.099914454, step = 16901 (7.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0588\n",
      "INFO:tensorflow:loss = 0.13543913, step = 17001 (6.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9606\n",
      "INFO:tensorflow:loss = 0.13363227, step = 17101 (6.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1283\n",
      "INFO:tensorflow:loss = 0.16855782, step = 17201 (6.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0289\n",
      "INFO:tensorflow:loss = 0.11253208, step = 17301 (6.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0395\n",
      "INFO:tensorflow:loss = 0.1124581, step = 17401 (6.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9822\n",
      "INFO:tensorflow:loss = 0.11673731, step = 17501 (6.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.85\n",
      "INFO:tensorflow:loss = 0.1220212, step = 17601 (6.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7231\n",
      "INFO:tensorflow:loss = 0.11993271, step = 17701 (6.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3923\n",
      "INFO:tensorflow:loss = 0.063810326, step = 17801 (5.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3552\n",
      "INFO:tensorflow:loss = 0.09742581, step = 17901 (6.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8871\n",
      "INFO:tensorflow:loss = 0.13064769, step = 18001 (7.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3999\n",
      "INFO:tensorflow:loss = 0.14670745, step = 18101 (5.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0203\n",
      "INFO:tensorflow:loss = 0.08502853, step = 18201 (6.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6347\n",
      "INFO:tensorflow:loss = 0.05313166, step = 18301 (6.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0525\n",
      "INFO:tensorflow:loss = 0.13320732, step = 18401 (5.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6657\n",
      "INFO:tensorflow:loss = 0.15244195, step = 18501 (6.817 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18544 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4665\n",
      "INFO:tensorflow:loss = 0.13987517, step = 18601 (6.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2724\n",
      "INFO:tensorflow:loss = 0.080874234, step = 18701 (5.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6653\n",
      "INFO:tensorflow:loss = 0.17110375, step = 18801 (7.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3233\n",
      "INFO:tensorflow:loss = 0.11953631, step = 18901 (5.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6295\n",
      "INFO:tensorflow:loss = 0.13802813, step = 19001 (6.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3272\n",
      "INFO:tensorflow:loss = 0.099582896, step = 19101 (8.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9948\n",
      "INFO:tensorflow:loss = 0.1063497, step = 19201 (6.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8019\n",
      "INFO:tensorflow:loss = 0.1120478, step = 19301 (7.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5617\n",
      "INFO:tensorflow:loss = 0.13491571, step = 19401 (7.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8795\n",
      "INFO:tensorflow:loss = 0.12219373, step = 19501 (9.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4414\n",
      "INFO:tensorflow:loss = 0.16812634, step = 19601 (7.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7394\n",
      "INFO:tensorflow:loss = 0.11310622, step = 19701 (9.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6256\n",
      "INFO:tensorflow:loss = 0.073310845, step = 19801 (6.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4698\n",
      "INFO:tensorflow:loss = 0.1196831, step = 19901 (8.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4167\n",
      "INFO:tensorflow:loss = 0.12049557, step = 20001 (6.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3553\n",
      "INFO:tensorflow:loss = 0.1359083, step = 20101 (6.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3964\n",
      "INFO:tensorflow:loss = 0.14867473, step = 20201 (8.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9906\n",
      "INFO:tensorflow:loss = 0.2266074, step = 20301 (5.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0642\n",
      "INFO:tensorflow:loss = 0.12151467, step = 20401 (7.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2719\n",
      "INFO:tensorflow:loss = 0.1138605, step = 20501 (6.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0179\n",
      "INFO:tensorflow:loss = 0.1272277, step = 20601 (5.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0739\n",
      "INFO:tensorflow:loss = 0.034470893, step = 20701 (7.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.825\n",
      "INFO:tensorflow:loss = 0.07556691, step = 20801 (5.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5066\n",
      "INFO:tensorflow:loss = 0.07496771, step = 20901 (6.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9738\n",
      "INFO:tensorflow:loss = 0.115695626, step = 21001 (7.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5878\n",
      "INFO:tensorflow:loss = 0.11019763, step = 21101 (6.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2897\n",
      "INFO:tensorflow:loss = 0.16551009, step = 21201 (6.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3077\n",
      "INFO:tensorflow:loss = 0.100841194, step = 21301 (7.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7398\n",
      "INFO:tensorflow:loss = 0.13478991, step = 21401 (6.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1968\n",
      "INFO:tensorflow:loss = 0.09140912, step = 21501 (5.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9423\n",
      "INFO:tensorflow:loss = 0.10781123, step = 21601 (7.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4444\n",
      "INFO:tensorflow:loss = 0.12358429, step = 21701 (6.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1959\n",
      "INFO:tensorflow:loss = 0.10367428, step = 21801 (7.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6858\n",
      "INFO:tensorflow:loss = 0.17503482, step = 21901 (6.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2524\n",
      "INFO:tensorflow:loss = 0.081263915, step = 22001 (5.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4928\n",
      "INFO:tensorflow:loss = 0.07730122, step = 22101 (6.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8172\n",
      "INFO:tensorflow:loss = 0.2317449, step = 22201 (6.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1503\n",
      "INFO:tensorflow:loss = 0.15464252, step = 22301 (5.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1868\n",
      "INFO:tensorflow:loss = 0.100459725, step = 22401 (8.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9525\n",
      "INFO:tensorflow:loss = 0.16574654, step = 22501 (5.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9071\n",
      "INFO:tensorflow:loss = 0.12558003, step = 22601 (6.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0159\n",
      "INFO:tensorflow:loss = 0.06360598, step = 22701 (7.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8292\n",
      "INFO:tensorflow:loss = 0.1479571, step = 22801 (5.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2851\n",
      "INFO:tensorflow:loss = 0.061421406, step = 22901 (7.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13934757, step = 23001 (6.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.639\n",
      "INFO:tensorflow:loss = 0.11273081, step = 23101 (6.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7613\n",
      "INFO:tensorflow:loss = 0.109908305, step = 23201 (7.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7223\n",
      "INFO:tensorflow:loss = 0.07927288, step = 23301 (5.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5118\n",
      "INFO:tensorflow:loss = 0.1433799, step = 23401 (7.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.772\n",
      "INFO:tensorflow:loss = 0.10300407, step = 23501 (6.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3146\n",
      "INFO:tensorflow:loss = 0.12920997, step = 23601 (6.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1452\n",
      "INFO:tensorflow:loss = 0.12028912, step = 23701 (7.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.462\n",
      "INFO:tensorflow:loss = 0.12050682, step = 23801 (7.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3543\n",
      "INFO:tensorflow:loss = 0.07724108, step = 23901 (6.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2636\n",
      "INFO:tensorflow:loss = 0.056320153, step = 24001 (7.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0464\n",
      "INFO:tensorflow:loss = 0.12523094, step = 24101 (9.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2385\n",
      "INFO:tensorflow:loss = 0.092925265, step = 24201 (7.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.045\n",
      "INFO:tensorflow:loss = 0.07916479, step = 24301 (5.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7501\n",
      "INFO:tensorflow:loss = 0.10124906, step = 24401 (7.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.015\n",
      "INFO:tensorflow:loss = 0.1550016, step = 24501 (7.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8736\n",
      "INFO:tensorflow:loss = 0.071790926, step = 24601 (6.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8707\n",
      "INFO:tensorflow:loss = 0.11174226, step = 24701 (7.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0319\n",
      "INFO:tensorflow:loss = 0.06817583, step = 24801 (5.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1521\n",
      "INFO:tensorflow:loss = 0.078586474, step = 24901 (7.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9859\n",
      "INFO:tensorflow:loss = 0.10379577, step = 25001 (7.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6052\n",
      "INFO:tensorflow:loss = 0.14220709, step = 25101 (7.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2855\n",
      "INFO:tensorflow:loss = 0.16137251, step = 25201 (9.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.988\n",
      "INFO:tensorflow:loss = 0.14667317, step = 25301 (7.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8949\n",
      "INFO:tensorflow:loss = 0.093552485, step = 25401 (9.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2779\n",
      "INFO:tensorflow:loss = 0.098460525, step = 25501 (7.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1911\n",
      "INFO:tensorflow:loss = 0.14046788, step = 25601 (7.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7685\n",
      "INFO:tensorflow:loss = 0.15925854, step = 25701 (9.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8904\n",
      "INFO:tensorflow:loss = 0.1293937, step = 25801 (7.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7938\n",
      "INFO:tensorflow:loss = 0.105091386, step = 25901 (7.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1031\n",
      "INFO:tensorflow:loss = 0.09855003, step = 26001 (7.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3991\n",
      "INFO:tensorflow:loss = 0.108733505, step = 26101 (6.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3432\n",
      "INFO:tensorflow:loss = 0.041812755, step = 26201 (6.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.933\n",
      "INFO:tensorflow:loss = 0.10327275, step = 26301 (7.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9276\n",
      "INFO:tensorflow:loss = 0.10069506, step = 26401 (5.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2084\n",
      "INFO:tensorflow:loss = 0.07842551, step = 26501 (6.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1409\n",
      "INFO:tensorflow:loss = 0.12307706, step = 26601 (8.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8653\n",
      "INFO:tensorflow:loss = 0.07548627, step = 26701 (6.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5635\n",
      "INFO:tensorflow:loss = 0.08722235, step = 26801 (7.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8815\n",
      "INFO:tensorflow:loss = 0.10873868, step = 26901 (6.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5807\n",
      "INFO:tensorflow:loss = 0.12214491, step = 27001 (5.688 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27101 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 13.9618\n",
      "INFO:tensorflow:loss = 0.07250179, step = 27101 (7.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2883\n",
      "INFO:tensorflow:loss = 0.14472663, step = 27201 (7.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1895\n",
      "INFO:tensorflow:loss = 0.07484546, step = 27301 (6.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0899\n",
      "INFO:tensorflow:loss = 0.07007659, step = 27401 (5.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8832\n",
      "INFO:tensorflow:loss = 0.05093371, step = 27501 (7.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7426\n",
      "INFO:tensorflow:loss = 0.06773719, step = 27601 (6.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9623\n",
      "INFO:tensorflow:loss = 0.13306157, step = 27701 (5.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3577\n",
      "INFO:tensorflow:loss = 0.06628448, step = 27801 (7.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8401\n",
      "INFO:tensorflow:loss = 0.07872246, step = 27901 (6.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8361\n",
      "INFO:tensorflow:loss = 0.2170775, step = 28001 (6.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4376\n",
      "INFO:tensorflow:loss = 0.12888984, step = 28101 (7.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8285\n",
      "INFO:tensorflow:loss = 0.06846125, step = 28201 (5.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9024\n",
      "INFO:tensorflow:loss = 0.097535565, step = 28301 (6.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4483\n",
      "INFO:tensorflow:loss = 0.18032464, step = 28401 (7.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8009\n",
      "INFO:tensorflow:loss = 0.18972471, step = 28501 (5.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9315\n",
      "INFO:tensorflow:loss = 0.10375354, step = 28601 (7.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5541\n",
      "INFO:tensorflow:loss = 0.071996935, step = 28701 (6.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1464\n",
      "INFO:tensorflow:loss = 0.080440685, step = 28801 (5.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7348\n",
      "INFO:tensorflow:loss = 0.10403416, step = 28901 (7.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7834\n",
      "INFO:tensorflow:loss = 0.14852539, step = 29001 (5.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3845\n",
      "INFO:tensorflow:loss = 0.12532704, step = 29101 (6.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6803\n",
      "INFO:tensorflow:loss = 0.08747757, step = 29201 (7.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5883\n",
      "INFO:tensorflow:loss = 0.076211475, step = 29301 (6.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5653\n",
      "INFO:tensorflow:loss = 0.08470417, step = 29401 (6.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.092\n",
      "INFO:tensorflow:loss = 0.08886984, step = 29501 (7.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8857\n",
      "INFO:tensorflow:loss = 0.16354476, step = 29601 (5.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5306\n",
      "INFO:tensorflow:loss = 0.06372128, step = 29701 (7.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5734\n",
      "INFO:tensorflow:loss = 0.15239768, step = 29801 (6.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8204\n",
      "INFO:tensorflow:loss = 0.23320037, step = 29901 (6.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6468\n",
      "INFO:tensorflow:loss = 0.16133852, step = 30001 (7.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4064\n",
      "INFO:tensorflow:loss = 0.12441625, step = 30101 (8.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6941\n",
      "INFO:tensorflow:loss = 0.115880586, step = 30201 (9.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3924\n",
      "INFO:tensorflow:loss = 0.10355094, step = 30301 (6.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3622\n",
      "INFO:tensorflow:loss = 0.20117088, step = 30401 (8.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4229\n",
      "INFO:tensorflow:loss = 0.063817576, step = 30501 (8.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3898\n",
      "INFO:tensorflow:loss = 0.097789824, step = 30601 (6.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8575\n",
      "INFO:tensorflow:loss = 0.063283905, step = 30701 (6.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2729\n",
      "INFO:tensorflow:loss = 0.13556963, step = 30801 (7.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8846\n",
      "INFO:tensorflow:loss = 0.07592389, step = 30901 (5.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12999436, step = 31001 (8.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0914\n",
      "INFO:tensorflow:loss = 0.22739545, step = 31101 (6.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7606\n",
      "INFO:tensorflow:loss = 0.10614897, step = 31201 (7.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1367\n",
      "INFO:tensorflow:loss = 0.19777289, step = 31301 (7.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9414\n",
      "INFO:tensorflow:loss = 0.092063494, step = 31401 (6.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.544\n",
      "INFO:tensorflow:loss = 0.18354432, step = 31501 (7.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8775\n",
      "INFO:tensorflow:loss = 0.12232187, step = 31601 (6.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5858\n",
      "INFO:tensorflow:loss = 0.10676724, step = 31701 (5.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3987\n",
      "INFO:tensorflow:loss = 0.10281861, step = 31801 (8.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3157\n",
      "INFO:tensorflow:loss = 0.06834589, step = 31901 (6.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9417\n",
      "INFO:tensorflow:loss = 0.17456222, step = 32001 (7.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2205\n",
      "INFO:tensorflow:loss = 0.099682964, step = 32101 (5.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6553\n",
      "INFO:tensorflow:loss = 0.18308416, step = 32201 (7.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7467\n",
      "INFO:tensorflow:loss = 0.1760099, step = 32301 (5.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.653\n",
      "INFO:tensorflow:loss = 0.14088812, step = 32401 (6.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4731\n",
      "INFO:tensorflow:loss = 0.08369042, step = 32501 (7.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4925\n",
      "INFO:tensorflow:loss = 0.054484725, step = 32601 (5.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1244\n",
      "INFO:tensorflow:loss = 0.05920752, step = 32701 (7.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2104\n",
      "INFO:tensorflow:loss = 0.09080626, step = 32801 (5.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1122\n",
      "INFO:tensorflow:loss = 0.10230145, step = 32901 (6.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8005\n",
      "INFO:tensorflow:loss = 0.057358958, step = 33001 (7.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3492\n",
      "INFO:tensorflow:loss = 0.07450547, step = 33101 (5.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8319\n",
      "INFO:tensorflow:loss = 0.07189891, step = 33201 (7.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5695\n",
      "INFO:tensorflow:loss = 0.08954562, step = 33301 (5.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8736\n",
      "INFO:tensorflow:loss = 0.117542304, step = 33401 (6.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.916\n",
      "INFO:tensorflow:loss = 0.07272917, step = 33501 (7.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4334\n",
      "INFO:tensorflow:loss = 0.069554076, step = 33601 (5.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4239\n",
      "INFO:tensorflow:loss = 0.06605912, step = 33701 (7.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4967\n",
      "INFO:tensorflow:loss = 0.10202128, step = 33801 (6.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3855\n",
      "INFO:tensorflow:loss = 0.06936496, step = 33901 (5.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4318\n",
      "INFO:tensorflow:loss = 0.13666126, step = 34001 (8.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8699\n",
      "INFO:tensorflow:loss = 0.084682725, step = 34101 (6.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2435\n",
      "INFO:tensorflow:loss = 0.1934658, step = 34201 (6.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5191\n",
      "INFO:tensorflow:loss = 0.058833957, step = 34301 (6.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.13\n",
      "INFO:tensorflow:loss = 0.08411926, step = 34401 (7.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.264\n",
      "INFO:tensorflow:loss = 0.13831556, step = 34501 (5.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2671\n",
      "INFO:tensorflow:loss = 0.1341114, step = 34601 (7.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7984\n",
      "INFO:tensorflow:loss = 0.15802327, step = 34701 (5.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8444\n",
      "INFO:tensorflow:loss = 0.07152537, step = 34801 (5.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5435\n",
      "INFO:tensorflow:loss = 0.084740855, step = 34901 (7.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2115\n",
      "INFO:tensorflow:loss = 0.11793744, step = 35001 (5.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.94\n",
      "INFO:tensorflow:loss = 0.07662112, step = 35101 (7.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4341\n",
      "INFO:tensorflow:loss = 0.06838852, step = 35201 (6.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2431\n",
      "INFO:tensorflow:loss = 0.108983934, step = 35301 (5.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0926\n",
      "INFO:tensorflow:loss = 0.05878742, step = 35401 (7.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1256\n",
      "INFO:tensorflow:loss = 0.111690015, step = 35501 (5.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0313\n",
      "INFO:tensorflow:loss = 0.19054508, step = 35601 (7.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5086\n",
      "INFO:tensorflow:loss = 0.08638628, step = 35701 (6.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.11\n",
      "INFO:tensorflow:loss = 0.07477781, step = 35801 (5.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9236\n",
      "INFO:tensorflow:loss = 0.10085113, step = 35901 (7.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7526\n",
      "INFO:tensorflow:loss = 0.13633657, step = 36001 (6.349 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36047 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 17.187\n",
      "INFO:tensorflow:loss = 0.1484589, step = 36101 (5.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6202\n",
      "INFO:tensorflow:loss = 0.07275461, step = 36201 (7.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8935\n",
      "INFO:tensorflow:loss = 0.061755836, step = 36301 (5.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2976\n",
      "INFO:tensorflow:loss = 0.08735317, step = 36401 (7.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6957\n",
      "INFO:tensorflow:loss = 0.09015593, step = 36501 (6.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3452\n",
      "INFO:tensorflow:loss = 0.10162246, step = 36601 (5.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6086\n",
      "INFO:tensorflow:loss = 0.084985085, step = 36701 (6.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1261\n",
      "INFO:tensorflow:loss = 0.11221784, step = 36801 (7.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.324\n",
      "INFO:tensorflow:loss = 0.11013193, step = 36901 (5.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2922\n",
      "INFO:tensorflow:loss = 0.21135235, step = 37001 (7.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8063\n",
      "INFO:tensorflow:loss = 0.08492861, step = 37101 (5.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9224\n",
      "INFO:tensorflow:loss = 0.09215624, step = 37201 (5.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6772\n",
      "INFO:tensorflow:loss = 0.2082374, step = 37301 (7.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3448\n",
      "INFO:tensorflow:loss = 0.14049774, step = 37401 (5.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9165\n",
      "INFO:tensorflow:loss = 0.075146765, step = 37501 (8.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1116\n",
      "INFO:tensorflow:loss = 0.1161869, step = 37601 (6.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.123\n",
      "INFO:tensorflow:loss = 0.07865976, step = 37701 (6.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0358\n",
      "INFO:tensorflow:loss = 0.07251331, step = 37801 (7.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7127\n",
      "INFO:tensorflow:loss = 0.15722677, step = 37901 (5.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5554\n",
      "INFO:tensorflow:loss = 0.08811826, step = 38001 (7.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8612\n",
      "INFO:tensorflow:loss = 0.08119786, step = 38101 (5.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8541\n",
      "INFO:tensorflow:loss = 0.094922714, step = 38201 (7.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8634\n",
      "INFO:tensorflow:loss = 0.07755051, step = 38301 (5.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1541\n",
      "INFO:tensorflow:loss = 0.1337285, step = 38401 (6.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3859\n",
      "INFO:tensorflow:loss = 0.12463423, step = 38501 (6.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1265\n",
      "INFO:tensorflow:loss = 0.08914912, step = 38601 (5.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9529\n",
      "INFO:tensorflow:loss = 0.10801472, step = 38701 (6.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8766\n",
      "INFO:tensorflow:loss = 0.115988016, step = 38801 (7.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7245\n",
      "INFO:tensorflow:loss = 0.08762361, step = 38901 (6.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.921\n",
      "INFO:tensorflow:loss = 0.058227874, step = 39001 (7.739 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 17.8444\n",
      "INFO:tensorflow:loss = 0.06782308, step = 39101 (5.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3202\n",
      "INFO:tensorflow:loss = 0.076270014, step = 39201 (6.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.946\n",
      "INFO:tensorflow:loss = 0.15743813, step = 39301 (7.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0423\n",
      "INFO:tensorflow:loss = 0.08565939, step = 39401 (5.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1142\n",
      "INFO:tensorflow:loss = 0.08614284, step = 39501 (7.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8304\n",
      "INFO:tensorflow:loss = 0.15888311, step = 39601 (6.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5094\n",
      "INFO:tensorflow:loss = 0.058164403, step = 39701 (5.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3459\n",
      "INFO:tensorflow:loss = 0.07594635, step = 39801 (6.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4731\n",
      "INFO:tensorflow:loss = 0.17855248, step = 39901 (6.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1782\n",
      "INFO:tensorflow:loss = 0.07562367, step = 40001 (5.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7773\n",
      "INFO:tensorflow:loss = 0.05674559, step = 40101 (7.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5191\n",
      "INFO:tensorflow:loss = 0.13885401, step = 40201 (5.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0473\n",
      "INFO:tensorflow:loss = 0.07113546, step = 40301 (5.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0922\n",
      "INFO:tensorflow:loss = 0.07921865, step = 40401 (7.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8748\n",
      "INFO:tensorflow:loss = 0.10932477, step = 40501 (5.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5657\n",
      "INFO:tensorflow:loss = 0.15234889, step = 40601 (6.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8996\n",
      "INFO:tensorflow:loss = 0.18772404, step = 40701 (7.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3034\n",
      "INFO:tensorflow:loss = 0.06162777, step = 40801 (5.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3013\n",
      "INFO:tensorflow:loss = 0.09991196, step = 40901 (6.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3443\n",
      "INFO:tensorflow:loss = 0.082021676, step = 41001 (6.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1458\n",
      "INFO:tensorflow:loss = 0.11471167, step = 41101 (5.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1783\n",
      "INFO:tensorflow:loss = 0.07350121, step = 41201 (7.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9578\n",
      "INFO:tensorflow:loss = 0.071173854, step = 41301 (5.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4245\n",
      "INFO:tensorflow:loss = 0.04242727, step = 41401 (6.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.485\n",
      "INFO:tensorflow:loss = 0.0775456, step = 41501 (7.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8593\n",
      "INFO:tensorflow:loss = 0.05077983, step = 41601 (5.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9623\n",
      "INFO:tensorflow:loss = 0.08396684, step = 41701 (6.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.479\n",
      "INFO:tensorflow:loss = 0.076816015, step = 41801 (6.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3382\n",
      "INFO:tensorflow:loss = 0.15905963, step = 41901 (5.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9207\n",
      "INFO:tensorflow:loss = 0.10181644, step = 42001 (7.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4903\n",
      "INFO:tensorflow:loss = 0.101740435, step = 42101 (5.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0491\n",
      "INFO:tensorflow:loss = 0.11091286, step = 42201 (6.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8906\n",
      "INFO:tensorflow:loss = 0.08912191, step = 42301 (7.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9007\n",
      "INFO:tensorflow:loss = 0.13580786, step = 42401 (5.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6921\n",
      "INFO:tensorflow:loss = 0.101500034, step = 42501 (6.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2\n",
      "INFO:tensorflow:loss = 0.08794041, step = 42601 (7.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2355\n",
      "INFO:tensorflow:loss = 0.07939147, step = 42701 (5.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9461\n",
      "INFO:tensorflow:loss = 0.1373251, step = 42801 (7.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0236\n",
      "INFO:tensorflow:loss = 0.1344347, step = 42901 (6.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9866\n",
      "INFO:tensorflow:loss = 0.11973302, step = 43001 (5.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0762\n",
      "INFO:tensorflow:loss = 0.053083517, step = 43101 (8.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9667\n",
      "INFO:tensorflow:loss = 0.081180915, step = 43201 (5.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7173\n",
      "INFO:tensorflow:loss = 0.13107407, step = 43301 (6.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7732\n",
      "INFO:tensorflow:loss = 0.13601768, step = 43401 (7.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5398\n",
      "INFO:tensorflow:loss = 0.207004, step = 43501 (6.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6982\n",
      "INFO:tensorflow:loss = 0.13190633, step = 43601 (5.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.411\n",
      "INFO:tensorflow:loss = 0.045507714, step = 43701 (8.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.917\n",
      "INFO:tensorflow:loss = 0.081726514, step = 43801 (5.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2715\n",
      "INFO:tensorflow:loss = 0.17148253, step = 43901 (6.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0027\n",
      "INFO:tensorflow:loss = 0.07887383, step = 44001 (7.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.107\n",
      "INFO:tensorflow:loss = 0.20680358, step = 44101 (5.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.837\n",
      "INFO:tensorflow:loss = 0.051441662, step = 44201 (7.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6848\n",
      "INFO:tensorflow:loss = 0.16751347, step = 44301 (6.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3839\n",
      "INFO:tensorflow:loss = 0.096241795, step = 44401 (5.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0508\n",
      "INFO:tensorflow:loss = 0.047687665, step = 44501 (7.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5064\n",
      "INFO:tensorflow:loss = 0.1435202, step = 44601 (6.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8009\n",
      "INFO:tensorflow:loss = 0.07914165, step = 44701 (5.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3533\n",
      "INFO:tensorflow:loss = 0.06099071, step = 44801 (7.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1578\n",
      "INFO:tensorflow:loss = 0.13695812, step = 44901 (5.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1479\n",
      "INFO:tensorflow:loss = 0.099092536, step = 45001 (6.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5696\n",
      "INFO:tensorflow:loss = 0.12782325, step = 45101 (6.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1344\n",
      "INFO:tensorflow:loss = 0.11696678, step = 45201 (5.513 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45248 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5456\n",
      "INFO:tensorflow:loss = 0.119157024, step = 45301 (6.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6857\n",
      "INFO:tensorflow:loss = 0.06668518, step = 45401 (6.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5145\n",
      "INFO:tensorflow:loss = 0.071094185, step = 45501 (5.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0521\n",
      "INFO:tensorflow:loss = 0.12507363, step = 45601 (7.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9288\n",
      "INFO:tensorflow:loss = 0.095644556, step = 45701 (6.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9887\n",
      "INFO:tensorflow:loss = 0.08658591, step = 45801 (6.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8244\n",
      "INFO:tensorflow:loss = 0.105146214, step = 45901 (7.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2015\n",
      "INFO:tensorflow:loss = 0.12507832, step = 46001 (5.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6337\n",
      "INFO:tensorflow:loss = 0.17273916, step = 46101 (6.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1592\n",
      "INFO:tensorflow:loss = 0.082830295, step = 46201 (6.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2002\n",
      "INFO:tensorflow:loss = 0.121459246, step = 46301 (5.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2995\n",
      "INFO:tensorflow:loss = 0.10279317, step = 46401 (6.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4938\n",
      "INFO:tensorflow:loss = 0.0637345, step = 46501 (6.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6363\n",
      "INFO:tensorflow:loss = 0.14280213, step = 46601 (6.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7335\n",
      "INFO:tensorflow:loss = 0.07605256, step = 46701 (6.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9017\n",
      "INFO:tensorflow:loss = 0.08735159, step = 46801 (7.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5531\n",
      "INFO:tensorflow:loss = 0.07277635, step = 46901 (5.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4022\n",
      "INFO:tensorflow:loss = 0.059330083, step = 47001 (6.941 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 14.5782\n",
      "INFO:tensorflow:loss = 0.078153744, step = 47101 (6.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8786\n",
      "INFO:tensorflow:loss = 0.08470464, step = 47201 (5.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5765\n",
      "INFO:tensorflow:loss = 0.08085772, step = 47301 (7.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8132\n",
      "INFO:tensorflow:loss = 0.106475644, step = 47401 (6.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4563\n",
      "INFO:tensorflow:loss = 0.1081992, step = 47501 (5.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0827\n",
      "INFO:tensorflow:loss = 0.13401146, step = 47601 (7.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7147\n",
      "INFO:tensorflow:loss = 0.08443218, step = 47701 (5.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0417\n",
      "INFO:tensorflow:loss = 0.12223603, step = 47801 (8.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5913\n",
      "INFO:tensorflow:loss = 0.104453936, step = 47901 (5.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8469\n",
      "INFO:tensorflow:loss = 0.11621338, step = 48001 (6.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9619\n",
      "INFO:tensorflow:loss = 0.066176124, step = 48101 (7.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4601\n",
      "INFO:tensorflow:loss = 0.08398168, step = 48201 (5.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5124\n",
      "INFO:tensorflow:loss = 0.09300007, step = 48301 (7.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5959\n",
      "INFO:tensorflow:loss = 0.11960073, step = 48401 (6.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5841\n",
      "INFO:tensorflow:loss = 0.12445563, step = 48501 (6.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.118\n",
      "INFO:tensorflow:loss = 0.07880639, step = 48601 (7.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6774\n",
      "INFO:tensorflow:loss = 0.16683906, step = 48701 (6.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0718\n",
      "INFO:tensorflow:loss = 0.12130089, step = 48801 (6.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6874\n",
      "INFO:tensorflow:loss = 0.07388989, step = 48901 (7.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9405\n",
      "INFO:tensorflow:loss = 0.09993259, step = 49001 (5.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8476\n",
      "INFO:tensorflow:loss = 0.094735, step = 49101 (6.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.827\n",
      "INFO:tensorflow:loss = 0.07279471, step = 49201 (6.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5112\n",
      "INFO:tensorflow:loss = 0.07012743, step = 49301 (5.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8057\n",
      "INFO:tensorflow:loss = 0.06342425, step = 49401 (7.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4019\n",
      "INFO:tensorflow:loss = 0.10030775, step = 49501 (5.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7305\n",
      "INFO:tensorflow:loss = 0.07709615, step = 49601 (6.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0344\n",
      "INFO:tensorflow:loss = 0.11126793, step = 49701 (6.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3649\n",
      "INFO:tensorflow:loss = 0.049477167, step = 49801 (5.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6049\n",
      "INFO:tensorflow:loss = 0.12586944, step = 49901 (7.930 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50000 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.06813752.\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt-50000\n",
      "Accuracy:0.900194\n",
      "0.9001941497289154\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "classifier=learn.SKCompat(learn.Estimator(model_fn=cnn_model))\n",
    "\n",
    "# 训练和预测\n",
    "classifier.fit(x_train,y_train,steps=50000) \n",
    "y_predicted=classifier.predict(x_test)['class'] \n",
    "score=metrics.accuracy_score(y_test,y_predicted) \n",
    "print('Accuracy:{0:f}'.format(score))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-engine",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tutorial-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用RNN完成文本分类\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers.python.layers import encoders\n",
    "\n",
    "learn = tf.contrib.learn\n",
    "\n",
    "FALGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premier-builder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 72648\n"
     ]
    }
   ],
   "source": [
    "MAX_DOCUMENT_LENGTH=100\n",
    "MIN_WORD_FREQUENCE=2\n",
    "EMBEDDING_SIZE=20\n",
    "global n_words\n",
    "\n",
    "# 处理词汇\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH\n",
    "                                                          ,min_frequency=MIN_WORD_FREQUENCE)\n",
    "x_train = np.array(list(vocab_processor.fit_transform(train_data)))\n",
    "x_test = np.array(list(vocab_processor.transform(test_data))) \n",
    "n_words = len(vocab_processor.vocabulary_)\n",
    "print('Total words: %d' % n_words)\n",
    "\n",
    "# def bag_of_words_model(features, target): \n",
    "#     \"\"\"\n",
    "#     先转成词袋模型\n",
    "#     \"\"\"\n",
    "#     target = tf.one_hot(target, 15, 1, 0)\n",
    "#     features = encoders.bow_encoder(features\n",
    "#                                     ,vocab_size=n_words\n",
    "#                                     ,embed_dim=EMBEDDING_SIZE)\n",
    "#     logits = tf.contrib.layers.fully_connected(features, 15\n",
    "#                                                ,activation_fn=None)\n",
    "#     loss = tf.contrib.losses.softmax_cross_entropy(logits, target)\n",
    "#     train_op = tf.contrib.layers.optimize_loss(loss\n",
    "#                                                ,tf.contrib.framework.get_global_step()\n",
    "#                                                ,optimizer='Adam'\n",
    "#                                                ,learning_rate=0.01)\n",
    "#     return ({\n",
    "#             'class': tf.argmax(logits, 1),\n",
    "#             'prob': tf.nn.softmax(logits)\n",
    "#     }, loss, train_op)\n",
    "\n",
    "# model_fn = bag_of_words_model\n",
    "# classifier = learn.SKCompat(learn.Estimator(model_fn=model_fn))\n",
    "\n",
    "# # Train and predict\n",
    "# classifier.fit(x_train, y_train, steps=1000)\n",
    "# y_predicted = classifier.predict(x_test)['class']\n",
    "# score = metrics.accuracy_score(y_test, y_predicted)\n",
    "# print('Accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scheduled-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(features,target): \n",
    "    \"\"\"\n",
    "    用RNN模型（这里用的是GRU）完成文本分类\n",
    "    \"\"\"\n",
    "    # Convert indexes of words into embeddings.\n",
    "    # This creates embeddings matrix of [n_words, EMBEDDING_SIZE] and then\n",
    "    # maps word indexes of the sequence into [batch_size,sequence_length,\n",
    "    # EMBEDDING_SIZE].\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(features\n",
    "                                                    ,vocab_size=n_words\n",
    "                                                    ,embed_dim=EMBEDDING_SIZE\n",
    "                                                    ,scope='words')\n",
    "    # Split into list of embedding per word, while removing doc length dim。\n",
    "    # word_list results to be a list of tensors [batch_size,EMBEDDING_SIZE].\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "    \n",
    "    # Create a Gated Recurrent Unit cell with hidden size of EMBEDDING_SIZE.\n",
    "    cell = tf.contrib.rnn.GRUCell(EMBEDDING_SIZE)\n",
    "    \n",
    "    # Create an unrolled Recurrent Neural Networks to length of\n",
    "    # MAX_DOCUMENT_LENGTH and passes word_list as inputs for each unit.\n",
    "    _, encoding = tf.contrib.rnn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "    \n",
    "    # Given encoding of RNN, take encoding of last step (e.g hidden size of the\n",
    "    # neural network of last step) and pass it as features for logistic\n",
    "    # regression over output classes.\n",
    "    target = tf.one_hot(target, 15, 1, 0)\n",
    "    logits = tf.contrib.layers.fully_connected(encoding, 15, activation_fn=None)\n",
    "    loss = tf.contrib.losses.softmax_cross_entropy(logits, target)\n",
    "    # Create a training op.\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss,\n",
    "            tf.contrib.framework.get_global_step(),\n",
    "            optimizer='Adam',\n",
    "            learning_rate=0.01)\n",
    "    return ({\n",
    "            'class': tf.argmax(logits, 1),\n",
    "            'prob': tf.nn.softmax(logits)\n",
    "    }, loss, train_op)\n",
    "\n",
    "model_fn = rnn_model \n",
    "# 初始化注意取消\n",
    "# result_rnn=pd.DataFrame(columns=('step','loss_train','loss_test','score'))\n",
    "# result_rnn.to_csv(\"./DL_model/rnn_loss.csv\",index=False)\n",
    "\n",
    "result_rnn = pd.read_csv(\"./DL_model/rnn_loss.csv\")\n",
    "# classifier=learn.SKCompat(learn.Estimator(model_fn=model_fn))\n",
    "# #Train and predict\n",
    "# classifier.fit(x_train,y_train,steps=1000) \n",
    "# y_predicted=classifier.predict(x_test)['class']\n",
    "# score=metrics.accuracy_score(y_test,y_predicted)\n",
    "# print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "automated-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A0F251320>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.011134097, step = 5001\n",
      "INFO:tensorflow:Saving checkpoints for 5100 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.017118284.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5100\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:01:41\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5100\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:02:22\n",
      "INFO:tensorflow:Saving dict for global step 5100: global_step = 5100, loss = 1.7297435\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:02:33\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5100\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:02:47\n",
      "INFO:tensorflow:Saving dict for global step 5100: global_step = 5100, loss = 1.7693002\n",
      "我存了第0次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A41F12B38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5100\n",
      "INFO:tensorflow:Saving checkpoints for 5101 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.036168486, step = 5101\n",
      "INFO:tensorflow:Saving checkpoints for 5200 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.02111713.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A0F0CC710>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5200\n",
      "INFO:tensorflow:Saving checkpoints for 5201 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.007907595, step = 5201\n",
      "INFO:tensorflow:Saving checkpoints for 5300 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.05832271.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5300\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:04:15\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5300\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:05:00\n",
      "INFO:tensorflow:Saving dict for global step 5300: global_step = 5300, loss = 1.7620724\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:05:10\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5300\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:05:23\n",
      "INFO:tensorflow:Saving dict for global step 5300: global_step = 5300, loss = 1.8099918\n",
      "我存了第2次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A41F12BA8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5300\n",
      "INFO:tensorflow:Saving checkpoints for 5301 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.01173254, step = 5301\n",
      "INFO:tensorflow:Saving checkpoints for 5400 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.019931663.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A41A1B6D8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5400\n",
      "INFO:tensorflow:Saving checkpoints for 5401 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.013084378, step = 5401\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.027122535.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:06:52\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:07:35\n",
      "INFO:tensorflow:Saving dict for global step 5500: global_step = 5500, loss = 1.5792755\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:07:45\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:07:58\n",
      "INFO:tensorflow:Saving dict for global step 5500: global_step = 5500, loss = 1.6223388\n",
      "我存了第4次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A3D528EB8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Saving checkpoints for 5501 into ./DL_model/rnn_model\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0059621804, step = 5501\n",
      "INFO:tensorflow:Saving checkpoints for 5600 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.016434975.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A46A53B38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5600\n",
      "INFO:tensorflow:Saving checkpoints for 5601 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0073946323, step = 5601\n",
      "INFO:tensorflow:Saving checkpoints for 5700 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.016385108.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5700\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:09:25\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5700\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:10:06\n",
      "INFO:tensorflow:Saving dict for global step 5700: global_step = 5700, loss = 1.6984601\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:10:16\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5700\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:10:30\n",
      "INFO:tensorflow:Saving dict for global step 5700: global_step = 5700, loss = 1.7421048\n",
      "我存了第6次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A3BD81208>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5700\n",
      "INFO:tensorflow:Saving checkpoints for 5701 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0051681027, step = 5701\n",
      "INFO:tensorflow:Saving checkpoints for 5800 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015718877.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A42BCC550>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5800\n",
      "INFO:tensorflow:Saving checkpoints for 5801 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0037483706, step = 5801\n",
      "INFO:tensorflow:Saving checkpoints for 5900 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015966058.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5900\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:11:52\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5900\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:12:34\n",
      "INFO:tensorflow:Saving dict for global step 5900: global_step = 5900, loss = 1.8297547\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:12:43\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5900\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:12:57\n",
      "INFO:tensorflow:Saving dict for global step 5900: global_step = 5900, loss = 1.8771957\n",
      "我存了第8次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A471AB400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5900\n",
      "INFO:tensorflow:Saving checkpoints for 5901 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0041372804, step = 5901\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015917799.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A0F43FE10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0035944774, step = 6001\n",
      "INFO:tensorflow:Saving checkpoints for 6100 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015807923.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6100\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:14:22\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6100\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:15:07\n",
      "INFO:tensorflow:Saving dict for global step 6100: global_step = 6100, loss = 1.9060384\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:15:19\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6100\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:15:33\n",
      "INFO:tensorflow:Saving dict for global step 6100: global_step = 6100, loss = 1.9573623\n",
      "我存了第10次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A4815BF98>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6100\n",
      "INFO:tensorflow:Saving checkpoints for 6101 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0035379804, step = 6101\n",
      "INFO:tensorflow:Saving checkpoints for 6200 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015610561.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A47466438>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6200\n",
      "INFO:tensorflow:Saving checkpoints for 6201 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0035714125, step = 6201\n",
      "INFO:tensorflow:Saving checkpoints for 6300 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.017943554.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6300\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:16:58\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6300\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:17:42\n",
      "INFO:tensorflow:Saving dict for global step 6300: global_step = 6300, loss = 1.9562646\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:17:52\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6300\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:18:04\n",
      "INFO:tensorflow:Saving dict for global step 6300: global_step = 6300, loss = 2.0111754\n",
      "我存了第12次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A447CFB70>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6300\n",
      "INFO:tensorflow:Saving checkpoints for 6301 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.004339765, step = 6301\n",
      "INFO:tensorflow:Saving checkpoints for 6400 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015873143.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A4413BA90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6400\n",
      "INFO:tensorflow:Saving checkpoints for 6401 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0036867626, step = 6401\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015708975.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6500\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:19:31\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6500\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:20:15\n",
      "INFO:tensorflow:Saving dict for global step 6500: global_step = 6500, loss = 2.002041\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:20:24\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-30f750509595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         result_rnn = result_rnn.append({\"loss_test\":loss_test[\"loss\"],\n\u001b[0;32m     12\u001b[0m                                                             \u001b[1;34m\"loss_train\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 instructions)\n\u001b[1;32m--> 316\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    318\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, input_fn, feed_fn, batch_size, steps, metrics, name, checkpoint_path, hooks, log_progress)\u001b[0m\n\u001b[0;32m    553\u001b[0m     \u001b[0m_verify_input_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mSKCompat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, x, y, batch_size, steps, metrics, name)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   1455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_results\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m       \u001b[0meval_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'global_step'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[1;34m(self, input_fn, steps, feed_fn, metrics, name, checkpoint_path, hooks, log_progress)\u001b[0m\n\u001b[0;32m    882\u001b[0m           \u001b[0mfinal_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m           config=self._session_config)\n\u001b[0m\u001b[0;32m    885\u001b[0m       \u001b[0mcurrent_global_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mglobal_step_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[1;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    893\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    classifier2=learn.Estimator(model_fn=model_fn,model_dir='./DL_model/rnn_model')\n",
    "    #Train and predict\n",
    "    classifier2_skl = learn.SKCompat(classifier2)\n",
    "    classifier2_skl.fit(x_train,y_train,steps=100)\n",
    "    if i%2==0 :\n",
    "        y_predicted=classifier2_skl.predict(x_test)['class']\n",
    "        score=metrics.accuracy_score(y_test,y_predicted)\n",
    "        loss_train = classifier2.evaluate(x_train,y_train)\n",
    "        loss_test = classifier2.evaluate(x_test,y_test) \n",
    "        result_rnn = result_rnn.append({\"loss_test\":loss_test[\"loss\"],\n",
    "                                                            \"loss_train\":loss_train[\"loss\"],\n",
    "                                                            \"score\":score,\n",
    "                                                            \"step\":loss_train[\"global_step\"]\n",
    "                                                            },ignore_index=True)\n",
    "        result_rnn.to_csv(\"./DL_model/rnn_loss.csv\",index=False)\n",
    "        print(\"我存了第%d次\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "biblical-editing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.689098</td>\n",
       "      <td>0.689096</td>\n",
       "      <td>0.551554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.650221</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>0.678445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.602337</td>\n",
       "      <td>0.616072</td>\n",
       "      <td>0.747839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.857544</td>\n",
       "      <td>0.878631</td>\n",
       "      <td>0.739936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900.0</td>\n",
       "      <td>1.052216</td>\n",
       "      <td>1.078539</td>\n",
       "      <td>0.737479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.091040</td>\n",
       "      <td>1.120810</td>\n",
       "      <td>0.736117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>1.207862</td>\n",
       "      <td>1.241585</td>\n",
       "      <td>0.733121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.322826</td>\n",
       "      <td>1.363286</td>\n",
       "      <td>0.732911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1700.0</td>\n",
       "      <td>1.323175</td>\n",
       "      <td>1.364141</td>\n",
       "      <td>0.733419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900.0</td>\n",
       "      <td>1.303353</td>\n",
       "      <td>1.334746</td>\n",
       "      <td>0.726668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2100.0</td>\n",
       "      <td>1.400095</td>\n",
       "      <td>1.435923</td>\n",
       "      <td>0.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2300.0</td>\n",
       "      <td>1.349991</td>\n",
       "      <td>1.385149</td>\n",
       "      <td>0.722003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>1.572923</td>\n",
       "      <td>1.613785</td>\n",
       "      <td>0.729350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2700.0</td>\n",
       "      <td>1.607881</td>\n",
       "      <td>1.652217</td>\n",
       "      <td>0.726644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2900.0</td>\n",
       "      <td>1.629199</td>\n",
       "      <td>1.674930</td>\n",
       "      <td>0.722728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3100.0</td>\n",
       "      <td>1.380606</td>\n",
       "      <td>1.416057</td>\n",
       "      <td>0.723397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3300.0</td>\n",
       "      <td>1.501900</td>\n",
       "      <td>1.539920</td>\n",
       "      <td>0.732589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>1.615683</td>\n",
       "      <td>1.657292</td>\n",
       "      <td>0.728537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3700.0</td>\n",
       "      <td>1.690008</td>\n",
       "      <td>1.735754</td>\n",
       "      <td>0.727763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3900.0</td>\n",
       "      <td>1.795067</td>\n",
       "      <td>1.846130</td>\n",
       "      <td>0.727739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4100.0</td>\n",
       "      <td>1.848376</td>\n",
       "      <td>1.902008</td>\n",
       "      <td>0.727473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4300.0</td>\n",
       "      <td>1.884592</td>\n",
       "      <td>1.937628</td>\n",
       "      <td>0.728674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>1.917674</td>\n",
       "      <td>1.969267</td>\n",
       "      <td>0.726909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4700.0</td>\n",
       "      <td>1.387980</td>\n",
       "      <td>1.425044</td>\n",
       "      <td>0.726031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4900.0</td>\n",
       "      <td>1.489746</td>\n",
       "      <td>1.531501</td>\n",
       "      <td>0.729858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5100.0</td>\n",
       "      <td>1.729743</td>\n",
       "      <td>1.769300</td>\n",
       "      <td>0.728521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5300.0</td>\n",
       "      <td>1.762072</td>\n",
       "      <td>1.809992</td>\n",
       "      <td>0.722575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5500.0</td>\n",
       "      <td>1.579275</td>\n",
       "      <td>1.622339</td>\n",
       "      <td>0.727562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5700.0</td>\n",
       "      <td>1.698460</td>\n",
       "      <td>1.742105</td>\n",
       "      <td>0.726611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5900.0</td>\n",
       "      <td>1.829755</td>\n",
       "      <td>1.877196</td>\n",
       "      <td>0.727715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6100.0</td>\n",
       "      <td>1.906038</td>\n",
       "      <td>1.957362</td>\n",
       "      <td>0.727361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6300.0</td>\n",
       "      <td>1.956265</td>\n",
       "      <td>2.011175</td>\n",
       "      <td>0.727385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step  loss_train  loss_test     score\n",
       "0    100.0    0.689098   0.689096  0.551554\n",
       "1    300.0    0.650221   0.650369  0.678445\n",
       "2    500.0    0.602337   0.616072  0.747839\n",
       "3    700.0    0.857544   0.878631  0.739936\n",
       "4    900.0    1.052216   1.078539  0.737479\n",
       "5   1100.0    1.091040   1.120810  0.736117\n",
       "6   1300.0    1.207862   1.241585  0.733121\n",
       "7   1500.0    1.322826   1.363286  0.732911\n",
       "8   1700.0    1.323175   1.364141  0.733419\n",
       "9   1900.0    1.303353   1.334746  0.726668\n",
       "10  2100.0    1.400095   1.435923  0.723300\n",
       "11  2300.0    1.349991   1.385149  0.722003\n",
       "12  2500.0    1.572923   1.613785  0.729350\n",
       "13  2700.0    1.607881   1.652217  0.726644\n",
       "14  2900.0    1.629199   1.674930  0.722728\n",
       "15  3100.0    1.380606   1.416057  0.723397\n",
       "16  3300.0    1.501900   1.539920  0.732589\n",
       "17  3500.0    1.615683   1.657292  0.728537\n",
       "18  3700.0    1.690008   1.735754  0.727763\n",
       "19  3900.0    1.795067   1.846130  0.727739\n",
       "20  4100.0    1.848376   1.902008  0.727473\n",
       "21  4300.0    1.884592   1.937628  0.728674\n",
       "22  4500.0    1.917674   1.969267  0.726909\n",
       "23  4700.0    1.387980   1.425044  0.726031\n",
       "24  4900.0    1.489746   1.531501  0.729858\n",
       "25  5100.0    1.729743   1.769300  0.728521\n",
       "26  5300.0    1.762072   1.809992  0.722575\n",
       "27  5500.0    1.579275   1.622339  0.727562\n",
       "28  5700.0    1.698460   1.742105  0.726611\n",
       "29  5900.0    1.829755   1.877196  0.727715\n",
       "30  6100.0    1.906038   1.957362  0.727361\n",
       "31  6300.0    1.956265   2.011175  0.727385"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rnn=pd.read_csv(\"./DL_model/rnn_loss.csv\")\n",
    "result_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vietnamese-algebra",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b92e778e4149>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nlike'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'好精彩的电影！'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'烂片啊！'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-b92e778e4149>\u001b[0m in \u001b[0;36mpred\u001b[1;34m(commment)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcommment\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unknown'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx_tt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_text' is not defined"
     ]
    }
   ],
   "source": [
    "def pred(commment):\n",
    "    sentences=[]\n",
    "    preprocess_text([commment] ,sentences, 'unknown')\n",
    "    x,y=zip(*sentences)\n",
    "    x_tt = np.array(list(vocab_processor.transform([x[0]])))\n",
    "    \n",
    "    if classifier.predict(x_tt)['class'][0]:\n",
    "        print('like')\n",
    "    else:\n",
    "        print('nlike')\n",
    "pred('好精彩的电影！')\n",
    "pred('烂片啊！')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
