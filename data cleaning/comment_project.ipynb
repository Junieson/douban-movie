{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amazing-beijing",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "peaceful-compression",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba   # 分词包\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyecharts.charts import Bar,Grid,Line,Pie\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.globals import ThemeType\n",
    "from pyecharts.commons.utils import JsCode\n",
    "from wordcloud import WordCloud # 词云包\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-initial",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 数据读取和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prepared-bristol",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movies_b = pd.read_csv(\"movies_piaofang.csv\")\n",
    "movies_m = pd.read_csv(\"movies_pingfen.csv\")\n",
    "movies = pd.concat([movies_b,movies_m]).drop_duplicates(subset=\"movie_id\").reset_index(drop=True)\n",
    "movies['movie_id'] = movies['movie_id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dried-fossil",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>box_office</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>directedBy</th>\n",
       "      <th>starring</th>\n",
       "      <th>genre</th>\n",
       "      <th>runtime</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>rating_num</th>\n",
       "      <th>vote_num</th>\n",
       "      <th>rating_per_stars5</th>\n",
       "      <th>rating_per_stars4</th>\n",
       "      <th>rating_per_stars3</th>\n",
       "      <th>rating_per_stars2</th>\n",
       "      <th>rating_per_stars1</th>\n",
       "      <th>intro</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>question_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27978.0</td>\n",
       "      <td>26100958</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>2019</td>\n",
       "      <td>['安东尼·罗素', '乔·罗素']</td>\n",
       "      <td>['小罗伯特·唐尼', '克里斯·埃文斯', '马克·鲁弗洛', '克里斯·海姆斯沃斯', ...</td>\n",
       "      <td>['剧情', '动作', '科幻', '奇幻', '冒险']</td>\n",
       "      <td>181</td>\n",
       "      <td>美国</td>\n",
       "      <td>英语 / 日语 / 科萨语</td>\n",
       "      <td>8.5</td>\n",
       "      <td>923023</td>\n",
       "      <td>46.1</td>\n",
       "      <td>35.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>一声响指，宇宙间半数生命灰飞烟灭。几近绝望的复仇者们在惊奇队长（布丽·拉尔森 Brie La...</td>\n",
       "      <td>314581</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27897.0</td>\n",
       "      <td>1652587</td>\n",
       "      <td>阿凡达 Avatar</td>\n",
       "      <td>2009</td>\n",
       "      <td>['詹姆斯·卡梅隆']</td>\n",
       "      <td>['萨姆·沃辛顿', '佐伊·索尔达娜', '西格妮·韦弗', '史蒂芬·朗', '米歇尔·...</td>\n",
       "      <td>['动作', '科幻', '冒险']</td>\n",
       "      <td>162</td>\n",
       "      <td>美国 / 英国</td>\n",
       "      <td>英语 / 西班牙语</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1046959</td>\n",
       "      <td>50.8</td>\n",
       "      <td>36.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>战斗中负伤而下身瘫痪的前海军战士杰克•萨利（萨姆•沃辛顿 Sam Worthington 饰...</td>\n",
       "      <td>206783</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21875.0</td>\n",
       "      <td>1292722</td>\n",
       "      <td>泰坦尼克号 Titanic</td>\n",
       "      <td>1997</td>\n",
       "      <td>['詹姆斯·卡梅隆']</td>\n",
       "      <td>['莱昂纳多·迪卡普里奥', '凯特·温丝莱特', '比利·赞恩', '凯西·贝茨', '弗...</td>\n",
       "      <td>['剧情', '爱情', '灾难']</td>\n",
       "      <td>194</td>\n",
       "      <td>美国</td>\n",
       "      <td>英语 / 意大利语 / 德语 / 俄语</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1693601</td>\n",
       "      <td>75.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1912年4月10日，号称 “世界工业史上的奇迹”的豪华客轮泰坦尼克号开始了自己的处女航，从...</td>\n",
       "      <td>328281</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20682.0</td>\n",
       "      <td>20326665</td>\n",
       "      <td>星球大战7：原力觉醒 Star Wars: The Force Awakens</td>\n",
       "      <td>2015</td>\n",
       "      <td>['J·J·艾布拉姆斯']</td>\n",
       "      <td>['哈里森·福特', '马克·哈米尔', '凯丽·费雪', '亚当·德赖弗', '黛西·雷德...</td>\n",
       "      <td>['动作', '科幻', '冒险']</td>\n",
       "      <td>135</td>\n",
       "      <td>美国</td>\n",
       "      <td>英语</td>\n",
       "      <td>7.2</td>\n",
       "      <td>196795</td>\n",
       "      <td>14.2</td>\n",
       "      <td>38.8</td>\n",
       "      <td>39.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>自从银河帝国衰败之后，正邪轮回再度开始，第一秩序的黑暗力量蔓延滋长，重新为银河系带来威胁。与...</td>\n",
       "      <td>60634</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20484.0</td>\n",
       "      <td>24773958</td>\n",
       "      <td>复仇者联盟3：无限战争 Avengers: Infinity War</td>\n",
       "      <td>2018</td>\n",
       "      <td>['安东尼·罗素', '乔·罗素']</td>\n",
       "      <td>['小罗伯特·唐尼', '克里斯·海姆斯沃斯', '克里斯·埃文斯', '马克·鲁弗洛', ...</td>\n",
       "      <td>['动作', '科幻', '奇幻', '冒险']</td>\n",
       "      <td>149</td>\n",
       "      <td>美国</td>\n",
       "      <td>英语</td>\n",
       "      <td>8.1</td>\n",
       "      <td>695008</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>最先与灭霸军团遭遇的雷神索尔一行遭遇惨烈打击，洛基遇害，空间宝石落入灭霸之手。未几，灭霸的先...</td>\n",
       "      <td>226207</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1308575</td>\n",
       "      <td>蓝色大门 藍色大門</td>\n",
       "      <td>2002</td>\n",
       "      <td>['易智言']</td>\n",
       "      <td>['陈柏霖', '桂纶镁', '梁又琳', '仇政', '明金成', '林贤能', '黄江丰...</td>\n",
       "      <td>['剧情', '爱情', '同性']</td>\n",
       "      <td>85</td>\n",
       "      <td>台湾 / 法国</td>\n",
       "      <td>汉语普通话</td>\n",
       "      <td>8.3</td>\n",
       "      <td>264174</td>\n",
       "      <td>35.3</td>\n",
       "      <td>44.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>高中生孟克柔（桂纶镁 饰）与林月珍（梁淑慧饰）是无话不谈的好友，月珍告诉克柔，说自己喜欢上了...</td>\n",
       "      <td>68627</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2053515</td>\n",
       "      <td>曾经 Once</td>\n",
       "      <td>2007</td>\n",
       "      <td>['约翰·卡尼']</td>\n",
       "      <td>['格伦·汉塞德', '玛可塔·伊尔格洛娃']</td>\n",
       "      <td>['剧情', '爱情', '音乐']</td>\n",
       "      <td>85</td>\n",
       "      <td>爱尔兰</td>\n",
       "      <td>英语 / 捷克语</td>\n",
       "      <td>8.3</td>\n",
       "      <td>195666</td>\n",
       "      <td>38.1</td>\n",
       "      <td>42.3</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>这是一部由音乐开启的爱尔兰电影。　卖花女（Marketa Irglova）被街头艺人（Gle...</td>\n",
       "      <td>59606</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1292217</td>\n",
       "      <td>穆赫兰道 Mulholland Dr.</td>\n",
       "      <td>2001</td>\n",
       "      <td>['大卫·林奇']</td>\n",
       "      <td>['娜奥米·沃茨', '劳拉·哈灵', '安·米勒', '贾斯汀·塞洛克斯', '斯科特·科...</td>\n",
       "      <td>['剧情', '悬疑', '惊悚']</td>\n",
       "      <td>147</td>\n",
       "      <td>法国 / 美国</td>\n",
       "      <td>英语 / 西班牙语</td>\n",
       "      <td>8.3</td>\n",
       "      <td>224077</td>\n",
       "      <td>41.9</td>\n",
       "      <td>38.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>深夜的穆赫兰道发生一桩车祸，女子丽塔（劳拉·赫利 Laura Harring 饰）在车祸中失...</td>\n",
       "      <td>75866</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3011051</td>\n",
       "      <td>恐怖游轮 Triangle</td>\n",
       "      <td>2009</td>\n",
       "      <td>['克里斯托弗·史密斯']</td>\n",
       "      <td>['梅利莎·乔治', '利亚姆·海姆斯沃斯', '迈克尔·多曼', '瑞秋·卡帕尼', '艾...</td>\n",
       "      <td>['剧情', '悬疑', '惊悚']</td>\n",
       "      <td>99</td>\n",
       "      <td>英国 / 澳大利亚</td>\n",
       "      <td>英语</td>\n",
       "      <td>8.3</td>\n",
       "      <td>303980</td>\n",
       "      <td>36.8</td>\n",
       "      <td>44.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>单亲母亲杰西（梅利莎·乔治 饰）和一帮朋友乘游艇出海游玩，但她总有一种有不好的事情发生的感觉...</td>\n",
       "      <td>90752</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1862151</td>\n",
       "      <td>疯狂的石头</td>\n",
       "      <td>2006</td>\n",
       "      <td>['宁浩']</td>\n",
       "      <td>['郭涛', '刘桦', '连晋', '黄渤', '徐峥', '优恵', '罗兰 ', '王迅']</td>\n",
       "      <td>['喜剧', '犯罪']</td>\n",
       "      <td>106</td>\n",
       "      <td>中国大陆 / 香港</td>\n",
       "      <td>汉语普通话 / 重庆话</td>\n",
       "      <td>8.2</td>\n",
       "      <td>294114</td>\n",
       "      <td>33.5</td>\n",
       "      <td>46.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>重庆一间工艺品厂已经濒临倒闭，却不料在拆倒旧厂房的时候，发现了厕所里的一件宝物——一块价值连...</td>\n",
       "      <td>40292</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     box_office  movie_id                              movie_title  \\\n",
       "0       27978.0  26100958            复仇者联盟4：终局之战 Avengers: Endgame   \n",
       "1       27897.0   1652587                               阿凡达 Avatar   \n",
       "2       21875.0   1292722                            泰坦尼克号 Titanic   \n",
       "3       20682.0  20326665  星球大战7：原力觉醒 Star Wars: The Force Awakens   \n",
       "4       20484.0  24773958       复仇者联盟3：无限战争 Avengers: Infinity War   \n",
       "..          ...       ...                                      ...   \n",
       "459         NaN   1308575                                蓝色大门 藍色大門   \n",
       "460         NaN   2053515                                  曾经 Once   \n",
       "461         NaN   1292217                      穆赫兰道 Mulholland Dr.   \n",
       "462         NaN   3011051                            恐怖游轮 Triangle   \n",
       "463         NaN   1862151                                    疯狂的石头   \n",
       "\n",
       "     release_date          directedBy  \\\n",
       "0            2019  ['安东尼·罗素', '乔·罗素']   \n",
       "1            2009         ['詹姆斯·卡梅隆']   \n",
       "2            1997         ['詹姆斯·卡梅隆']   \n",
       "3            2015       ['J·J·艾布拉姆斯']   \n",
       "4            2018  ['安东尼·罗素', '乔·罗素']   \n",
       "..            ...                 ...   \n",
       "459          2002             ['易智言']   \n",
       "460          2007           ['约翰·卡尼']   \n",
       "461          2001           ['大卫·林奇']   \n",
       "462          2009       ['克里斯托弗·史密斯']   \n",
       "463          2006              ['宁浩']   \n",
       "\n",
       "                                              starring  \\\n",
       "0    ['小罗伯特·唐尼', '克里斯·埃文斯', '马克·鲁弗洛', '克里斯·海姆斯沃斯', ...   \n",
       "1    ['萨姆·沃辛顿', '佐伊·索尔达娜', '西格妮·韦弗', '史蒂芬·朗', '米歇尔·...   \n",
       "2    ['莱昂纳多·迪卡普里奥', '凯特·温丝莱特', '比利·赞恩', '凯西·贝茨', '弗...   \n",
       "3    ['哈里森·福特', '马克·哈米尔', '凯丽·费雪', '亚当·德赖弗', '黛西·雷德...   \n",
       "4    ['小罗伯特·唐尼', '克里斯·海姆斯沃斯', '克里斯·埃文斯', '马克·鲁弗洛', ...   \n",
       "..                                                 ...   \n",
       "459  ['陈柏霖', '桂纶镁', '梁又琳', '仇政', '明金成', '林贤能', '黄江丰...   \n",
       "460                            ['格伦·汉塞德', '玛可塔·伊尔格洛娃']   \n",
       "461  ['娜奥米·沃茨', '劳拉·哈灵', '安·米勒', '贾斯汀·塞洛克斯', '斯科特·科...   \n",
       "462  ['梅利莎·乔治', '利亚姆·海姆斯沃斯', '迈克尔·多曼', '瑞秋·卡帕尼', '艾...   \n",
       "463  ['郭涛', '刘桦', '连晋', '黄渤', '徐峥', '优恵', '罗兰 ', '王迅']   \n",
       "\n",
       "                              genre  runtime    country             language  \\\n",
       "0    ['剧情', '动作', '科幻', '奇幻', '冒险']      181         美国        英语 / 日语 / 科萨语   \n",
       "1                ['动作', '科幻', '冒险']      162    美国 / 英国            英语 / 西班牙语   \n",
       "2                ['剧情', '爱情', '灾难']      194         美国  英语 / 意大利语 / 德语 / 俄语   \n",
       "3                ['动作', '科幻', '冒险']      135         美国                   英语   \n",
       "4          ['动作', '科幻', '奇幻', '冒险']      149         美国                   英语   \n",
       "..                              ...      ...        ...                  ...   \n",
       "459              ['剧情', '爱情', '同性']       85    台湾 / 法国                汉语普通话   \n",
       "460              ['剧情', '爱情', '音乐']       85        爱尔兰             英语 / 捷克语   \n",
       "461              ['剧情', '悬疑', '惊悚']      147    法国 / 美国            英语 / 西班牙语   \n",
       "462              ['剧情', '悬疑', '惊悚']       99  英国 / 澳大利亚                   英语   \n",
       "463                    ['喜剧', '犯罪']      106  中国大陆 / 香港          汉语普通话 / 重庆话   \n",
       "\n",
       "     rating_num  vote_num  rating_per_stars5  rating_per_stars4  \\\n",
       "0           8.5    923023               46.1               35.7   \n",
       "1           8.7   1046959               50.8               36.7   \n",
       "2           9.4   1693601               75.0               21.5   \n",
       "3           7.2    196795               14.2               38.8   \n",
       "4           8.1    695008               33.0               44.1   \n",
       "..          ...       ...                ...                ...   \n",
       "459         8.3    264174               35.3               44.1   \n",
       "460         8.3    195666               38.1               42.3   \n",
       "461         8.3    224077               41.9               38.2   \n",
       "462         8.3    303980               36.8               44.9   \n",
       "463         8.2    294114               33.5               46.3   \n",
       "\n",
       "     rating_per_stars3  rating_per_stars2  rating_per_stars1  \\\n",
       "0                 15.6                1.9                0.8   \n",
       "1                 11.3                0.9                0.3   \n",
       "2                  3.2                0.2                0.1   \n",
       "3                 39.5                5.8                1.7   \n",
       "4                 19.7                2.3                0.8   \n",
       "..                 ...                ...                ...   \n",
       "459               18.9                1.4                0.2   \n",
       "460               17.4                1.8                0.3   \n",
       "461               15.7                2.8                1.5   \n",
       "462               16.2                1.7                0.5   \n",
       "463               18.1                1.7                0.4   \n",
       "\n",
       "                                                 intro  comment_num  \\\n",
       "0    一声响指，宇宙间半数生命灰飞烟灭。几近绝望的复仇者们在惊奇队长（布丽·拉尔森 Brie La...       314581   \n",
       "1    战斗中负伤而下身瘫痪的前海军战士杰克•萨利（萨姆•沃辛顿 Sam Worthington 饰...       206783   \n",
       "2    1912年4月10日，号称 “世界工业史上的奇迹”的豪华客轮泰坦尼克号开始了自己的处女航，从...       328281   \n",
       "3    自从银河帝国衰败之后，正邪轮回再度开始，第一秩序的黑暗力量蔓延滋长，重新为银河系带来威胁。与...        60634   \n",
       "4    最先与灭霸军团遭遇的雷神索尔一行遭遇惨烈打击，洛基遇害，空间宝石落入灭霸之手。未几，灭霸的先...       226207   \n",
       "..                                                 ...          ...   \n",
       "459  高中生孟克柔（桂纶镁 饰）与林月珍（梁淑慧饰）是无话不谈的好友，月珍告诉克柔，说自己喜欢上了...        68627   \n",
       "460  这是一部由音乐开启的爱尔兰电影。　卖花女（Marketa Irglova）被街头艺人（Gle...        59606   \n",
       "461  深夜的穆赫兰道发生一桩车祸，女子丽塔（劳拉·赫利 Laura Harring 饰）在车祸中失...        75866   \n",
       "462  单亲母亲杰西（梅利莎·乔治 饰）和一帮朋友乘游艇出海游玩，但她总有一种有不好的事情发生的感觉...        90752   \n",
       "463  重庆一间工艺品厂已经濒临倒闭，却不料在拆倒旧厂房的时候，发现了厕所里的一件宝物——一块价值连...        40292   \n",
       "\n",
       "     question_num  \n",
       "0             174  \n",
       "1              17  \n",
       "2              23  \n",
       "3             122  \n",
       "4             105  \n",
       "..            ...  \n",
       "459            23  \n",
       "460            16  \n",
       "461            39  \n",
       "462           119  \n",
       "463            10  \n",
       "\n",
       "[464 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naked-teddy",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 导入、分词、去停用词\n",
    "def lcut(Intro_movie):\n",
    "    segment=[]\n",
    "    segs = jieba.lcut(Intro_movie) # 将一段话分成词语列表\n",
    "    for seg in segs:# 单个子的去除\n",
    "        if len(seg)>1 and seg!='\\r\\n':\n",
    "            segment.append(seg)\n",
    "    return segment\n",
    "\n",
    "stopwords = pd.read_csv(\"stopwords.txt\" \n",
    "                  ,index_col=False\n",
    "                  ,quoting=3\n",
    "                  ,sep=\"\\t\"\n",
    "                  ,names=['stopword']\n",
    "                  ,encoding='utf-8') # quoting=3 全不引用    \n",
    "\n",
    "def dropstopword(segment):\n",
    "    # 去停用词,停用词是指在信息检索中，为节省存储空间和提高搜索效率，在处理自然语言数据（或文本）之前或之后会自动过滤掉某些字或词，这些字或词即被称为Stop Words（停用词）\n",
    "    words_df = pd.DataFrame({'segment':segment})\n",
    "\n",
    "    #stopwords.head()\n",
    "    return words_df[~words_df.segment.isin(stopwords.stopword)].segment.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disabled-florida",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # 基于TextRank算法的关键词抽取(仅动词和动名词)\n",
    "import jieba.analyse as analyse\n",
    "\n",
    "# movies_b['keywords'] = movies_b.intro.apply(lcut)\\\n",
    "#                 .apply(dropstopword)\\\n",
    "#                 .apply(lambda x : \" \".join(x))\\\n",
    "#                 .apply(lambda x:\" \".join(analyse.textrank(x, topK=8, withWeight=False, allowPOS=('n','vn', 'v','a','z'))))\n",
    "# movies_b.sort_values('rating_num', ascending=False)[['movie_title','keywords']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "formed-alias",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\11514\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.701 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>灭霸 复仇者 队长 宇宙 无限 响指 冰释 找到</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>阿凡达 Avatar</td>\n",
       "      <td>最佳 部落 人类基因 西格 视觉效果 混血 电影史 砍伐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>泰坦尼克号 Titanic</td>\n",
       "      <td>处女航 温丝 头等舱 投海 未婚夫 船票 驶往 救起</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>星球大战7：原力觉醒 Star Wars: The Force Awakens</td>\n",
       "      <td>军团 秩序 地图 天行者 死星 星者 原力 蛮荒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>复仇者联盟3：无限战争 Avengers: Infinity War</td>\n",
       "      <td>灭霸 星爵 落入 阻止 蜘蛛侠 遭遇 外星 幻视</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>侏罗纪世界 Jurassic World</td>\n",
       "      <td>暴虐 游客 吸引 生物 速度 骗过 惨剧 精密仪器</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>狮子王 The Lion King</td>\n",
       "      <td>配音 木法 刀疤 王位 迎来 肉中刺 奋进 国度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>复仇者联盟 The Avengers</td>\n",
       "      <td>地球 复仇者 鹰眼 发威 抵挡 指挥官 侵袭 致命</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>速度与激情7 Furious 7</td>\n",
       "      <td>复仇 探长 对决 世外桃源 死对头 干掉 利刃 王牌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>冰雪奇缘2 Frozen II</td>\n",
       "      <td>配音 公主 魔法 吟唱 征途 旅程 丧生 追寻</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie_title                      keywords\n",
       "0            复仇者联盟4：终局之战 Avengers: Endgame      灭霸 复仇者 队长 宇宙 无限 响指 冰释 找到\n",
       "1                               阿凡达 Avatar  最佳 部落 人类基因 西格 视觉效果 混血 电影史 砍伐\n",
       "2                            泰坦尼克号 Titanic    处女航 温丝 头等舱 投海 未婚夫 船票 驶往 救起\n",
       "3  星球大战7：原力觉醒 Star Wars: The Force Awakens      军团 秩序 地图 天行者 死星 星者 原力 蛮荒\n",
       "4       复仇者联盟3：无限战争 Avengers: Infinity War      灭霸 星爵 落入 阻止 蜘蛛侠 遭遇 外星 幻视\n",
       "5                     侏罗纪世界 Jurassic World     暴虐 游客 吸引 生物 速度 骗过 惨剧 精密仪器\n",
       "6                        狮子王 The Lion King      配音 木法 刀疤 王位 迎来 肉中刺 奋进 国度\n",
       "7                       复仇者联盟 The Avengers     地球 复仇者 鹰眼 发威 抵挡 指挥官 侵袭 致命\n",
       "8                         速度与激情7 Furious 7    复仇 探长 对决 世外桃源 死对头 干掉 利刃 王牌\n",
       "9                          冰雪奇缘2 Frozen II       配音 公主 魔法 吟唱 征途 旅程 丧生 追寻"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_b['keywords'] = movies_b.intro.apply(lcut)\\\n",
    "                .apply(dropstopword)\\\n",
    "                .apply(lambda x : \" \".join(x))\\\n",
    "                .apply(lambda x:\" \".join(analyse.extract_tags(x, topK=8, withWeight=False, allowPOS=('n' ,'v','z'))))\n",
    "movies_b.sort_values('box_office', ascending=False)[['movie_title','keywords']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "global-mileage",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>灭霸 复仇者 队长 宇宙 无限 响指 冰释 找到</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>阿凡达 Avatar</td>\n",
       "      <td>最佳 部落 人类基因 西格 视觉效果 混血 电影史 砍伐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>泰坦尼克号 Titanic</td>\n",
       "      <td>处女航 温丝 头等舱 投海 未婚夫 船票 驶往 救起</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>星球大战7：原力觉醒 Star Wars: The Force Awakens</td>\n",
       "      <td>军团 秩序 地图 天行者 死星 星者 原力 蛮荒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>复仇者联盟3：无限战争 Avengers: Infinity War</td>\n",
       "      <td>灭霸 星爵 落入 阻止 蜘蛛侠 遭遇 外星 幻视</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>侏罗纪世界 Jurassic World</td>\n",
       "      <td>暴虐 游客 吸引 生物 速度 骗过 惨剧 精密仪器</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>狮子王 The Lion King</td>\n",
       "      <td>配音 木法 刀疤 王位 迎来 肉中刺 奋进 国度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>复仇者联盟 The Avengers</td>\n",
       "      <td>地球 复仇者 鹰眼 发威 抵挡 指挥官 侵袭 致命</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>速度与激情7 Furious 7</td>\n",
       "      <td>复仇 探长 对决 世外桃源 死对头 干掉 利刃 王牌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>冰雪奇缘2 Frozen II</td>\n",
       "      <td>配音 公主 魔法 吟唱 征途 旅程 丧生 追寻</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie_title                      keywords\n",
       "0            复仇者联盟4：终局之战 Avengers: Endgame      灭霸 复仇者 队长 宇宙 无限 响指 冰释 找到\n",
       "1                               阿凡达 Avatar  最佳 部落 人类基因 西格 视觉效果 混血 电影史 砍伐\n",
       "2                            泰坦尼克号 Titanic    处女航 温丝 头等舱 投海 未婚夫 船票 驶往 救起\n",
       "3  星球大战7：原力觉醒 Star Wars: The Force Awakens      军团 秩序 地图 天行者 死星 星者 原力 蛮荒\n",
       "4       复仇者联盟3：无限战争 Avengers: Infinity War      灭霸 星爵 落入 阻止 蜘蛛侠 遭遇 外星 幻视\n",
       "5                     侏罗纪世界 Jurassic World     暴虐 游客 吸引 生物 速度 骗过 惨剧 精密仪器\n",
       "6                        狮子王 The Lion King      配音 木法 刀疤 王位 迎来 肉中刺 奋进 国度\n",
       "7                       复仇者联盟 The Avengers     地球 复仇者 鹰眼 发威 抵挡 指挥官 侵袭 致命\n",
       "8                         速度与激情7 Furious 7    复仇 探长 对决 世外桃源 死对头 干掉 利刃 王牌\n",
       "9                          冰雪奇缘2 Frozen II       配音 公主 魔法 吟唱 征途 旅程 丧生 追寻"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_b['keywords'] = movies_b.intro.apply(lcut)\\\n",
    "                .apply(dropstopword)\\\n",
    "                .apply(lambda x : \" \".join(x))\\\n",
    "                .apply(lambda x:\" \".join(analyse.extract_tags(x, topK=8, withWeight=False, allowPOS=('n' ,'v','z'))))\n",
    "movies_b.sort_values('box_office', ascending=False)[['movie_title','keywords']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beneficial-composer",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x240e6c76ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keywords= movies_b.intro.apply(lcut)\\\n",
    "                .apply(dropstopword)\\\n",
    "                .apply(lambda x : \" \".join(x))\\\n",
    "                .apply(lambda x: (analyse.extract_tags(x, topK=50, withWeight=True)))\n",
    "word_fre  = {x:y for x, y in keywords[0]}\n",
    "cloud = WordCloud(\n",
    " # 设置字体，不指定就会出现乱码\n",
    " font_path=\"simhei.ttf\", #这个路径是pc中的字体路径\n",
    " # 设置背景色\n",
    " background_color='white',\n",
    "mode=\"RGBA\",\n",
    "    scale  =5,\n",
    " # 允许最大词汇\n",
    " max_words=200,\n",
    " # 最大号字体\n",
    " max_font_size=40\n",
    ")\n",
    "wc = cloud.fit_words(word_fre)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "functioning-error",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_json(\"../data/top_office/movie_comment20.json\", lines=True,encoding='utf-8')\n",
    "data2 = pd.read_json(\"../data/top_office/movie_comment40.json\", lines=True,encoding='utf-8')\n",
    "data3 = pd.read_json(\"../data/top_office/movie_comment60.json\", lines=True,encoding='utf-8')\n",
    "data4 = pd.read_json(\"../data/top_office/movie_comment80.json\", lines=True,encoding='utf-8')\n",
    "data5 = pd.read_json(\"../data/top_office/movie_comment110.json\", lines=True,encoding='utf-8')\n",
    "data6 = pd.read_json(\"../data/top_office/movie_comment140.json\", lines=True,encoding='utf-8')\n",
    "data7 = pd.read_json(\"../data/top_office/movie_comment170.json\", lines=True,encoding='utf-8')\n",
    "data8 = pd.read_json(\"../data/top_office/movie_comment200.json\", lines=True,encoding='utf-8')\n",
    "data9 = pd.read_json(\"../data/top_office/movie_comment230.json\", lines=True,encoding='utf-8')\n",
    "data10 = pd.read_json(\"../data/top_office/movie_comment250.json\", lines=True,encoding='utf-8')\n",
    "datas = [data1,data2,data3,data4,data5,data6,data7,data8,data9,data10]\n",
    "comm1 = pd.concat(datas).drop_duplicates(subset=\"comment_id\").reset_index(drop=True)\n",
    "file = ['../data/top_mark/movie_comment%s.json' %j for j in [ i for i in range(20,220,20)] +[225,250]]\n",
    "datas = []\n",
    "for sr in file:\n",
    "    datas.append(pd.read_json(sr, lines=True,encoding='utf-8'))\n",
    "comm2 = pd.concat(datas).drop_duplicates(subset=\"comment_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "super-generator",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>URL</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>useful_num</th>\n",
       "      <th>star</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "      <th>people</th>\n",
       "      <th>people_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1364011224</td>\n",
       "      <td>37274</td>\n",
       "      <td>allstar50 rating</td>\n",
       "      <td>[2019-04-24 02:23:59]</td>\n",
       "      <td>[如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的]</td>\n",
       "      <td>棠枫海</td>\n",
       "      <td>https://www.douban.com/people/146803809/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762639519</td>\n",
       "      <td>20741</td>\n",
       "      <td>allstar40 rating</td>\n",
       "      <td>[2019-04-24 00:11:06]</td>\n",
       "      <td>[我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落...</td>\n",
       "      <td>Tel</td>\n",
       "      <td>https://www.douban.com/people/164105540/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762628760</td>\n",
       "      <td>16016</td>\n",
       "      <td>allstar50 rating</td>\n",
       "      <td>[2019-04-24 00:01:17]</td>\n",
       "      <td>[托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”...</td>\n",
       "      <td>朝暮雪</td>\n",
       "      <td>https://www.douban.com/people/lingrui1995/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762741840</td>\n",
       "      <td>14352</td>\n",
       "      <td>allstar50 rating</td>\n",
       "      <td>[2019-04-24 03:05:48]</td>\n",
       "      <td>[钢铁侠成为了美队，美队活成了钢铁侠。]</td>\n",
       "      <td>Rafe</td>\n",
       "      <td>https://www.douban.com/people/Rafe0323/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762795339</td>\n",
       "      <td>12817</td>\n",
       "      <td>allstar50 rating</td>\n",
       "      <td>[2019-04-24 04:52:12]</td>\n",
       "      <td>[谁能想到是一只老鼠拯救了地球呢？]</td>\n",
       "      <td>KarSa</td>\n",
       "      <td>https://www.douban.com/people/karsa/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211506</th>\n",
       "      <td>1607471</td>\n",
       "      <td>https://movie.douban.com/subject/1607471/comme...</td>\n",
       "      <td>286579861</td>\n",
       "      <td>0</td>\n",
       "      <td>allstar30 rating</td>\n",
       "      <td>[2010-08-26 02:53:27]</td>\n",
       "      <td>[实在不想再看到凯奇哥，若是以后演老年剧可能会看看。。。]</td>\n",
       "      <td>Pixie</td>\n",
       "      <td>https://www.douban.com/people/2476087/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211507</th>\n",
       "      <td>1607471</td>\n",
       "      <td>https://movie.douban.com/subject/1607471/comme...</td>\n",
       "      <td>41780959</td>\n",
       "      <td>0</td>\n",
       "      <td>allstar30 rating</td>\n",
       "      <td>[2008-05-24 00:32:14]</td>\n",
       "      <td>[我大叔唉。。学会挤眉弄眼了。。不说了。。]</td>\n",
       "      <td>嘟小七</td>\n",
       "      <td>https://www.douban.com/people/duducool/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211508</th>\n",
       "      <td>1607471</td>\n",
       "      <td>https://movie.douban.com/subject/1607471/comme...</td>\n",
       "      <td>179414810</td>\n",
       "      <td>0</td>\n",
       "      <td>allstar30 rating</td>\n",
       "      <td>[2009-11-16 23:13:51]</td>\n",
       "      <td>[和前作相比没有新意]</td>\n",
       "      <td>木木茶</td>\n",
       "      <td>https://www.douban.com/people/mumucha/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211509</th>\n",
       "      <td>1607471</td>\n",
       "      <td>https://movie.douban.com/subject/1607471/comme...</td>\n",
       "      <td>200315884</td>\n",
       "      <td>0</td>\n",
       "      <td>allstar30 rating</td>\n",
       "      <td>[2010-01-08 20:33:23]</td>\n",
       "      <td>[只能是还行。。CAGE的演技很牛逼]</td>\n",
       "      <td>我真不是大雁</td>\n",
       "      <td>https://www.douban.com/people/ez2dier/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211510</th>\n",
       "      <td>1607471</td>\n",
       "      <td>https://movie.douban.com/subject/1607471/comme...</td>\n",
       "      <td>77125780</td>\n",
       "      <td>0</td>\n",
       "      <td>allstar30 rating</td>\n",
       "      <td>[2008-12-04 19:17:07]</td>\n",
       "      <td>[一般大片]</td>\n",
       "      <td>冬贝与9-13刺青</td>\n",
       "      <td>https://www.douban.com/people/tattoo9-13/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211511 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        movie_id                                                URL  \\\n",
       "0       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "1       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "2       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "3       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "4       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "...          ...                                                ...   \n",
       "211506   1607471  https://movie.douban.com/subject/1607471/comme...   \n",
       "211507   1607471  https://movie.douban.com/subject/1607471/comme...   \n",
       "211508   1607471  https://movie.douban.com/subject/1607471/comme...   \n",
       "211509   1607471  https://movie.douban.com/subject/1607471/comme...   \n",
       "211510   1607471  https://movie.douban.com/subject/1607471/comme...   \n",
       "\n",
       "        comment_id  useful_num              star                   time  \\\n",
       "0       1364011224       37274  allstar50 rating  [2019-04-24 02:23:59]   \n",
       "1       1762639519       20741  allstar40 rating  [2019-04-24 00:11:06]   \n",
       "2       1762628760       16016  allstar50 rating  [2019-04-24 00:01:17]   \n",
       "3       1762741840       14352  allstar50 rating  [2019-04-24 03:05:48]   \n",
       "4       1762795339       12817  allstar50 rating  [2019-04-24 04:52:12]   \n",
       "...            ...         ...               ...                    ...   \n",
       "211506   286579861           0  allstar30 rating  [2010-08-26 02:53:27]   \n",
       "211507    41780959           0  allstar30 rating  [2008-05-24 00:32:14]   \n",
       "211508   179414810           0  allstar30 rating  [2009-11-16 23:13:51]   \n",
       "211509   200315884           0  allstar30 rating  [2010-01-08 20:33:23]   \n",
       "211510    77125780           0  allstar30 rating  [2008-12-04 19:17:07]   \n",
       "\n",
       "                                                  content     people  \\\n",
       "0                [如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的]        棠枫海   \n",
       "1       [我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落...        Tel   \n",
       "2       [托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”...        朝暮雪   \n",
       "3                                    [钢铁侠成为了美队，美队活成了钢铁侠。]       Rafe   \n",
       "4                                      [谁能想到是一只老鼠拯救了地球呢？]      KarSa   \n",
       "...                                                   ...        ...   \n",
       "211506                      [实在不想再看到凯奇哥，若是以后演老年剧可能会看看。。。]      Pixie   \n",
       "211507                             [我大叔唉。。学会挤眉弄眼了。。不说了。。]        嘟小七   \n",
       "211508                                        [和前作相比没有新意]        木木茶   \n",
       "211509                                [只能是还行。。CAGE的演技很牛逼]     我真不是大雁   \n",
       "211510                                             [一般大片]  冬贝与9-13刺青   \n",
       "\n",
       "                                        people_url  \n",
       "0         https://www.douban.com/people/146803809/  \n",
       "1         https://www.douban.com/people/164105540/  \n",
       "2       https://www.douban.com/people/lingrui1995/  \n",
       "3          https://www.douban.com/people/Rafe0323/  \n",
       "4             https://www.douban.com/people/karsa/  \n",
       "...                                            ...  \n",
       "211506      https://www.douban.com/people/2476087/  \n",
       "211507     https://www.douban.com/people/duducool/  \n",
       "211508      https://www.douban.com/people/mumucha/  \n",
       "211509      https://www.douban.com/people/ez2dier/  \n",
       "211510   https://www.douban.com/people/tattoo9-13/  \n",
       "\n",
       "[211511 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sunrise-arthur",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comm2['movie_id'] = comm2['movie_id'].apply(lambda x: int(x[0][5:]))\n",
    "comm2['content'] = comm2.content.apply(lambda x: x[0].strip())\n",
    "# comm2['people'] = comm2.people.apply(lambda x: x.strip())\n",
    "# 用url中的名称替代\n",
    "comm2['people'] = comm2.people_url.apply(lambda x: x[30:-1])\n",
    "comm2['useful_num'] = comm2.useful_num.apply(lambda x: int(x))\n",
    "def regular_nonstar(x):\n",
    "    if x == 'comment-time':\n",
    "        return 'allstar00 rating'\n",
    "    else:\n",
    "        return x\n",
    "comm2['star'] = comm2.star.apply(regular_nonstar).apply(lambda x: int(x[7]))\n",
    "comm2['time'] = pd.to_datetime(comm2.time.apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "square-klein",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>URL</th>\n",
       "      <th>star</th>\n",
       "      <th>content</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>people</th>\n",
       "      <th>useful_num</th>\n",
       "      <th>time</th>\n",
       "      <th>people_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1292052</td>\n",
       "      <td>https://movie.douban.com/subject/1292052/comments</td>\n",
       "      <td>5</td>\n",
       "      <td>不需要女主角的好电影</td>\n",
       "      <td>2050003</td>\n",
       "      <td>kingfish</td>\n",
       "      <td>11314</td>\n",
       "      <td>2006-03-22 12:38:09</td>\n",
       "      <td>https://www.douban.com/people/kingfish/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                                URL  star  \\\n",
       "0   1292052  https://movie.douban.com/subject/1292052/comments     5   \n",
       "\n",
       "      content  comment_id    people  useful_num                time  \\\n",
       "0  不需要女主角的好电影     2050003  kingfish       11314 2006-03-22 12:38:09   \n",
       "\n",
       "                                people_url  \n",
       "0  https://www.douban.com/people/kingfish/  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quarterly-process",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comm1['movie_id'] = comm1['movie_id'].apply(lambda x: int(x))\n",
    "# comm1['content'] = comm1.content.apply(lambda x: \"\".join(x).strip())\n",
    "comm1[\"content\"] = comm1.content.apply(lambda x: \"\".join(x).strip())\n",
    "comm1['people'] = comm1.people_url.apply(lambda x: x[30:-1])\n",
    "comm1['useful_num'] = comm1.useful_num.apply(lambda x: int(x))\n",
    "comm1['star'] = comm1.star.apply(regular_nonstar).apply(lambda x: int(x[7]))\n",
    "comm1['time'] = pd.to_datetime(comm1.time.apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "convinced-disposition",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comm1.head(1)\n",
    "comm = pd.concat([comm1,comm2])\n",
    "comm = comm.drop_duplicates(subset=\"comment_id\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "excess-institution",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1292720</th>\n",
       "      <th>阿甘正传 Forrest Gump</th>\n",
       "      <td>1740.0</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.422404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291843</th>\n",
       "      <th>黑客帝国 The Matrix</th>\n",
       "      <td>1666.0</td>\n",
       "      <td>3.751501</td>\n",
       "      <td>1.347029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131459</th>\n",
       "      <th>机器人总动员 WALL·E</th>\n",
       "      <td>1665.0</td>\n",
       "      <td>3.896096</td>\n",
       "      <td>1.301124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301753</th>\n",
       "      <th>狮子王 The Lion King</th>\n",
       "      <td>1660.0</td>\n",
       "      <td>3.718675</td>\n",
       "      <td>1.360251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291552</th>\n",
       "      <th>指环王3：王者无敌 The Lord of the Rings: The Return of the King</th>\n",
       "      <td>1639.0</td>\n",
       "      <td>3.799878</td>\n",
       "      <td>1.367323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541415</th>\n",
       "      <th>盗梦空间 Inception</th>\n",
       "      <td>1639.0</td>\n",
       "      <td>3.716290</td>\n",
       "      <td>1.420475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851857</th>\n",
       "      <th>蝙蝠侠：黑暗骑士 The Dark Knight</th>\n",
       "      <td>1637.0</td>\n",
       "      <td>3.777642</td>\n",
       "      <td>1.329803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292849</th>\n",
       "      <th>拯救大兵瑞恩 Saving Private Ryan</th>\n",
       "      <td>1625.0</td>\n",
       "      <td>3.648615</td>\n",
       "      <td>1.346945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297630</th>\n",
       "      <th>第六感 The Sixth Sense</th>\n",
       "      <td>1624.0</td>\n",
       "      <td>3.717365</td>\n",
       "      <td>1.263564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295038</th>\n",
       "      <th>哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone</th>\n",
       "      <td>1619.0</td>\n",
       "      <td>3.589253</td>\n",
       "      <td>1.252403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291571</th>\n",
       "      <th>指环王1：魔戒再现 The Lord of the Rings: The Fellowship of the Ring</th>\n",
       "      <td>1618.0</td>\n",
       "      <td>3.691595</td>\n",
       "      <td>1.313341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25662329</th>\n",
       "      <th>疯狂动物城 Zootopia</th>\n",
       "      <td>1604.0</td>\n",
       "      <td>3.645885</td>\n",
       "      <td>1.353091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858711</th>\n",
       "      <th>玩具总动员3 Toy Story 3</th>\n",
       "      <td>1602.0</td>\n",
       "      <td>3.833958</td>\n",
       "      <td>1.282134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294638</th>\n",
       "      <th>E.T. 外星人 E.T.: The Extra-Terrestrial</th>\n",
       "      <td>1597.0</td>\n",
       "      <td>3.574828</td>\n",
       "      <td>1.281815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533913</th>\n",
       "      <th>头脑特工队 Inside Out</th>\n",
       "      <td>1595.0</td>\n",
       "      <td>3.645768</td>\n",
       "      <td>1.310334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298070</th>\n",
       "      <th>加勒比海盗 Pirates of the Caribbean: The Curse of the Black Pearl</th>\n",
       "      <td>1588.0</td>\n",
       "      <td>3.627204</td>\n",
       "      <td>1.234176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292722</th>\n",
       "      <th>泰坦尼克号 Titanic</th>\n",
       "      <td>1587.0</td>\n",
       "      <td>3.873346</td>\n",
       "      <td>1.411434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652587</th>\n",
       "      <th>阿凡达 Avatar</th>\n",
       "      <td>1570.0</td>\n",
       "      <td>3.668790</td>\n",
       "      <td>1.344860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353023</th>\n",
       "      <th>驯龙高手 How to Train Your Dragon</th>\n",
       "      <td>1569.0</td>\n",
       "      <td>3.697259</td>\n",
       "      <td>1.263498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929463</th>\n",
       "      <th>少年派的奇幻漂流 Life of Pi</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>3.648787</td>\n",
       "      <td>1.329641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              count      mean  \\\n",
       "movie_id movie_title                                                            \n",
       "1292720  阿甘正传 Forrest Gump                                   1740.0  3.800000   \n",
       "1291843  黑客帝国 The Matrix                                     1666.0  3.751501   \n",
       "2131459  机器人总动员 WALL·E                                       1665.0  3.896096   \n",
       "1301753  狮子王 The Lion King                                   1660.0  3.718675   \n",
       "1291552  指环王3：王者无敌 The Lord of the Rings: The Return of ...  1639.0  3.799878   \n",
       "3541415  盗梦空间 Inception                                      1639.0  3.716290   \n",
       "1851857  蝙蝠侠：黑暗骑士 The Dark Knight                            1637.0  3.777642   \n",
       "1292849  拯救大兵瑞恩 Saving Private Ryan                          1625.0  3.648615   \n",
       "1297630  第六感 The Sixth Sense                                 1624.0  3.717365   \n",
       "1295038  哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone     1619.0  3.589253   \n",
       "1291571  指环王1：魔戒再现 The Lord of the Rings: The Fellowship...  1618.0  3.691595   \n",
       "25662329 疯狂动物城 Zootopia                                      1604.0  3.645885   \n",
       "1858711  玩具总动员3 Toy Story 3                                  1602.0  3.833958   \n",
       "1294638  E.T. 外星人 E.T.: The Extra-Terrestrial                1597.0  3.574828   \n",
       "10533913 头脑特工队 Inside Out                                    1595.0  3.645768   \n",
       "1298070  加勒比海盗 Pirates of the Caribbean: The Curse of th...  1588.0  3.627204   \n",
       "1292722  泰坦尼克号 Titanic                                       1587.0  3.873346   \n",
       "1652587  阿凡达 Avatar                                          1570.0  3.668790   \n",
       "2353023  驯龙高手 How to Train Your Dragon                       1569.0  3.697259   \n",
       "1929463  少年派的奇幻漂流 Life of Pi                                 1566.0  3.648787   \n",
       "\n",
       "                                                                  std  min  \\\n",
       "movie_id movie_title                                                         \n",
       "1292720  阿甘正传 Forrest Gump                                   1.422404  0.0   \n",
       "1291843  黑客帝国 The Matrix                                     1.347029  0.0   \n",
       "2131459  机器人总动员 WALL·E                                       1.301124  0.0   \n",
       "1301753  狮子王 The Lion King                                   1.360251  0.0   \n",
       "1291552  指环王3：王者无敌 The Lord of the Rings: The Return of ...  1.367323  0.0   \n",
       "3541415  盗梦空间 Inception                                      1.420475  0.0   \n",
       "1851857  蝙蝠侠：黑暗骑士 The Dark Knight                            1.329803  0.0   \n",
       "1292849  拯救大兵瑞恩 Saving Private Ryan                          1.346945  0.0   \n",
       "1297630  第六感 The Sixth Sense                                 1.263564  0.0   \n",
       "1295038  哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone     1.252403  0.0   \n",
       "1291571  指环王1：魔戒再现 The Lord of the Rings: The Fellowship...  1.313341  0.0   \n",
       "25662329 疯狂动物城 Zootopia                                      1.353091  0.0   \n",
       "1858711  玩具总动员3 Toy Story 3                                  1.282134  0.0   \n",
       "1294638  E.T. 外星人 E.T.: The Extra-Terrestrial                1.281815  0.0   \n",
       "10533913 头脑特工队 Inside Out                                    1.310334  0.0   \n",
       "1298070  加勒比海盗 Pirates of the Caribbean: The Curse of th...  1.234176  0.0   \n",
       "1292722  泰坦尼克号 Titanic                                       1.411434  0.0   \n",
       "1652587  阿凡达 Avatar                                          1.344860  0.0   \n",
       "2353023  驯龙高手 How to Train Your Dragon                       1.263498  0.0   \n",
       "1929463  少年派的奇幻漂流 Life of Pi                                 1.329641  0.0   \n",
       "\n",
       "                                                             25%  50%  75%  \\\n",
       "movie_id movie_title                                                         \n",
       "1292720  阿甘正传 Forrest Gump                                   3.0  4.0  5.0   \n",
       "1291843  黑客帝国 The Matrix                                     3.0  4.0  5.0   \n",
       "2131459  机器人总动员 WALL·E                                       3.0  4.0  5.0   \n",
       "1301753  狮子王 The Lion King                                   3.0  4.0  5.0   \n",
       "1291552  指环王3：王者无敌 The Lord of the Rings: The Return of ...  3.0  4.0  5.0   \n",
       "3541415  盗梦空间 Inception                                      3.0  4.0  5.0   \n",
       "1851857  蝙蝠侠：黑暗骑士 The Dark Knight                            3.0  4.0  5.0   \n",
       "1292849  拯救大兵瑞恩 Saving Private Ryan                          3.0  4.0  5.0   \n",
       "1297630  第六感 The Sixth Sense                                 3.0  4.0  5.0   \n",
       "1295038  哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone     3.0  4.0  5.0   \n",
       "1291571  指环王1：魔戒再现 The Lord of the Rings: The Fellowship...  3.0  4.0  5.0   \n",
       "25662329 疯狂动物城 Zootopia                                      3.0  4.0  5.0   \n",
       "1858711  玩具总动员3 Toy Story 3                                  3.0  4.0  5.0   \n",
       "1294638  E.T. 外星人 E.T.: The Extra-Terrestrial                3.0  4.0  5.0   \n",
       "10533913 头脑特工队 Inside Out                                    3.0  4.0  5.0   \n",
       "1298070  加勒比海盗 Pirates of the Caribbean: The Curse of th...  3.0  4.0  5.0   \n",
       "1292722  泰坦尼克号 Titanic                                       3.0  5.0  5.0   \n",
       "1652587  阿凡达 Avatar                                          3.0  4.0  5.0   \n",
       "2353023  驯龙高手 How to Train Your Dragon                       3.0  4.0  5.0   \n",
       "1929463  少年派的奇幻漂流 Life of Pi                                 3.0  4.0  5.0   \n",
       "\n",
       "                                                             max  \n",
       "movie_id movie_title                                              \n",
       "1292720  阿甘正传 Forrest Gump                                   5.0  \n",
       "1291843  黑客帝国 The Matrix                                     5.0  \n",
       "2131459  机器人总动员 WALL·E                                       5.0  \n",
       "1301753  狮子王 The Lion King                                   5.0  \n",
       "1291552  指环王3：王者无敌 The Lord of the Rings: The Return of ...  5.0  \n",
       "3541415  盗梦空间 Inception                                      5.0  \n",
       "1851857  蝙蝠侠：黑暗骑士 The Dark Knight                            5.0  \n",
       "1292849  拯救大兵瑞恩 Saving Private Ryan                          5.0  \n",
       "1297630  第六感 The Sixth Sense                                 5.0  \n",
       "1295038  哈利·波特与魔法石 Harry Potter and the Sorcerer's Stone     5.0  \n",
       "1291571  指环王1：魔戒再现 The Lord of the Rings: The Fellowship...  5.0  \n",
       "25662329 疯狂动物城 Zootopia                                      5.0  \n",
       "1858711  玩具总动员3 Toy Story 3                                  5.0  \n",
       "1294638  E.T. 外星人 E.T.: The Extra-Terrestrial                5.0  \n",
       "10533913 头脑特工队 Inside Out                                    5.0  \n",
       "1298070  加勒比海盗 Pirates of the Caribbean: The Curse of th...  5.0  \n",
       "1292722  泰坦尼克号 Titanic                                       5.0  \n",
       "1652587  阿凡达 Avatar                                          5.0  \n",
       "2353023  驯龙高手 How to Train Your Dragon                       5.0  \n",
       "1929463  少年派的奇幻漂流 Life of Pi                                 5.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = movies[[\"movie_id\",\"movie_title\",\"rating_num\"]]\n",
    "comm = pd.merge(comm,temp,on=['movie_id'])\n",
    "comment = comm\n",
    "comment.groupby([\"movie_id\",\"movie_title\"])[\"star\"].describe().sort_values(\"count\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "compatible-pride",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>URL</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>useful_num</th>\n",
       "      <th>star</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "      <th>people</th>\n",
       "      <th>people_url</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>rating_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1364011224</td>\n",
       "      <td>37274</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-24 02:23:59</td>\n",
       "      <td>如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的</td>\n",
       "      <td>146803809</td>\n",
       "      <td>https://www.douban.com/people/146803809/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762639519</td>\n",
       "      <td>20741</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-24 00:11:06</td>\n",
       "      <td>我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落幕...</td>\n",
       "      <td>164105540</td>\n",
       "      <td>https://www.douban.com/people/164105540/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762628760</td>\n",
       "      <td>16016</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-24 00:01:17</td>\n",
       "      <td>托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”。...</td>\n",
       "      <td>lingrui1995</td>\n",
       "      <td>https://www.douban.com/people/lingrui1995/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762741840</td>\n",
       "      <td>14352</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-24 03:05:48</td>\n",
       "      <td>钢铁侠成为了美队，美队活成了钢铁侠。</td>\n",
       "      <td>Rafe0323</td>\n",
       "      <td>https://www.douban.com/people/Rafe0323/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26100958</td>\n",
       "      <td>https://movie.douban.com/subject/26100958/comm...</td>\n",
       "      <td>1762795339</td>\n",
       "      <td>12817</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-24 04:52:12</td>\n",
       "      <td>谁能想到是一只老鼠拯救了地球呢？</td>\n",
       "      <td>karsa</td>\n",
       "      <td>https://www.douban.com/people/karsa/</td>\n",
       "      <td>复仇者联盟4：终局之战 Avengers: Endgame</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450917</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>232767186</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-03-24 19:30:51</td>\n",
       "      <td>喜欢里面的奇思妙想，空灵而优美的音乐，因此还把它刻成光盘珍藏了</td>\n",
       "      <td>echozhanglijun</td>\n",
       "      <td>https://www.douban.com/people/echozhanglijun/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450918</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>453274665</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-11-03 16:10:50</td>\n",
       "      <td>忘不了那优美的音乐</td>\n",
       "      <td>ponyoicy</td>\n",
       "      <td>https://www.douban.com/people/ponyoicy/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450919</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>34553643</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008-03-22 10:37:49</td>\n",
       "      <td>看的第一部宫崎骏的作品 之后坚定了我要看全宫崎骏全部作品的决心</td>\n",
       "      <td>1900555</td>\n",
       "      <td>https://www.douban.com/people/1900555/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450920</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>576096444</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-09-03 13:09:16</td>\n",
       "      <td>谁愿陪伴我身旁 找到它的方向...探访天际的家乡 你是我的翅膀.</td>\n",
       "      <td>38355555</td>\n",
       "      <td>https://www.douban.com/people/38355555/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450921</th>\n",
       "      <td>1291583</td>\n",
       "      <td>https://movie.douban.com/subject/1291583/comme...</td>\n",
       "      <td>279050212</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-08-06 08:45:35</td>\n",
       "      <td>竟然是1986年的片片……膜拜一下</td>\n",
       "      <td>amanda_wong</td>\n",
       "      <td>https://www.douban.com/people/amanda_wong/</td>\n",
       "      <td>天空之城 天空の城ラピュタ</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450922 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        movie_id                                                URL  \\\n",
       "0       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "1       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "2       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "3       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "4       26100958  https://movie.douban.com/subject/26100958/comm...   \n",
       "...          ...                                                ...   \n",
       "450917   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "450918   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "450919   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "450920   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "450921   1291583  https://movie.douban.com/subject/1291583/comme...   \n",
       "\n",
       "        comment_id  useful_num  star                time  \\\n",
       "0       1364011224       37274     5 2019-04-24 02:23:59   \n",
       "1       1762639519       20741     4 2019-04-24 00:11:06   \n",
       "2       1762628760       16016     5 2019-04-24 00:01:17   \n",
       "3       1762741840       14352     5 2019-04-24 03:05:48   \n",
       "4       1762795339       12817     5 2019-04-24 04:52:12   \n",
       "...            ...         ...   ...                 ...   \n",
       "450917   232767186           0     5 2010-03-24 19:30:51   \n",
       "450918   453274665           0     5 2011-11-03 16:10:50   \n",
       "450919    34553643           0     5 2008-03-22 10:37:49   \n",
       "450920   576096444           0     5 2012-09-03 13:09:16   \n",
       "450921   279050212           0     4 2010-08-06 08:45:35   \n",
       "\n",
       "                                                  content          people  \\\n",
       "0                  如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的       146803809   \n",
       "1       我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落幕...       164105540   \n",
       "2       托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”。...     lingrui1995   \n",
       "3                                      钢铁侠成为了美队，美队活成了钢铁侠。        Rafe0323   \n",
       "4                                        谁能想到是一只老鼠拯救了地球呢？           karsa   \n",
       "...                                                   ...             ...   \n",
       "450917                    喜欢里面的奇思妙想，空灵而优美的音乐，因此还把它刻成光盘珍藏了  echozhanglijun   \n",
       "450918                                          忘不了那优美的音乐        ponyoicy   \n",
       "450919                    看的第一部宫崎骏的作品 之后坚定了我要看全宫崎骏全部作品的决心         1900555   \n",
       "450920                   谁愿陪伴我身旁 找到它的方向...探访天际的家乡 你是我的翅膀.        38355555   \n",
       "450921                                  竟然是1986年的片片……膜拜一下     amanda_wong   \n",
       "\n",
       "                                           people_url  \\\n",
       "0            https://www.douban.com/people/146803809/   \n",
       "1            https://www.douban.com/people/164105540/   \n",
       "2          https://www.douban.com/people/lingrui1995/   \n",
       "3             https://www.douban.com/people/Rafe0323/   \n",
       "4                https://www.douban.com/people/karsa/   \n",
       "...                                               ...   \n",
       "450917  https://www.douban.com/people/echozhanglijun/   \n",
       "450918        https://www.douban.com/people/ponyoicy/   \n",
       "450919         https://www.douban.com/people/1900555/   \n",
       "450920        https://www.douban.com/people/38355555/   \n",
       "450921     https://www.douban.com/people/amanda_wong/   \n",
       "\n",
       "                          movie_title  rating_num  \n",
       "0       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "1       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "2       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "3       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "4       复仇者联盟4：终局之战 Avengers: Endgame         8.5  \n",
       "...                               ...         ...  \n",
       "450917                  天空之城 天空の城ラピュタ         9.0  \n",
       "450918                  天空之城 天空の城ラピュタ         9.0  \n",
       "450919                  天空之城 天空の城ラピュタ         9.0  \n",
       "450920                  天空之城 天空の城ラピュタ         9.0  \n",
       "450921                  天空之城 天空の城ラピュタ         9.0  \n",
       "\n",
       "[450922 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-insight",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 评论合并(运行上面代码生成训练所需的数据)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "religious-yemen",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27119724</td>\n",
       "      <td>小丑 Joker</td>\n",
       "      <td>漫威 制造 大坏蛋 超高 智慧 强大 肉体 技能 无限 宝石 DC 糟糕 人生 年前 制造 ...</td>\n",
       "      <td>84058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26266893</td>\n",
       "      <td>流浪地球</td>\n",
       "      <td>北京 道路 提醒 道路 千万条 第一条 行车 规范 亲人 两行 这句 广播 洗脑 押点 哈哈...</td>\n",
       "      <td>81080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26754233</td>\n",
       "      <td>八佰</td>\n",
       "      <td>王千源 没有碰过 女人 飞机 特别 厉害 电影 结束 全场 静默 仿佛 观众 沉浸 那种 悲...</td>\n",
       "      <td>79871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889243</td>\n",
       "      <td>星际穿越 Interstellar</td>\n",
       "      <td>诺兰 活得够 豆瓣 TOP250 承包 时间 伸缩 折叠 唯独 倒退 鹤发 童颜 呼吸 抵过...</td>\n",
       "      <td>76984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26794435</td>\n",
       "      <td>哪吒之魔童降世</td>\n",
       "      <td>实名 反对 最赞 烂片 评论 这是 人类 逃脱 真香 定律 不值 票钱 快乐 星球 邓超救 ...</td>\n",
       "      <td>73807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1457217</td>\n",
       "      <td>哈利·波特与凤凰社 Harry Potter and the Order of the Ph...</td>\n",
       "      <td>没什么 场面 精彩 特效 政治 斗争 阴谋诡计 幼稚 没边 三徐 看不下去 只好 杀人 游戏...</td>\n",
       "      <td>10236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>1315574</td>\n",
       "      <td>加勒比海盗2：聚魂棺 Pirates of the Caribbean: Dead Man'...</td>\n",
       "      <td>土著 那段 惨爹 哈哈哈 树林 打来打去 一场 欢乐 野人 一段 搞笑 编剧 极尽 所能 这...</td>\n",
       "      <td>7017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2973079</td>\n",
       "      <td>霍比特人3：五军之战 The Hobbit: The Battle of the Five ...</td>\n",
       "      <td>笑点 拉斯 超级玛丽 阿佐格 阿尔弗雷 卷福 那条 死于 甘道夫 女王 公主 片尾 素描 分...</td>\n",
       "      <td>4105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>11606328</td>\n",
       "      <td>霍比特人2：史矛革之战 The Hobbit: The Desolation of Smaug</td>\n",
       "      <td>矮人 食人妖 抓走 矮人 哥不林 抓走 矮人 蜘蛛 抓走 矮人 精灵 抓走 矮人 人类 抓走...</td>\n",
       "      <td>3668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1418192</td>\n",
       "      <td>加勒比海盗3：世界的尽头 Pirates of the Caribbean: At Worl...</td>\n",
       "      <td>难看 发哥 个杯 可爱 一群 海盗 手一松 四星 比前 两部 两部 铺垫 故事 线略 一点 ...</td>\n",
       "      <td>2136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id                                        movie_title  \\\n",
       "0    27119724                                           小丑 Joker   \n",
       "1    26266893                                               流浪地球   \n",
       "2    26754233                                                 八佰   \n",
       "3     1889243                                  星际穿越 Interstellar   \n",
       "4    26794435                                            哪吒之魔童降世   \n",
       "..        ...                                                ...   \n",
       "458   1457217  哈利·波特与凤凰社 Harry Potter and the Order of the Ph...   \n",
       "459   1315574  加勒比海盗2：聚魂棺 Pirates of the Caribbean: Dead Man'...   \n",
       "460   2973079  霍比特人3：五军之战 The Hobbit: The Battle of the Five ...   \n",
       "461  11606328    霍比特人2：史矛革之战 The Hobbit: The Desolation of Smaug   \n",
       "462   1418192  加勒比海盗3：世界的尽头 Pirates of the Caribbean: At Worl...   \n",
       "\n",
       "                                               content  length  \n",
       "0    漫威 制造 大坏蛋 超高 智慧 强大 肉体 技能 无限 宝石 DC 糟糕 人生 年前 制造 ...   84058  \n",
       "1    北京 道路 提醒 道路 千万条 第一条 行车 规范 亲人 两行 这句 广播 洗脑 押点 哈哈...   81080  \n",
       "2    王千源 没有碰过 女人 飞机 特别 厉害 电影 结束 全场 静默 仿佛 观众 沉浸 那种 悲...   79871  \n",
       "3    诺兰 活得够 豆瓣 TOP250 承包 时间 伸缩 折叠 唯独 倒退 鹤发 童颜 呼吸 抵过...   76984  \n",
       "4    实名 反对 最赞 烂片 评论 这是 人类 逃脱 真香 定律 不值 票钱 快乐 星球 邓超救 ...   73807  \n",
       "..                                                 ...     ...  \n",
       "458  没什么 场面 精彩 特效 政治 斗争 阴谋诡计 幼稚 没边 三徐 看不下去 只好 杀人 游戏...   10236  \n",
       "459  土著 那段 惨爹 哈哈哈 树林 打来打去 一场 欢乐 野人 一段 搞笑 编剧 极尽 所能 这...    7017  \n",
       "460  笑点 拉斯 超级玛丽 阿佐格 阿尔弗雷 卷福 那条 死于 甘道夫 女王 公主 片尾 素描 分...    4105  \n",
       "461  矮人 食人妖 抓走 矮人 哥不林 抓走 矮人 蜘蛛 抓走 矮人 精灵 抓走 矮人 人类 抓走...    3668  \n",
       "462  难看 发哥 个杯 可爱 一群 海盗 手一松 四星 比前 两部 两部 铺垫 故事 线略 一点 ...    2136  \n",
       "\n",
       "[463 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ls_str(x):\n",
    "    return \" \".join(x.content.values.tolist())\n",
    "# comment 合并同个电影所有影评\n",
    "comment = comment.groupby([\"movie_id\",\"movie_title\"]).apply(ls_str)\n",
    "comment = comment.reset_index().rename(columns ={0:\"content\"})\n",
    "comment[\"content\"] = comment.content.apply(lcut).apply(dropstopword).apply(lambda x : \" \".join(x))\n",
    "comment[\"length\"] = comment['content'].str.len()\n",
    "comment = comment.sort_values(\"length\",ascending=False).reset_index(drop=True)\n",
    "corpus=comment.content.tolist()\n",
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-nomination",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 关键词提取 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-honduras",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wrapped-favor",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()#该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "transformer=TfidfTransformer()#该类会统计每个词语的tf-idf权值\n",
    "tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "word=vectorizer.get_feature_names()#获取词袋模型中的所有词语\n",
    "weight=tfidf.toarray()#将tf-idf矩阵抽取出来，元素a[i][j]表示j词在i类文本中的tf-idf权重\n",
    "info= {}\n",
    "for j in range(len(word)):\n",
    "    info[word[j]] = weight[1][j]\n",
    "data = pd.DataFrame(pd.Series(info)).reset_index()\n",
    "data.columns = [\"world\",\"tfidf\"]\n",
    "data = data.sort_values(\"tfidf\",ascending = False)\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "breathing-allah",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>科幻</td>\n",
       "      <td>0.350719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>地球</td>\n",
       "      <td>0.310135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>流浪</td>\n",
       "      <td>0.270352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>吴京</td>\n",
       "      <td>0.232492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>中国</td>\n",
       "      <td>0.202006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>电影</td>\n",
       "      <td>0.196852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>木星</td>\n",
       "      <td>0.194055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>特效</td>\n",
       "      <td>0.186893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>科幻电影</td>\n",
       "      <td>0.170765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>刘慈欣</td>\n",
       "      <td>0.155628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  world     tfidf\n",
       "0    科幻  0.350719\n",
       "1    地球  0.310135\n",
       "2    流浪  0.270352\n",
       "3    吴京  0.232492\n",
       "4    中国  0.202006\n",
       "5    电影  0.196852\n",
       "6    木星  0.194055\n",
       "7    特效  0.186893\n",
       "8  科幻电影  0.170765\n",
       "9   刘慈欣  0.155628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf = data.iloc[:60]\n",
    "data_tfidf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-maple",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## TextTrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceramic-syndicate",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>trank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>地球</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>电影</td>\n",
       "      <td>0.996673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>科幻</td>\n",
       "      <td>0.975426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>中国</td>\n",
       "      <td>0.958317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>流浪</td>\n",
       "      <td>0.489865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>煽情</td>\n",
       "      <td>0.396438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>人物</td>\n",
       "      <td>0.374241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>科幻片</td>\n",
       "      <td>0.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>台词</td>\n",
       "      <td>0.360245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>人类</td>\n",
       "      <td>0.358842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  world     trank\n",
       "0    地球  1.000000\n",
       "1    电影  0.996673\n",
       "2    科幻  0.975426\n",
       "3    中国  0.958317\n",
       "4    流浪  0.489865\n",
       "5    煽情  0.396438\n",
       "6    人物  0.374241\n",
       "7   科幻片  0.369000\n",
       "8    台词  0.360245\n",
       "9    人类  0.358842"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = jieba.analyse.textrank(corpus[1], topK=60, withWeight=True)\n",
    "info= {}\n",
    "for item in keywords:\n",
    "    info[item[0]] = item[1]\n",
    "data = pd.DataFrame(pd.Series(info)).reset_index()\n",
    "data.columns = [\"world\",\"trank\"]\n",
    "data_trank = data.sort_values(\"trank\",ascending = False).reset_index(drop = True).iloc[:60]\n",
    "data_trank.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-benefit",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "virtual-texture",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>电影</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>科幻</td>\n",
       "      <td>0.010787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>中国</td>\n",
       "      <td>0.010514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>地球</td>\n",
       "      <td>0.009876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>特效</td>\n",
       "      <td>0.007232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>流浪</td>\n",
       "      <td>0.004923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>煽情</td>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>科幻片</td>\n",
       "      <td>0.004193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>人物</td>\n",
       "      <td>0.004011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>故事</td>\n",
       "      <td>0.003889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  world       lda\n",
       "0    电影  0.011000\n",
       "1    科幻  0.010787\n",
       "2    中国  0.010514\n",
       "3    地球  0.009876\n",
       "4    特效  0.007232\n",
       "5    流浪  0.004923\n",
       "6    煽情  0.004224\n",
       "7   科幻片  0.004193\n",
       "8    人物  0.004011\n",
       "9    故事  0.003889"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "import jieba.posseg as jp\n",
    "import jieba\n",
    "\n",
    "def LDA_model(words_list):\n",
    "    # 构造词典\n",
    "    # Dictionary()方法遍历所有的文本，为每个不重复的单词分配一个单独的整数ID，同时收集该单词出现次数以及相关的统计信息\n",
    "    dictionary = corpora.Dictionary(words_list)\n",
    "    # print('打印查看每个单词的id:')\n",
    "    # print(dictionary.token2id)  # 打印查看每个单词的id\n",
    "    # 将dictionary转化为一个词袋\n",
    "    # doc2bow()方法将dictionary转化为一个词袋。得到的结果corpus是一个向量的列表，向量的个数就是文档数。\n",
    "    # 在每个文档向量中都包含一系列元组,元组的形式是（单词 ID，词频）\n",
    "    corpus = [dictionary.doc2bow(words) for words in words_list]\n",
    "    # print('输出每个文档的向量:')\n",
    "    # print(corpus)  # 输出每个文档的向量\n",
    "    # LDA主题模型\n",
    "    # num_topics -- 必须，要生成的主题个数。\n",
    "    # id2word    -- 必须，LdaModel类要求我们之前的dictionary把id都映射成为字符串。\n",
    "    # passes     -- 可选，模型遍历语料库的次数。遍历的次数越多，模型越精确。但是对于非常大的语料库，遍历太多次会花费很长的时间。\n",
    "    lda_model = models.ldamodel.LdaModel(corpus=corpus, num_topics=1, id2word=dictionary, passes=50)\n",
    "    return lda_model\n",
    "\n",
    "# 获取分词后的文本列表\n",
    "words_list =  comm[comm[\"movie_id\"]==26266893].content.apply(lcut).apply(dropstopword).tolist()\n",
    "\n",
    "# 获取训练后的LDA模型\n",
    "lda_model = LDA_model(words_list)\n",
    "# 可以用 print_topic 和 print_topics 方法来查看主题\n",
    "# 打印所有主题，每个主题显示5个词\n",
    "topic_words = lda_model.print_topics(num_topics=1, num_words=60)\n",
    "# print('打印所有主题，每个主题显示5个词:')\n",
    "# print(topic_words)\n",
    "# 输出该主题的的词及其词的权重\n",
    "words_list = lda_model.show_topic(0, 60)\n",
    "info= {}\n",
    "for item in words_list:\n",
    "    info[item[0]] = item[1]\n",
    "data = pd.DataFrame(pd.Series(info)).reset_index()\n",
    "data.columns = [\"world\",\"lda\"]\n",
    "data_lda = data.sort_values(\"lda\",ascending = False).reset_index(drop = True).iloc[:60]\n",
    "data_lda.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-headset",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "friendly-dialogue",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world</th>\n",
       "      <th>w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>郭帆</td>\n",
       "      <td>-1757.133688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>联合政府</td>\n",
       "      <td>-1774.407979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>地下城</td>\n",
       "      <td>-1783.770349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>刘慈欣</td>\n",
       "      <td>-1812.050486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>救援队</td>\n",
       "      <td>-1827.208292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>元年</td>\n",
       "      <td>-1869.175104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>朵朵</td>\n",
       "      <td>-1877.624687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>木星</td>\n",
       "      <td>-1912.290113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>可惜</td>\n",
       "      <td>-1937.365457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>至少</td>\n",
       "      <td>-1951.742979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  world          w2v\n",
       "0    郭帆 -1757.133688\n",
       "1  联合政府 -1774.407979\n",
       "2   地下城 -1783.770349\n",
       "3   刘慈欣 -1812.050486\n",
       "4   救援队 -1827.208292\n",
       "5    元年 -1869.175104\n",
       "6    朵朵 -1877.624687\n",
       "7    木星 -1912.290113\n",
       "8    可惜 -1937.365457\n",
       "9    至少 -1951.742979"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sg=1是skip—gram算法，对低频词敏感，默认sg=0为CBOW算法\n",
    "#size是神经网络层数，值太大则会耗内存并使算法计算变慢，一般值取为100到200之间。\n",
    "#window是句子中当前词与目标词之间的最大距离，3表示在目标词前看3-b个词，后面看b个词（b在0-3之间随机）\n",
    "#min_count是对词进行过滤，频率小于min-count的单词则会被忽视，默认值为5。\n",
    "#negative和sample可根据训练结果进行微调，sample表示更高频率的词被随机下采样到所设置的阈值，默认值为1e-3,\n",
    "#negative: 如果>0,则会采用negativesamping，用于设置多少个noise words\n",
    "#hs=1表示层级softmax将会被使用，默认hs=0且negative不为0，则负采样将会被选择使用。\n",
    "import gensim\n",
    "# sentences = comment.content.str.split(\" \").tolist()\n",
    "# model=gensim.models.Word2Vec(sentences,sg=0,size=150,window=3,min_count=2,negative=3,sample=0.001,hs=1,workers=4)\n",
    "# model.save(\"word2vec_modle\")\n",
    "model = gensim.models.Word2Vec.load(\"word2vec_modle\")\n",
    "# 此函数计算某词对于模型中各个词的转移概率p(wk|wi)\n",
    "def predict_proba(oword, iword):\n",
    "    #获取输入词的词向量\n",
    "    iword_vec = model[iword]\n",
    "    #获取保存权重的词的词库\n",
    "    oword = model.wv.vocab[oword]\n",
    "    oword_l = model.trainables.syn1[oword.point].T\n",
    "    dot = np.dot(iword_vec, oword_l)\n",
    "    lprob = -sum(np.logaddexp(0, -dot) + oword.code*dot) \n",
    "    return lprob\n",
    "from collections import Counter\n",
    "def keywords(s):\n",
    "    #抽出s中和与训练的model重叠的词\n",
    "    s = [w for w in s if w in model]\n",
    "    ws = {w:sum([predict_proba(u, w) for u in s]) for w in s}\n",
    "    return Counter(ws).most_common()\n",
    "\n",
    "frequency = pd.DataFrame(comment.content.str.split(\" \")[1])\n",
    "frequency[\"num\"] = 1\n",
    "frequency  = frequency.groupby(0).sum().sort_values(\"num\",ascending=False)\n",
    "sentence = frequency[frequency['num']>15].index.tolist()\n",
    "x = pd.Series(keywords(sentence))\n",
    "# 输出最重要的前60个词\n",
    "words_list = x[:60]\n",
    "info= {}\n",
    "for item in words_list:\n",
    "    info[item[0]] = item[1]\n",
    "data = pd.DataFrame(pd.Series(info)).reset_index()\n",
    "data.columns = [\"world\",\"w2v\"]\n",
    "data_w2v = data.sort_values(\"w2v\",ascending = False).reset_index(drop = True).iloc[:60]\n",
    "data_w2v.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-tractor",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 展示和分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "assumed-moldova",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min', 'echarts-wordcloud':'https://assets.pyecharts.org/assets/echarts-wordcloud.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"6fac5df09d2342cca42204eb56d8f1d3\" style=\"width:950px; height:900px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts', 'echarts-wordcloud'], function(echarts) {\n",
       "                var chart_6fac5df09d2342cca42204eb56d8f1d3 = echarts.init(\n",
       "                    document.getElementById('6fac5df09d2342cca42204eb56d8f1d3'), 'white', {renderer: 'canvas'});\n",
       "                var option_6fac5df09d2342cca42204eb56d8f1d3 = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"wordCloud\",\n",
       "            \"name\": \"tfidf\",\n",
       "            \"shape\": \"circle\",\n",
       "            \"rotationRange\": [\n",
       "                -90,\n",
       "                90\n",
       "            ],\n",
       "            \"rotationStep\": 45,\n",
       "            \"girdSize\": 20,\n",
       "            \"sizeRange\": [\n",
       "                10,\n",
       "                60\n",
       "            ],\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\",\n",
       "                    \"value\": 0.3507194627500583,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(61,9,80)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u7403\",\n",
       "                    \"value\": 0.31013455799942974,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(68,23,0)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6d41\\u6d6a\",\n",
       "                    \"value\": 0.2703519449160141,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(114,110,136)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u4eac\",\n",
       "                    \"value\": 0.23249229770419616,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(75,89,143)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e2d\\u56fd\",\n",
       "                    \"value\": 0.2020061692151813,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(67,69,84)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7535\\u5f71\",\n",
       "                    \"value\": 0.19685155963273912,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(91,109,130)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6728\\u661f\",\n",
       "                    \"value\": 0.19405502322709736,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(103,146,14)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7279\\u6548\",\n",
       "                    \"value\": 0.18689344558900603,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(28,80,6)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7535\\u5f71\",\n",
       "                    \"value\": 0.1707651086401221,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(30,112,37)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5218\\u6148\\u6b23\",\n",
       "                    \"value\": 0.15562760840628112,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,82,154)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7247\",\n",
       "                    \"value\": 0.14971613408661352,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(26,13,156)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6218\\u72fc\",\n",
       "                    \"value\": 0.114499461218671,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(76,150,67)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5143\\u5e74\",\n",
       "                    \"value\": 0.10860292351113165,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(76,107,79)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\\u7247\",\n",
       "                    \"value\": 0.10807604865685719,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(84,61,127)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u717d\\u60c5\",\n",
       "                    \"value\": 0.10731896674447655,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(98,61,102)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u592a\\u7a7a\",\n",
       "                    \"value\": 0.0983555461287162,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(140,120,117)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u56fd\\u4ea7\",\n",
       "                    \"value\": 0.09572538786997965,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(68,65,65)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u4e0b\\u57ce\",\n",
       "                    \"value\": 0.08830192567832965,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(30,28,73)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7a7a\\u95f4\\u7ad9\",\n",
       "                    \"value\": 0.08624667698982105,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(79,90,40)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6735\\u6735\",\n",
       "                    \"value\": 0.08444032493696497,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(158,116,30)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u661f\\u9645\",\n",
       "                    \"value\": 0.08346138440135242,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(94,65,4)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u539f\\u8457\",\n",
       "                    \"value\": 0.0800637041127792,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(140,28,23)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7c7b\",\n",
       "                    \"value\": 0.07950612730164099,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(147,89,132)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u90ed\\u5e06\",\n",
       "                    \"value\": 0.07733824580447071,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(47,155,121)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5c34\\u5c2c\",\n",
       "                    \"value\": 0.07640110328391096,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(12,4,15)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53f0\\u8bcd\",\n",
       "                    \"value\": 0.07516978081561924,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(92,114,145)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7269\",\n",
       "                    \"value\": 0.07251954317269492,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(25,52,62)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u9f13\\u52b1\",\n",
       "                    \"value\": 0.06966416132571909,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,133,2)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6545\\u4e8b\",\n",
       "                    \"value\": 0.06925248773783343,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(108,9,57)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u771f\\u7684\",\n",
       "                    \"value\": 0.06543542148456702,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(48,64,160)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8bbe\\u5b9a\",\n",
       "                    \"value\": 0.06538314577656854,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(16,115,53)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6551\\u63f4\",\n",
       "                    \"value\": 0.064932399053562,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(127,27,63)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5b87\\u5b99\",\n",
       "                    \"value\": 0.06435014428505274,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(60,51,52)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8054\\u5408\\u653f\\u5e9c\",\n",
       "                    \"value\": 0.06327674656729422,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(80,134,94)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u597d\\u83b1\\u575e\",\n",
       "                    \"value\": 0.0629033291239096,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(23,154,138)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6625\\u8282\",\n",
       "                    \"value\": 0.05772818907485669,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(3,88,41)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u60c5\",\n",
       "                    \"value\": 0.05750332029070034,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(150,157,80)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6551\\u63f4\\u961f\",\n",
       "                    \"value\": 0.05729879192151195,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(6,10,153)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\",\n",
       "                    \"value\": 0.0572472420347372,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(25,87,146)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53d1\\u52a8\\u673a\",\n",
       "                    \"value\": 0.05238849222845158,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(59,113,5)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5e0c\\u671b\",\n",
       "                    \"value\": 0.05045143979767551,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(35,33,153)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8fd9\\u90e8\",\n",
       "                    \"value\": 0.04962186129246332,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(61,107,92)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u62ef\\u6551\",\n",
       "                    \"value\": 0.04937168226459944,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(104,96,128)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5927\\u7247\",\n",
       "                    \"value\": 0.04864900759340445,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(133,25,134)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u5fc3\\u5f15\\u529b\",\n",
       "                    \"value\": 0.04804288114302772,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(100,30,78)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u90e8\",\n",
       "                    \"value\": 0.04689538539727303,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(30,28,105)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786c\\u6838\",\n",
       "                    \"value\": 0.04670879200582564,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(120,99,126)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e09\\u4f53\",\n",
       "                    \"value\": 0.04525783774007544,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(91,131,113)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5b8f\\u5927\",\n",
       "                    \"value\": 0.04470297439626555,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(81,78,130)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7a7f\\u8d8a\",\n",
       "                    \"value\": 0.044670000619156935,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(146,60,41)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u5b5f\\u8fbe\",\n",
       "                    \"value\": 0.042483738031442876,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(147,25,152)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5c48\\u695a\",\n",
       "                    \"value\": 0.04218449771152948,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(41,47,70)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8ba1\\u5212\",\n",
       "                    \"value\": 0.042105477632293394,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(62,86,45)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u611f\",\n",
       "                    \"value\": 0.04205812585957073,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(55,116,147)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5e7f\\u64ad\",\n",
       "                    \"value\": 0.04201530143762426,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(71,148,153)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u727a\\u7272\",\n",
       "                    \"value\": 0.04100043846469013,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(10,110,141)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u611f\\u89c9\",\n",
       "                    \"value\": 0.04089713842785439,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(86,21,96)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"2001\",\n",
       "                    \"value\": 0.040015018455147114,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(24,155,15)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u70b9\\u71c3\",\n",
       "                    \"value\": 0.0400136502631621,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(68,154,38)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5de5\\u4e1a\",\n",
       "                    \"value\": 0.03972522136593252,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(118,13,132)\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            ],\n",
       "            \"left\": \"-10%\",\n",
       "            \"top\": \"-10%\",\n",
       "            \"drawOutOfBound\": false,\n",
       "            \"textStyle\": {\n",
       "                \"emphasis\": {}\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"wordCloud\",\n",
       "            \"name\": \"textrank\",\n",
       "            \"shape\": \"circle\",\n",
       "            \"rotationRange\": [\n",
       "                -90,\n",
       "                90\n",
       "            ],\n",
       "            \"rotationStep\": 45,\n",
       "            \"girdSize\": 20,\n",
       "            \"sizeRange\": [\n",
       "                10,\n",
       "                60\n",
       "            ],\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u7403\",\n",
       "                    \"value\": 1.0,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(128,105,87)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7535\\u5f71\",\n",
       "                    \"value\": 0.996673087448874,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(134,158,20)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\",\n",
       "                    \"value\": 0.9754260881022752,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(33,121,17)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e2d\\u56fd\",\n",
       "                    \"value\": 0.9583168640857961,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(38,103,148)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6d41\\u6d6a\",\n",
       "                    \"value\": 0.48986504120696994,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(16,18,27)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u717d\\u60c5\",\n",
       "                    \"value\": 0.39643839721356705,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(53,85,107)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7269\",\n",
       "                    \"value\": 0.3742408821996431,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(100,160,38)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7247\",\n",
       "                    \"value\": 0.3689999844335871,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(151,23,50)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53f0\\u8bcd\",\n",
       "                    \"value\": 0.36024505590926087,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(153,115,28)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7c7b\",\n",
       "                    \"value\": 0.3588422390094141,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(63,160,66)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6545\\u4e8b\",\n",
       "                    \"value\": 0.3551532417840374,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(136,1,9)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7535\\u5f71\",\n",
       "                    \"value\": 0.31403344073615386,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(112,140,48)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u4eac\",\n",
       "                    \"value\": 0.31230056725449706,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(3,17,52)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u60c5\",\n",
       "                    \"value\": 0.2760973525818965,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(21,83,138)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u597d\\u83b1\\u575e\",\n",
       "                    \"value\": 0.273861934180611,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(160,154,94)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8bbe\\u5b9a\",\n",
       "                    \"value\": 0.270650747197413,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(10,52,100)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6728\\u661f\",\n",
       "                    \"value\": 0.24564425983732835,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(25,36,25)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5e0c\\u671b\",\n",
       "                    \"value\": 0.24474388717786663,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(47,92,118)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u56fd\\u4ea7\",\n",
       "                    \"value\": 0.23910885448109495,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(151,0,14)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u611f\\u89c9\",\n",
       "                    \"value\": 0.22151369086048697,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(91,11,46)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u62ef\\u6551\",\n",
       "                    \"value\": 0.22120880325962464,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(13,58,102)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u611f\",\n",
       "                    \"value\": 0.21049713036467563,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(29,131,53)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u89c2\\u4f17\",\n",
       "                    \"value\": 0.21041226313890893,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(81,25,19)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u539f\\u8457\",\n",
       "                    \"value\": 0.2046662068769043,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(133,141,114)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5b87\\u5b99\",\n",
       "                    \"value\": 0.20240290165407196,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(93,45,152)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5927\\u7247\",\n",
       "                    \"value\": 0.2012766595246156,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(89,80,122)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5bfc\\u6f14\",\n",
       "                    \"value\": 0.20046582638950994,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(124,146,54)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u592a\\u7a7a\",\n",
       "                    \"value\": 0.1992468219314784,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(43,92,18)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\\u7247\",\n",
       "                    \"value\": 0.19446275334238458,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(157,37,126)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u89d2\\u8272\",\n",
       "                    \"value\": 0.1926279108567905,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(158,0,119)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6f14\\u5458\",\n",
       "                    \"value\": 0.1738286097420517,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(16,84,137)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u8282\",\n",
       "                    \"value\": 0.16857306641299083,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(3,22,93)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u661f\\u9645\",\n",
       "                    \"value\": 0.15861159106201883,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(156,13,4)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6218\\u72fc\",\n",
       "                    \"value\": 0.15655208226710693,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(11,51,63)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\",\n",
       "                    \"value\": 0.15418358907789959,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(69,115,72)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7a7f\\u8d8a\",\n",
       "                    \"value\": 0.15147751064746248,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(113,57,130)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7247\\u5b50\",\n",
       "                    \"value\": 0.15110840028977818,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(88,76,111)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u727a\\u7272\",\n",
       "                    \"value\": 0.1503068182000741,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(66,60,111)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u503c\\u5f97\",\n",
       "                    \"value\": 0.1501974557236288,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(24,97,43)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e16\\u754c\",\n",
       "                    \"value\": 0.14784771004627362,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(9,43,7)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53d9\\u4e8b\",\n",
       "                    \"value\": 0.146725964596363,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(124,7,128)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u610f\\u4e49\",\n",
       "                    \"value\": 0.1462941916364683,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(100,120,71)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u9f13\\u52b1\",\n",
       "                    \"value\": 0.14470596085085782,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(111,119,137)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7ec6\\u8282\",\n",
       "                    \"value\": 0.14332385434101488,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(8,12,115)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7c7b\\u578b\",\n",
       "                    \"value\": 0.13791616557744749,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(6,110,124)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u672c\",\n",
       "                    \"value\": 0.1359218021461008,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(74,55,77)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u573a\\u666f\",\n",
       "                    \"value\": 0.13274650486957998,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(20,55,115)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u526a\\u8f91\",\n",
       "                    \"value\": 0.12995993009508466,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(59,150,21)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u903b\\u8f91\",\n",
       "                    \"value\": 0.12605892398518126,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(68,92,59)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u65b9\",\n",
       "                    \"value\": 0.1259389226499488,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(152,83,134)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6280\\u672f\",\n",
       "                    \"value\": 0.12324011679669852,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(57,5,97)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5f71\\u7247\",\n",
       "                    \"value\": 0.12288923086677457,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(4,159,5)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8868\\u6f14\",\n",
       "                    \"value\": 0.12192202026338059,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(12,141,136)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4f5c\\u54c1\",\n",
       "                    \"value\": 0.11924584718057449,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(54,12,135)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6c34\\u51c6\",\n",
       "                    \"value\": 0.11896478982127279,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(158,35,36)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u955c\\u5934\",\n",
       "                    \"value\": 0.11759503554914624,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(37,4,70)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6f14\\u6280\",\n",
       "                    \"value\": 0.11743768750807877,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(37,40,114)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8ba1\\u5212\",\n",
       "                    \"value\": 0.11343083494164627,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(119,54,36)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u6027\",\n",
       "                    \"value\": 0.11284558793336648,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(92,146,66)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5c0f\\u8bf4\",\n",
       "                    \"value\": 0.11034462399387983,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(139,109,20)\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            ],\n",
       "            \"left\": \"40%\",\n",
       "            \"top\": \"-10%\",\n",
       "            \"drawOutOfBound\": false,\n",
       "            \"textStyle\": {\n",
       "                \"emphasis\": {}\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"wordCloud\",\n",
       "            \"name\": \"lda\",\n",
       "            \"shape\": \"circle\",\n",
       "            \"rotationRange\": [\n",
       "                -90,\n",
       "                90\n",
       "            ],\n",
       "            \"rotationStep\": 45,\n",
       "            \"girdSize\": 20,\n",
       "            \"sizeRange\": [\n",
       "                10,\n",
       "                60\n",
       "            ],\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u7535\\u5f71\",\n",
       "                    \"value\": 0.011000045575201511,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(31,136,50)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\",\n",
       "                    \"value\": 0.010787355713546276,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(107,56,142)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e2d\\u56fd\",\n",
       "                    \"value\": 0.010513871908187866,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,0,4)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u7403\",\n",
       "                    \"value\": 0.009875745512545109,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(63,78,87)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7279\\u6548\",\n",
       "                    \"value\": 0.00723205367103219,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(101,30,122)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6d41\\u6d6a\",\n",
       "                    \"value\": 0.00492261303588748,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,101,137)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u717d\\u60c5\",\n",
       "                    \"value\": 0.004223708063364029,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(10,18,114)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7247\",\n",
       "                    \"value\": 0.004193317610770464,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(5,123,19)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7269\",\n",
       "                    \"value\": 0.004010995849967003,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(73,62,110)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6545\\u4e8b\",\n",
       "                    \"value\": 0.003889448009431362,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(20,79,85)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53f0\\u8bcd\",\n",
       "                    \"value\": 0.003889448009431362,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(52,29,117)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4eba\\u7c7b\",\n",
       "                    \"value\": 0.0037071227561682463,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(106,57,50)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u771f\\u7684\",\n",
       "                    \"value\": 0.003676737891510129,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(23,156,115)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7535\\u5f71\",\n",
       "                    \"value\": 0.0034336368553340435,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(117,94,72)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u60c5\",\n",
       "                    \"value\": 0.0032209292985498905,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(10,24,70)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u4eac\",\n",
       "                    \"value\": 0.0030386000871658325,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(15,17,104)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u597d\\u83b1\\u575e\",\n",
       "                    \"value\": 0.0029778301250189543,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(73,58,44)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8bbe\\u5b9a\",\n",
       "                    \"value\": 0.0029170531779527664,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(57,109,59)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u56fd\\u4ea7\",\n",
       "                    \"value\": 0.002856278093531728,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(55,67,139)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8fd9\\u90e8\",\n",
       "                    \"value\": 0.0027955046389251947,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,120,125)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5e0c\\u671b\",\n",
       "                    \"value\": 0.0027347297873347998,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(153,37,66)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5c34\\u5c2c\",\n",
       "                    \"value\": 0.0026739556342363358,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(30,158,121)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u90e8\",\n",
       "                    \"value\": 0.002643567742779851,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(44,60,60)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u539f\\u8457\",\n",
       "                    \"value\": 0.002400472294539213,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(7,117,155)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u611f\\u89c9\",\n",
       "                    \"value\": 0.002309308620169759,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(10,68,89)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u592a\\u7a7a\",\n",
       "                    \"value\": 0.002218149369582534,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(132,151,117)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6728\\u661f\",\n",
       "                    \"value\": 0.00221814913675189,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(66,117,100)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5927\\u7247\",\n",
       "                    \"value\": 0.0021877605468034744,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(156,30,50)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u62ef\\u6551\",\n",
       "                    \"value\": 0.00215737521648407,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(31,114,56)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u89c2\\u4f17\",\n",
       "                    \"value\": 0.0020662129390984774,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(63,18,139)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u611f\",\n",
       "                    \"value\": 0.00203582551330328,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(0,154,127)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5b87\\u5b99\",\n",
       "                    \"value\": 0.00203582551330328,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(102,110,35)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5bfc\\u6f14\",\n",
       "                    \"value\": 0.0020054387860000134,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(21,39,41)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\\u7247\",\n",
       "                    \"value\": 0.001975052058696747,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(54,58,104)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u89d2\\u8272\",\n",
       "                    \"value\": 0.0019446639344096184,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(41,70,26)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u9519\",\n",
       "                    \"value\": 0.00191427581012249,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(56,129,64)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u9f13\\u52b1\",\n",
       "                    \"value\": 0.0018535020062699914,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(36,24,38)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6f14\\u5458\",\n",
       "                    \"value\": 0.0018231153953820467,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(73,10,51)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u8282\",\n",
       "                    \"value\": 0.0018231153953820467,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(120,77,68)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5218\\u6148\\u6b23\",\n",
       "                    \"value\": 0.0018231153953820467,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(113,63,57)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7247\\u5b50\",\n",
       "                    \"value\": 0.0017623400781303644,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(155,7,130)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e09\\u661f\",\n",
       "                    \"value\": 0.0017319535836577415,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(151,88,92)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u661f\\u9645\",\n",
       "                    \"value\": 0.0017319534672424197,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(122,104,80)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u503c\\u5f97\",\n",
       "                    \"value\": 0.001671178499236703,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(68,60,130)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\",\n",
       "                    \"value\": 0.0016407921211794019,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(76,46,53)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6218\\u72fc\",\n",
       "                    \"value\": 0.00164079200476408,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(115,40,34)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7a7f\\u8d8a\",\n",
       "                    \"value\": 0.001610403647646308,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(93,52,84)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7ec6\\u8282\",\n",
       "                    \"value\": 0.001580017851665616,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(25,77,147)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u70b9\",\n",
       "                    \"value\": 0.0015800177352502942,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(88,82,48)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53d9\\u4e8b\",\n",
       "                    \"value\": 0.0015496297273784876,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(111,34,45)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u610f\\u4e49\",\n",
       "                    \"value\": 0.0015496297273784876,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(159,91,49)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u672c\",\n",
       "                    \"value\": 0.0014888558071106672,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(53,111,92)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u526a\\u8f91\",\n",
       "                    \"value\": 0.0014888558071106672,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(40,98,65)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6f14\\u6280\",\n",
       "                    \"value\": 0.0014888558071106672,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(130,133,142)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5f71\\u7247\",\n",
       "                    \"value\": 0.0014584680320695043,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(92,108,154)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e16\\u754c\",\n",
       "                    \"value\": 0.0014280813047662377,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(160,125,31)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u727a\\u7272\",\n",
       "                    \"value\": 0.0014280813047662377,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(17,84,1)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7c7b\\u578b\",\n",
       "                    \"value\": 0.001397694111801684,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(82,4,22)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u65b9\",\n",
       "                    \"value\": 0.001397694111801684,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(110,113,105)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786e\\u5b9e\",\n",
       "                    \"value\": 0.001397694111801684,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(37,13,86)\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            ],\n",
       "            \"left\": \"-10%\",\n",
       "            \"top\": \"35%\",\n",
       "            \"drawOutOfBound\": false,\n",
       "            \"textStyle\": {\n",
       "                \"emphasis\": {}\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"wordCloud\",\n",
       "            \"name\": \"word2vec\",\n",
       "            \"shape\": \"circle\",\n",
       "            \"rotationRange\": [\n",
       "                -90,\n",
       "                90\n",
       "            ],\n",
       "            \"rotationStep\": 45,\n",
       "            \"girdSize\": 20,\n",
       "            \"sizeRange\": [\n",
       "                10,\n",
       "                60\n",
       "            ],\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u90ed\\u5e06\",\n",
       "                    \"value\": -1757.1336878985167,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(24,76,143)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8054\\u5408\\u653f\\u5e9c\",\n",
       "                    \"value\": -1774.4079785346985,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(115,118,16)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u4e0b\\u57ce\",\n",
       "                    \"value\": -1783.770349264145,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(38,142,21)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5218\\u6148\\u6b23\",\n",
       "                    \"value\": -1812.0504857748747,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(36,94,4)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6551\\u63f4\\u961f\",\n",
       "                    \"value\": -1827.208292067051,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(147,114,44)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5143\\u5e74\",\n",
       "                    \"value\": -1869.1751044355333,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(129,46,39)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6735\\u6735\",\n",
       "                    \"value\": -1877.6246874779463,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(146,71,76)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6728\\u661f\",\n",
       "                    \"value\": -1912.2901126630604,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(145,51,63)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53ef\\u60dc\",\n",
       "                    \"value\": -1937.3654574956745,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(35,10,62)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u81f3\\u5c11\",\n",
       "                    \"value\": -1951.7429789002053,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(141,33,98)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53ea\\u80fd\",\n",
       "                    \"value\": -1956.3698825156316,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(31,0,50)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u53d1\\u52a8\\u673a\",\n",
       "                    \"value\": -1973.0470940843225,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(127,51,88)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786c\\u6838\",\n",
       "                    \"value\": -1977.5962551534176,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(81,123,111)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u70b9\\u71c3\",\n",
       "                    \"value\": -1991.1569873727858,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(93,69,79)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e09\\u4f53\",\n",
       "                    \"value\": -1996.2133169118315,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(33,159,25)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786e\\u5b9e\",\n",
       "                    \"value\": -1996.6248589493334,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(7,130,90)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5f71\\u7247\",\n",
       "                    \"value\": -1998.3930413899943,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(78,133,6)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u57fa\\u7840\",\n",
       "                    \"value\": -1998.6483534417057,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(82,156,110)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5730\\u5fc3\\u5f15\\u529b\",\n",
       "                    \"value\": -2001.5776877321769,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(67,127,66)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u50cf\\u662f\",\n",
       "                    \"value\": -2019.4596791984513,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(141,113,76)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u80af\\u5b9a\",\n",
       "                    \"value\": -2035.7619176302105,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(34,132,64)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7535\\u5f71\",\n",
       "                    \"value\": -2036.0707702818327,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(15,42,99)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u9519\",\n",
       "                    \"value\": -2045.9975019949488,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(61,5,80)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4f9d\\u7136\",\n",
       "                    \"value\": -2048.935940299183,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(152,93,69)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6210\\u529f\",\n",
       "                    \"value\": -2052.9916877134237,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(89,19,131)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u611f\\u89c9\",\n",
       "                    \"value\": -2067.8701943299384,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(99,135,105)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u79d1\\u5e7b\\u7247\",\n",
       "                    \"value\": -2070.9574657734447,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(14,34,19)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6982\\u5ff5\",\n",
       "                    \"value\": -2073.729540048833,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(62,82,75)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8fd9\\u662f\",\n",
       "                    \"value\": -2076.105830639135,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(8,157,2)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7535\\u5f71\",\n",
       "                    \"value\": -2079.090236918215,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(153,146,73)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u672b\\u65e5\",\n",
       "                    \"value\": -2081.124973738857,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(143,2,43)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6218\\u72fc\",\n",
       "                    \"value\": -2081.9974810163258,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(96,152,81)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5267\\u672c\",\n",
       "                    \"value\": -2089.2734922707314,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(106,18,104)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7406\\u89e3\",\n",
       "                    \"value\": -2089.29617554383,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(158,31,69)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7247\\u5b50\",\n",
       "                    \"value\": -2089.3166226574685,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(42,149,86)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u70b9\",\n",
       "                    \"value\": -2089.851214717375,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(137,91,130)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u771f\\u7684\",\n",
       "                    \"value\": -2097.196458680555,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(103,137,70)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7c97\\u7cd9\",\n",
       "                    \"value\": -2097.653156610406,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(100,70,128)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u884c\",\n",
       "                    \"value\": -2100.6055776875583,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(80,88,27)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5434\\u4eac\",\n",
       "                    \"value\": -2102.1245884622913,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(19,24,134)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7279\\u522b\",\n",
       "                    \"value\": -2104.0539271162997,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(135,65,105)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u707e\\u96be\",\n",
       "                    \"value\": -2104.664778503844,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(73,92,61)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e0d\\u597d\",\n",
       "                    \"value\": -2105.109005513601,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(21,50,19)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u786c\\u4f24\",\n",
       "                    \"value\": -2107.2725463265087,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(59,37,37)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u60c5\\u6000\",\n",
       "                    \"value\": -2109.406559197814,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(38,31,58)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6551\\u63f4\",\n",
       "                    \"value\": -2110.429212840856,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(95,83,144)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7c7b\\u578b\",\n",
       "                    \"value\": -2111.064899618781,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(77,108,7)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"bug\",\n",
       "                    \"value\": -2111.1685410763093,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(24,134,73)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e09\\u661f\",\n",
       "                    \"value\": -2113.4292630583514,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(24,103,97)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6c34\\u5e73\",\n",
       "                    \"value\": -2114.837322113912,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(150,119,22)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7f3a\\u70b9\",\n",
       "                    \"value\": -2115.2823285037884,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(81,85,5)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e00\\u90e8\",\n",
       "                    \"value\": -2121.911513410625,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(145,62,149)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6545\\u4e8b\",\n",
       "                    \"value\": -2122.131462634774,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(47,115,27)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8fd9\\u90e8\",\n",
       "                    \"value\": -2125.268442822271,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(34,124,65)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u660e\\u767d\",\n",
       "                    \"value\": -2125.415136915515,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(81,26,27)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7279\\u6548\",\n",
       "                    \"value\": -2129.765435821151,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(77,54,31)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u5957\\u8def\",\n",
       "                    \"value\": -2130.204747956479,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(115,49,122)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u7f16\\u5267\",\n",
       "                    \"value\": -2132.8593144352344,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(4,64,32)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u6807\\u51c6\",\n",
       "                    \"value\": -2133.408374204999,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(155,112,113)\"\n",
       "                        }\n",
       "                    }\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u56fd\\u4ea7\\u7535\\u5f71\",\n",
       "                    \"value\": -2135.906498065917,\n",
       "                    \"textStyle\": {\n",
       "                        \"normal\": {\n",
       "                            \"color\": \"rgb(75,86,133)\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            ],\n",
       "            \"left\": \"40%\",\n",
       "            \"top\": \"35%\",\n",
       "            \"drawOutOfBound\": false,\n",
       "            \"textStyle\": {\n",
       "                \"emphasis\": {}\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [],\n",
       "            \"selected\": {},\n",
       "            \"show\": true,\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"itemWidth\": 25,\n",
       "            \"itemHeight\": 14\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"showContent\": true,\n",
       "        \"alwaysShowContent\": false,\n",
       "        \"showDelay\": 0,\n",
       "        \"hideDelay\": 100,\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0,\n",
       "        \"padding\": 5\n",
       "    },\n",
       "    \"title\": [\n",
       "        {\n",
       "            \"text\": \"\\u6d41\\u6d6a\\u5730\\u7403\",\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"textStyle\": {\n",
       "                \"fontSize\": 24\n",
       "            }\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_6fac5df09d2342cca42204eb56d8f1d3.setOption(option_6fac5df09d2342cca42204eb56d8f1d3);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x1bbbeb59be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import WordCloud,Page\n",
    "word1 = data_tfidf.world.values.tolist()\n",
    "value1 = data_tfidf.tfidf.values.tolist()\n",
    "datas1 = [(x,y) for x,y in zip(word1,value1)]\n",
    "word2 = data_trank.world.values.tolist()\n",
    "value2 = data_trank.trank.values.tolist()\n",
    "datas2 = [(x,y) for x,y in zip(word2,value2)]\n",
    "word3 = data_lda.world.values.tolist()\n",
    "value3 = data_lda.lda.values.tolist()\n",
    "datas3 = [(x,y) for x,y in zip(word3,value3)]\n",
    "word4 = data_w2v.world.values.tolist()\n",
    "value4 = data_w2v.w2v.values.tolist()\n",
    "datas4 = [(x,y) for x,y in zip(word4,value4)]\n",
    "clo = (\n",
    "    WordCloud(init_opts=opts.InitOpts(width=\"950px\", height=\"900px\"))\n",
    "    .add(series_name=\"tfidf\", data_pair=datas1, word_size_range=[10, 60],shape = \"circle\",pos_top=\"-10%\",pos_left=\"-10%\")\n",
    "    .add(series_name=\"textrank\", data_pair=datas2, word_size_range=[10, 60],shape = \"circle\",pos_top=\"-10%\",pos_left=\"40%\")\n",
    "    .add(series_name=\"lda\", data_pair=datas3, word_size_range=[10, 60],shape = \"circle\",pos_top=\"35%\",pos_left=\"-10%\")\n",
    "     .add(series_name=\"word2vec\", data_pair=datas4, word_size_range=[10, 60],shape = \"circle\",pos_top=\"35%\",pos_left=\"40%\")\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(\n",
    "            title=\"流浪地球\", title_textstyle_opts=opts.TextStyleOpts(font_size=24)\n",
    "        ),\n",
    "        tooltip_opts=opts.TooltipOpts(is_show=True),\n",
    "    )\n",
    ")\n",
    "\n",
    "clo.render_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stunning-cycle",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>科幻</td>\n",
       "      <td>电影</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>地球</td>\n",
       "      <td>科幻</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>流浪</td>\n",
       "      <td>中国</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>吴京</td>\n",
       "      <td>地球</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>中国</td>\n",
       "      <td>特效</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>电影</td>\n",
       "      <td>流浪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>木星</td>\n",
       "      <td>煽情</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>特效</td>\n",
       "      <td>科幻片</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>科幻电影</td>\n",
       "      <td>人物</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>刘慈欣</td>\n",
       "      <td>故事</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tfidf frequency\n",
       "0    科幻        电影\n",
       "1    地球        科幻\n",
       "2    流浪        中国\n",
       "3    吴京        地球\n",
       "4    中国        特效\n",
       "5    电影        流浪\n",
       "6    木星        煽情\n",
       "7    特效       科幻片\n",
       "8  科幻电影        人物\n",
       "9   刘慈欣        故事"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp = pd.concat([frequency.reset_index()[0],data_lda.world,data_tfidf.world,data_trank.world,data_w2v.world],axis = 1)\n",
    "cmp.columns = [\"frequency\",\"lda\",\"tfidf\",\"texttrank\",\"word2vec\"]\n",
    "cmp[['tfidf','frequency']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-privilege",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nuclear-devices",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th colspan=\"6\" halign=\"left\">star</th>\n",
       "      <th>low</th>\n",
       "      <th>mid</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291544</td>\n",
       "      <td>哈利·波特与阿兹卡班的囚徒 Harry Potter and the Prisoner of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.336667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291545</td>\n",
       "      <td>大鱼 Big Fish</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.095945</td>\n",
       "      <td>0.891197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1291548</td>\n",
       "      <td>死亡诗社 Dead Poets Society</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>0.107004</td>\n",
       "      <td>0.874514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1291549</td>\n",
       "      <td>放牛班的春天 Les choristes</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.067061</td>\n",
       "      <td>0.919132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1291552</td>\n",
       "      <td>指环王3：王者无敌 The Lord of the Rings: The Return of...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>0.186957</td>\n",
       "      <td>0.194410</td>\n",
       "      <td>0.618634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>26931786</td>\n",
       "      <td>蜘蛛侠：英雄远征 Spider-Man: Far from Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.332222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.334444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>27119724</td>\n",
       "      <td>小丑 Joker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>27133569</td>\n",
       "      <td>小丑回魂2 It: Chapter Two</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.337778</td>\n",
       "      <td>0.332222</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>27163278</td>\n",
       "      <td>速度与激情：特别行动 Fast &amp; Furious Presents: Hobbs &amp; Shaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.333704</td>\n",
       "      <td>0.332592</td>\n",
       "      <td>0.333704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>30128985</td>\n",
       "      <td>勇敢者游戏2：再战巅峰 Jumanji: The Next Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id                                        movie_title  star         \\\n",
       "                                                                     0      1   \n",
       "0     1291544  哈利·波特与阿兹卡班的囚徒 Harry Potter and the Prisoner of...   NaN   38.0   \n",
       "1     1291545                                        大鱼 Big Fish  29.0    4.0   \n",
       "2     1291548                            死亡诗社 Dead Poets Society  12.0    3.0   \n",
       "3     1291549                               放牛班的春天 Les choristes  25.0    3.0   \n",
       "4     1291552  指环王3：王者无敌 The Lord of the Rings: The Return of...  29.0   74.0   \n",
       "..        ...                                                ...   ...    ...   \n",
       "458  26931786                 蜘蛛侠：英雄远征 Spider-Man: Far from Home   NaN   64.0   \n",
       "459  27119724                                           小丑 Joker   NaN  104.0   \n",
       "460  27133569                              小丑回魂2 It: Chapter Two   NaN   55.0   \n",
       "461  27163278   速度与激情：特别行动 Fast & Furious Presents: Hobbs & Shaw   NaN   51.0   \n",
       "462  30128985                勇敢者游戏2：再战巅峰 Jumanji: The Next Level   NaN   57.0   \n",
       "\n",
       "                                      low       mid      high  \n",
       "         2      3      4      5                                \n",
       "0    262.0  297.0  173.0  130.0  0.333333  0.330000  0.336667  \n",
       "1      9.0   97.0  325.0  576.0  0.012859  0.095945  0.891197  \n",
       "2     16.0  110.0  335.0  564.0  0.018482  0.107004  0.874514  \n",
       "3     11.0   68.0  276.0  656.0  0.013807  0.067061  0.919132  \n",
       "4    227.0  313.0  219.0  777.0  0.186957  0.194410  0.618634  \n",
       "..     ...    ...    ...    ...       ...       ...       ...  \n",
       "458  235.0  300.0  200.0  101.0  0.332222  0.333333  0.334444  \n",
       "459  196.0  300.0  124.0  176.0  0.333333  0.333333  0.333333  \n",
       "460  249.0  299.0  253.0   44.0  0.337778  0.332222  0.330000  \n",
       "461  249.0  299.0  257.0   43.0  0.333704  0.332592  0.333704  \n",
       "462  243.0  300.0  257.0   43.0  0.333333  0.333333  0.333333  \n",
       "\n",
       "[463 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_star = comm.groupby(['movie_id','movie_title'])['star'].apply(pd.Series.value_counts).to_frame().unstack().reset_index()\n",
    "comm_star[\"low\"] = (comm_star.star[1]+comm_star.star[2])/(comm_star.star[1]+comm_star.star[2]+comm_star.star[3]+comm_star.star[4]+comm_star.star[5])\n",
    "comm_star[\"mid\"] = (comm_star.star[3])/(comm_star.star[1]+comm_star.star[2]+comm_star.star[3]+comm_star.star[4]+comm_star.star[5])\n",
    "comm_star[\"high\"] = (comm_star.star[4]+comm_star.star[5])/(comm_star.star[1]+comm_star.star[2]+comm_star.star[3]+comm_star.star[4]+comm_star.star[5])\n",
    "comm_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "necessary-fruit",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    273857\n",
       "-1     95992\n",
       " 0     74222\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1234)\n",
    "comm[\"label\"] = comm['star'].apply(lambda x :  0 if x<3 else 1 if x>3 else -1)\n",
    "comm_data = comm[comm.star !=0]\n",
    "comm_data \n",
    "comm_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "native-orange",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~生成数据已经保存~~~~~~~~~~~~~~~\n",
    "# # 中评比较模棱两可\n",
    "# like = comm_data[comm_data.label==1].content.values.tolist()\n",
    "# dislike = comm_data[comm_data.label==0].content.values.tolist()\n",
    "# def preprocess_text(content_lines, sentences, category):\n",
    "#     for line in content_lines:\n",
    "#         try:\n",
    "#             segs=jieba.lcut(line)\n",
    "#             segs = filter(lambda x:len(x)>1, segs)\n",
    "#             segs = filter(lambda x:x not in stopwords.stopword, segs)\n",
    "#             sentences.append((\" \".join(segs), category))\n",
    "#         except:\n",
    "#             print (line)\n",
    "#             continue\n",
    "# sen = []\n",
    "# # 上采样,解决样本不均衡\n",
    "# preprocess_text(like, sen, 'like')\n",
    "# preprocess_text(dislike, sen, 'dislike')\n",
    "# preprocess_text(dislike, sen, 'dislike')\n",
    "# preprocess_text(dislike, sen, 'dislike')\n",
    "# # 存sen\n",
    "# temp_file = pd.DataFrame(pd.Series(sen).reset_index(drop = True))\n",
    "# temp_file.to_csv(\"temp_filem_ML.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "binding-lightning",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 将元组字符串解构成元组\n",
    "sen = pd.read_csv(\"temp_filem_ML.csv\")['0'].apply(lambda x: tuple(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "amber-anthropology",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               (如果 喜欢 这部 电影 说明 不是 准备 故事 终章 读过 故事 准备, like)\n",
       "1         (一个 90 曾经 羡慕 一代人 40 年前 观众 他们 影院 星战 正传 三部曲 落幕 2...\n",
       "2         (托尼 说好 回归 家庭 陪伴 家人 最终 还是 选择 重出江湖 因为 责任 使命 因为 钢...\n",
       "3                                 (钢铁 成为 美队 美队 活成 钢铁, like)\n",
       "4                                    (想到 一只 老鼠 拯救 地球, like)\n",
       "                                ...                        \n",
       "496518                          (宮崎駿 動畫 太超 現實 不喜歡, dislike)\n",
       "496519    (大师 作品 较差 一部 无聊 俗气 没法 产生共鸣 以及 喜欢 男女 主角 喜欢 笨人 喜...\n",
       "496520                (观测 爱看 动漫 比较 乐观 可惜 告诉 什么 好看, dislike)\n",
       "496521              (个人 虫子 有关 电影 看好 比较 喜欢 后来 幽灵公主, dislike)\n",
       "496522         (這是 唯一 宮崎駿 系列 喜歡 片子 知道 喜歡 就是 沒有 好感, dislike)\n",
       "Name: 0, Length: 496523, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-thing",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "lasting-metadata",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(sen)# 所有元素随机排列\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sen[:200000]) # 带星号的用来解压\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "class TextClassifier():\n",
    "\n",
    "    def __init__(self, classifier=BernoulliNB()):\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,4), max_features=20000)\n",
    "\n",
    "    def features(self, X):\n",
    "        return TfidfTransformer().fit_transform(self.vectorizer.transform(X))\n",
    "#         return self.vectorizer.transform(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.classifier.fit(self.features(X), y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(self.features(X))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.classifier.score(self.features(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "further-police",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_classifier = TextClassifier()\n",
    "text_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "illegal-estonia",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like' 'like']\n",
      "0.78792\n"
     ]
    }
   ],
   "source": [
    "print(text_classifier.predict([\"特效不错,但是剧情硬伤\",\n",
    "                        \"真难看,我喜欢\"]))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "speaking-inspiration",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#预测\n",
    "# comm[comm.star ==0].content[:10].values.tolist()\n",
    "# show_train = pd.DataFrame(pd.Series(comm[comm.star ==0].content[:50].values.tolist())).reset_index(drop = True)\n",
    "# show_pre = pd.DataFrame(pd.Series(text_classifier.predict(comm[comm.star ==0].content[:50].values.tolist()))).reset_index(drop = True)\n",
    "# show = pd.concat([show_train,show_pre],axis=1)\n",
    "# show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-night",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## SVM支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "anonymous-building",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "x, y = zip(*sen[:50000]) # 带星号的用来解压\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234)\n",
    "svm = SVC(kernel='linear')\n",
    "text_classifier = TextClassifier(svm)\n",
    "text_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "marked-lobby",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like' 'like']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b96d8aff4d62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m print(text_classifier.predict([\"特效不错,但是剧情硬伤\",\n\u001b[0;32m      2\u001b[0m                         \"我喜欢\"]))\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-a2b05da08c14>\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-a2b05da08c14>\u001b[0m in \u001b[0;36mfeatures\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;31m#         return self.vectorizer.transform(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "print(text_classifier.predict([\"特效不错,但是剧情硬伤\",\n",
    "                        \"我喜欢\"]))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-stocks",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "intellectual-sandwich",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like' 'like']\n",
      "0.8225906502001917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x, y = zip(*sen) # 带星号的用来解压\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234)\n",
    "lgr = LogisticRegression(solver='sag')\n",
    "text_classifier = TextClassifier(lgr)\n",
    "text_classifier.fit(x_train, y_train)\n",
    "print(text_classifier.predict([\"特效不错,但是剧情硬伤\",\n",
    "                        \"我觉得还行\"]))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-alaska",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##  FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sustainable-breath",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74222"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# like = comm_data[comm_data.label==1].content.values.tolist()\n",
    "# dislike = comm_data[comm_data.label==0].content.values.tolist()\n",
    "# len(dislike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stock-burning",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # ~~~~~~~~已经生成数据文件~~~~~~~~~~~~~~~~~\n",
    "# import jieba \n",
    "# import pandas as pd \n",
    "# import random\n",
    "# like = comm_data[comm_data.label==1].content.values.tolist()\n",
    "# dislike = comm_data[comm_data.label==0].content.values.tolist()\n",
    "\n",
    "# def preprocess_text(content_lines,sentences,category): \n",
    "#     for line in content_lines:\n",
    "#         try:\n",
    "#             segs=jieba.lcut(line)\n",
    "#             segs = filter(lambda x:len(x)>1, segs)\n",
    "#             segs = filter(lambda x:x not in stopwords, segs)\n",
    "#             sentences.append(\"__label__\"+str(category)+\" , \"+\" \".join(segs))\n",
    "#         except:\n",
    "#             print(line)\n",
    "#             continue\n",
    "            \n",
    "# # 生成训练数据            \n",
    "# senten=[]\n",
    "# preprocess_text(like,senten ,'like')\n",
    "# preprocess_text(dislike,senten ,'dislike')\n",
    "# preprocess_text(dislike,senten ,'dislike')\n",
    "# preprocess_text(dislike,senten ,'dislike')\n",
    "\n",
    "# random.shuffle(senten)\n",
    "\n",
    "# print(\"writing data to fasttext supervised learning format...\")\n",
    "# out = open('train_data_supervised_fasttext.txt','w' )#,encoding='utf-8') \n",
    "# for sentence in senten:\n",
    "#     out.write(sentence+\"\\n\") \n",
    "# print(\"done!\")\n",
    "# out = open('train_data_supervised_fasttext.txt','w' )#,encoding='utf-8') \n",
    "# for sentence in senten[:372392]:\n",
    "#     out.write(sentence+\"\\n\") \n",
    "\n",
    "# out1 = open('test_data_supervised_fasttext.txt','w' )#,encoding='utf-8') \n",
    "# for sentence in senten[372393:]:\n",
    "#     out1.write(sentence+\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "macro-stress",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9351486344960928\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "# 有监督\n",
    "classifier=fasttext.train_supervised('train_data_supervised_fasttext.txt',lr=1.0,dim=200,wordNgrams=4,epoch=30)\n",
    "# 对模型进行评估\n",
    "result = classifier.test('test_data_supervised_fasttext.txt')\n",
    "# print('P@1:',result.precision)\n",
    "# print('R@1:',result.recall)\n",
    "# print('Number of examples:',result.nexamples)\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-rapid",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "texts = \"特效不错,但是剧情硬伤\"\n",
    "labels=classifier.predict(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-bicycle",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dress-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = pd.read_csv(\"temp_filem_ML.csv\")['0'].apply(lambda x: tuple(eval(x)))\n",
    "random.shuffle(sen)     \n",
    "x,y=zip(*sen)\n",
    "train_data,test_data,train_target,test_target=train_test_split(x, y, random_state=1234)\n",
    "cate_dic={'like':1,'dislike':0}\n",
    "y_train = pd.Series(train_target).apply(lambda x:cate_dic[x] , train_target)\n",
    "y_test = pd.Series(test_target).apply(lambda x:cate_dic[x] , test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-peace",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "widespread-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "基于卷积神经网络的中文文本分类\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "learn = tf.contrib.learn\n",
    "FLAGS = None\n",
    "# 文档最长长度\n",
    "MAX_DOCUMENT_LENGTH = 100\n",
    "# 最小词频数\n",
    "MIN_WORD_FREQUENCE = 2\n",
    "# 词嵌入的维度\n",
    "EMBEDDING_SIZE = 20\n",
    "# filter个数\n",
    "N_FILTERS = 10 # 10个神经元\n",
    "# 感知野大小\n",
    "WINDOW_SIZE = 20\n",
    "#filter的形状\n",
    "FILTER_SHAPE1 = [WINDOW_SIZE, EMBEDDING_SIZE]\n",
    "FILTER_SHAPE2 = [WINDOW_SIZE, N_FILTERS] \n",
    "# 池化\n",
    "POOLING_WINDOW = 4\n",
    "POOLING_STRIDE = 2\n",
    "n_words = 0\n",
    "\n",
    "def cnn_model(features, target):\n",
    "    \"\"\"\n",
    "    2层的卷积神经网络，用于短文本分类\n",
    "    \"\"\"\n",
    "    # 先把词转成词嵌入\n",
    "    # 我们得到一个形状为[n_words, EMBEDDING_SIZE]的词表映射矩阵\n",
    "    # 接着我们可以把一批文本映射成[batch_size, sequence_length,EMBEDDING_SIZE]的矩阵形式\n",
    "    \n",
    "    target = tf.one_hot(target, 15, 1, 0) #对词编码最大选前15个标签,在的为1,不在的为0\n",
    "    print(target)\n",
    "    # 把词变成词嵌入, feature 词矩阵, vocab_size输入数据的总词汇量, embed_dim嵌入矩阵的维度大小\n",
    "    # 输出是 [句子数,词数,嵌入维度数]\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(features\n",
    "                                                    ,vocab_size=n_words\n",
    "                                                    ,embed_dim=EMBEDDING_SIZE\n",
    "                                                    ,scope='words')\n",
    "    # 增加一维\n",
    "    word_vectors = tf.expand_dims(word_vectors, 3)\n",
    "    print(word_vectors)\n",
    "    \n",
    "    with tf.variable_scope('CNN_Layer1'):\n",
    "        # 添加卷积层做滤波\n",
    "        conv1 = tf.contrib.layers.convolution2d(word_vectors\n",
    "                                                ,N_FILTERS\n",
    "                                                ,FILTER_SHAPE1\n",
    "                                                ,padding='VALID')# 不够了舍弃\n",
    "        # 添加RELU非线性\n",
    "        conv1 = tf.nn.relu(conv1) \n",
    "        # 最大池化\n",
    "        pool1 = tf.nn.max_pool(conv1\n",
    "                               ,ksize=[1, POOLING_WINDOW, 1, 1]\n",
    "                               ,strides=[1, POOLING_STRIDE, 1, 1]\n",
    "                               ,padding='SAME')# 不够了填充\n",
    "        # 对矩阵进行转置，以满足形状\n",
    "        pool1 = tf.transpose(pool1, [0, 1, 3, 2])\n",
    "        \n",
    "    with tf.variable_scope('CNN_Layer2'):\n",
    "        # 第2卷积层\n",
    "        conv2 = tf.contrib.layers.convolution2d(pool1\n",
    "                                                ,N_FILTERS\n",
    "                                                ,FILTER_SHAPE2\n",
    "                                                ,padding='VALID') \n",
    "        # 抽取特征\n",
    "        pool2 = tf.squeeze(tf.reduce_max(conv2, 1), squeeze_dims=[1])\n",
    "        \n",
    "    # 全连接层\n",
    "    logits = tf.contrib.layers.fully_connected(pool2, 15, activation_fn=None)\n",
    "    loss = tf.losses.softmax_cross_entropy(target, logits) \n",
    "    # 优化器\n",
    "    train_op = tf.contrib.layers.optimize_loss(loss\n",
    "                                               ,tf.contrib.framework.get_global_step()\n",
    "                                               ,optimizer='Adam'\n",
    "                                               ,learning_rate=0.01)\n",
    "    \n",
    "    return ({\n",
    "            'class': tf.argmax(logits, 1),\n",
    "            'prob': logits,\n",
    "    }, loss, train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "lucky-conviction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words:72609\n"
     ]
    }
   ],
   "source": [
    "global n_words\n",
    "# 处理词汇\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH# 最大长度和最小词频\n",
    "                                                          ,min_frequency=MIN_WORD_FREQUENCE) \n",
    "x_train = np.array(list(vocab_processor.fit_transform(train_data)))\n",
    "x_test = np.array(list(vocab_processor.transform(test_data)))\n",
    "n_words=len(vocab_processor.vocabulary_) \n",
    "print('Total words:%d'%n_words)# 不重复的单词数量\n",
    "\n",
    "# cate_dic={'like':1,'dislike':0}\n",
    "# y_train = pd.Series(train_target).apply(lambda x:cate_dic[x] , train_target)\n",
    "# y_test = pd.Series(test_target).apply(lambda x:cate_dic[x] , test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "invisible-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [step, loss_train, loss_test, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_cnn=pd.DataFrame(columns=('step','loss_train','loss_test','score'))\n",
    "# result_cnn.to_csv(\"./DL_model/cnn_loss.csv\",index=False)\n",
    "result_cnn = pd.read_csv(\"./DL_model/cnn_loss.csv\")\n",
    "result_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\11514\\AppData\\Local\\Temp\\tmp5_7ox85k\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002AB82087B70>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\11514\\\\AppData\\\\Local\\\\Temp\\\\tmp5_7ox85k'}\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp5_7ox85k\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.7081597, step = 1\n",
      "INFO:tensorflow:global_step/sec: 21.9788\n",
      "INFO:tensorflow:loss = 0.65374905, step = 101 (4.553 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp5_7ox85k\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.42477536.\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\11514\\AppData\\Local\\Temp\\tmp5_7ox85k\\model.ckpt-200\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    classifier1=learn.Estimator(model_fn=cnn_model)\n",
    "    #Train and predict\n",
    "    classifier1_skl = learn.SKCompat(classifier1)\n",
    "    classifier1_skl.fit(x_train,y_train,steps=(i+1)*100)\n",
    "    test_predicted=classifier1_skl.predict(x_test)\n",
    "    train_predicted=classifier1_skl.predict(x_train)\n",
    "    test_hot = tf.one_hot(y_test, 15, 1, 0)\n",
    "    train_hot = tf.one_hot(y_train, 15, 1, 0)\n",
    "    score=metrics.accuracy_score(y_test,test_predicted['class'])\n",
    "    loss_train = tf.losses.softmax_cross_entropy(train_hot, train_predicted['prob'])\n",
    "    loss_test = tf.losses.softmax_cross_entropy(test_hot, test_predicted['prob'])\n",
    "    with tf.Session() as sess:\n",
    "        loss_test=loss_test.eval()\n",
    "        loss_train=loss_train.eval()      \n",
    "#     loss_train = classifier1.evaluate(x_train,y_train)\n",
    "#     loss_test = classifier1.evaluate(x_test,y_test) \n",
    "    result_cnn = result_cnn.append({\"loss_test\":loss_test,\n",
    "                                                        \"loss_train\":loss_train,\n",
    "                                                        \"score\":score,\n",
    "                                                        \"step\":(i+1)*100\n",
    "                                                        },ignore_index=True)\n",
    "    result_cnn.to_csv(\"./DL_model/cnn_loss.csv\",index=False)\n",
    "    print(\"我存了第%d次\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "standard-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EBCF28B080>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\11514\\\\AppData\\\\Local\\\\Temp\\\\tmp1nu516dc'}\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-40-e7ee6796035b>:85: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.7078671, step = 1\n",
      "INFO:tensorflow:global_step/sec: 18.0318\n",
      "INFO:tensorflow:loss = 0.6899018, step = 101 (5.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9513\n",
      "INFO:tensorflow:loss = 0.4858918, step = 201 (6.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4824\n",
      "INFO:tensorflow:loss = 0.42110074, step = 301 (6.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9548\n",
      "INFO:tensorflow:loss = 0.46961197, step = 401 (7.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7101\n",
      "INFO:tensorflow:loss = 0.48979077, step = 501 (5.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.817\n",
      "INFO:tensorflow:loss = 0.45768446, step = 601 (6.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8585\n",
      "INFO:tensorflow:loss = 0.42910954, step = 701 (6.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1342\n",
      "INFO:tensorflow:loss = 0.43446928, step = 801 (6.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5572\n",
      "INFO:tensorflow:loss = 0.29818732, step = 901 (6.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5411\n",
      "INFO:tensorflow:loss = 0.41014272, step = 1001 (6.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2513\n",
      "INFO:tensorflow:loss = 0.38491175, step = 1101 (6.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8984\n",
      "INFO:tensorflow:loss = 0.37527162, step = 1201 (6.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7959\n",
      "INFO:tensorflow:loss = 0.35982987, step = 1301 (6.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2677\n",
      "INFO:tensorflow:loss = 0.33398935, step = 1401 (6.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6663\n",
      "INFO:tensorflow:loss = 0.3292506, step = 1501 (5.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4541\n",
      "INFO:tensorflow:loss = 0.3198082, step = 1601 (7.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5756\n",
      "INFO:tensorflow:loss = 0.3407227, step = 1701 (6.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5287\n",
      "INFO:tensorflow:loss = 0.3638414, step = 1801 (5.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3906\n",
      "INFO:tensorflow:loss = 0.39531487, step = 1901 (6.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7097\n",
      "INFO:tensorflow:loss = 0.30084682, step = 2001 (6.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8349\n",
      "INFO:tensorflow:loss = 0.40575224, step = 2101 (6.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9234\n",
      "INFO:tensorflow:loss = 0.36836702, step = 2201 (6.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4717\n",
      "INFO:tensorflow:loss = 0.24819532, step = 2301 (6.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4761\n",
      "INFO:tensorflow:loss = 0.5281279, step = 2401 (5.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6053\n",
      "INFO:tensorflow:loss = 0.29806727, step = 2501 (6.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9264\n",
      "INFO:tensorflow:loss = 0.42572406, step = 2601 (7.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7105\n",
      "INFO:tensorflow:loss = 0.35385308, step = 2701 (5.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1982\n",
      "INFO:tensorflow:loss = 0.38960323, step = 2801 (6.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9647\n",
      "INFO:tensorflow:loss = 0.41185445, step = 2901 (7.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2905\n",
      "INFO:tensorflow:loss = 0.20753959, step = 3001 (5.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1344\n",
      "INFO:tensorflow:loss = 0.27730978, step = 3101 (7.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.191\n",
      "INFO:tensorflow:loss = 0.2607367, step = 3201 (6.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3402\n",
      "INFO:tensorflow:loss = 0.24805868, step = 3301 (5.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.095\n",
      "INFO:tensorflow:loss = 0.3096096, step = 3401 (7.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7319\n",
      "INFO:tensorflow:loss = 0.2754598, step = 3501 (5.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2405\n",
      "INFO:tensorflow:loss = 0.2855526, step = 3601 (6.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3013\n",
      "INFO:tensorflow:loss = 0.2338152, step = 3701 (6.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.253\n",
      "INFO:tensorflow:loss = 0.27424306, step = 3801 (5.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9344\n",
      "INFO:tensorflow:loss = 0.37035728, step = 3901 (7.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2705\n",
      "INFO:tensorflow:loss = 0.26395684, step = 4001 (6.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4489\n",
      "INFO:tensorflow:loss = 0.21789171, step = 4101 (6.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9615\n",
      "INFO:tensorflow:loss = 0.34686205, step = 4201 (7.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.853\n",
      "INFO:tensorflow:loss = 0.28254864, step = 4301 (5.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3969\n",
      "INFO:tensorflow:loss = 0.25868064, step = 4401 (6.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5071\n",
      "INFO:tensorflow:loss = 0.36394304, step = 4501 (7.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1307\n",
      "INFO:tensorflow:loss = 0.20551907, step = 4601 (5.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0045\n",
      "INFO:tensorflow:loss = 0.2782653, step = 4701 (6.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1983\n",
      "INFO:tensorflow:loss = 0.28766826, step = 4801 (7.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1639\n",
      "INFO:tensorflow:loss = 0.22719195, step = 4901 (5.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4689\n",
      "INFO:tensorflow:loss = 0.2148499, step = 5001 (8.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3268\n",
      "INFO:tensorflow:loss = 0.28339148, step = 5101 (5.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3574\n",
      "INFO:tensorflow:loss = 0.22932327, step = 5201 (6.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4013\n",
      "INFO:tensorflow:loss = 0.22226042, step = 5301 (6.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2737\n",
      "INFO:tensorflow:loss = 0.18930739, step = 5401 (5.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0914\n",
      "INFO:tensorflow:loss = 0.29172716, step = 5501 (7.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1508\n",
      "INFO:tensorflow:loss = 0.24056655, step = 5601 (5.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2943\n",
      "INFO:tensorflow:loss = 0.3210176, step = 5701 (6.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4684\n",
      "INFO:tensorflow:loss = 0.25626594, step = 5801 (7.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1343\n",
      "INFO:tensorflow:loss = 0.2137895, step = 5901 (5.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8522\n",
      "INFO:tensorflow:loss = 0.21135557, step = 6001 (7.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9248\n",
      "INFO:tensorflow:loss = 0.12426661, step = 6101 (7.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2002\n",
      "INFO:tensorflow:loss = 0.118051425, step = 6201 (5.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2299\n",
      "INFO:tensorflow:loss = 0.25618765, step = 6301 (6.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9714\n",
      "INFO:tensorflow:loss = 0.14428098, step = 6401 (7.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.998\n",
      "INFO:tensorflow:loss = 0.1470037, step = 6501 (6.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8493\n",
      "INFO:tensorflow:loss = 0.25082153, step = 6601 (6.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3807\n",
      "INFO:tensorflow:loss = 0.22133633, step = 6701 (6.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0345\n",
      "INFO:tensorflow:loss = 0.16929515, step = 6801 (7.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.18874155, step = 6901 (5.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8919\n",
      "INFO:tensorflow:loss = 0.16936122, step = 7001 (6.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8225\n",
      "INFO:tensorflow:loss = 0.14647682, step = 7101 (7.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2067\n",
      "INFO:tensorflow:loss = 0.27741238, step = 7201 (5.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7019\n",
      "INFO:tensorflow:loss = 0.23521332, step = 7301 (7.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2394\n",
      "INFO:tensorflow:loss = 0.20307465, step = 7401 (5.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0531\n",
      "INFO:tensorflow:loss = 0.25825047, step = 7501 (6.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7013\n",
      "INFO:tensorflow:loss = 0.20991428, step = 7601 (7.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7186\n",
      "INFO:tensorflow:loss = 0.18756741, step = 7701 (5.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0914\n",
      "INFO:tensorflow:loss = 0.21992138, step = 7801 (7.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5965\n",
      "INFO:tensorflow:loss = 0.2509961, step = 7901 (5.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9175\n",
      "INFO:tensorflow:loss = 0.19572367, step = 8001 (6.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6826\n",
      "INFO:tensorflow:loss = 0.32052872, step = 8101 (7.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5001\n",
      "INFO:tensorflow:loss = 0.19149062, step = 8201 (5.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5041\n",
      "INFO:tensorflow:loss = 0.24442646, step = 8301 (6.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1474\n",
      "INFO:tensorflow:loss = 0.17669842, step = 8401 (6.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1798\n",
      "INFO:tensorflow:loss = 0.20040336, step = 8501 (5.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2678\n",
      "INFO:tensorflow:loss = 0.12437916, step = 8601 (7.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7319\n",
      "INFO:tensorflow:loss = 0.18743, step = 8701 (5.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6101\n",
      "INFO:tensorflow:loss = 0.1087505, step = 8801 (6.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9894\n",
      "INFO:tensorflow:loss = 0.08741075, step = 8901 (7.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3016\n",
      "INFO:tensorflow:loss = 0.14850695, step = 9001 (5.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.176\n",
      "INFO:tensorflow:loss = 0.194421, step = 9101 (6.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7064\n",
      "INFO:tensorflow:loss = 0.28330153, step = 9201 (7.297 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9284 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 17.3197\n",
      "INFO:tensorflow:loss = 0.124481805, step = 9301 (5.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6483\n",
      "INFO:tensorflow:loss = 0.18923119, step = 9401 (7.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3004\n",
      "INFO:tensorflow:loss = 0.14374949, step = 9501 (6.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2248\n",
      "INFO:tensorflow:loss = 0.14119884, step = 9601 (5.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1247\n",
      "INFO:tensorflow:loss = 0.13279039, step = 9701 (7.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0198\n",
      "INFO:tensorflow:loss = 0.138975, step = 9801 (5.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3931\n",
      "INFO:tensorflow:loss = 0.13512483, step = 9901 (6.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9481\n",
      "INFO:tensorflow:loss = 0.1738125, step = 10001 (7.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6549\n",
      "INFO:tensorflow:loss = 0.16594133, step = 10101 (5.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7757\n",
      "INFO:tensorflow:loss = 0.2010909, step = 10201 (6.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6197\n",
      "INFO:tensorflow:loss = 0.19208309, step = 10301 (6.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1194\n",
      "INFO:tensorflow:loss = 0.17159021, step = 10401 (5.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.666\n",
      "INFO:tensorflow:loss = 0.22995928, step = 10501 (7.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3289\n",
      "INFO:tensorflow:loss = 0.17649795, step = 10601 (6.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1638\n",
      "INFO:tensorflow:loss = 0.18545277, step = 10701 (5.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0943\n",
      "INFO:tensorflow:loss = 0.18850903, step = 10801 (7.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0724\n",
      "INFO:tensorflow:loss = 0.16928896, step = 10901 (5.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2707\n",
      "INFO:tensorflow:loss = 0.16428867, step = 11001 (7.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1992\n",
      "INFO:tensorflow:loss = 0.11621071, step = 11101 (6.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4623\n",
      "INFO:tensorflow:loss = 0.13722739, step = 11201 (5.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0973\n",
      "INFO:tensorflow:loss = 0.1373578, step = 11301 (7.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5471\n",
      "INFO:tensorflow:loss = 0.18540841, step = 11401 (6.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5009\n",
      "INFO:tensorflow:loss = 0.105079815, step = 11501 (6.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3621\n",
      "INFO:tensorflow:loss = 0.13735917, step = 11601 (7.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3045\n",
      "INFO:tensorflow:loss = 0.17423752, step = 11701 (5.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0669\n",
      "INFO:tensorflow:loss = 0.091914, step = 11801 (7.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7614\n",
      "INFO:tensorflow:loss = 0.09404072, step = 11901 (6.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3691\n",
      "INFO:tensorflow:loss = 0.09935269, step = 12001 (6.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5163\n",
      "INFO:tensorflow:loss = 0.12702847, step = 12101 (7.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3615\n",
      "INFO:tensorflow:loss = 0.18527108, step = 12201 (5.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8608\n",
      "INFO:tensorflow:loss = 0.136145, step = 12301 (7.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.027\n",
      "INFO:tensorflow:loss = 0.16396837, step = 12401 (6.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.339\n",
      "INFO:tensorflow:loss = 0.095932566, step = 12501 (5.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.693\n",
      "INFO:tensorflow:loss = 0.11480027, step = 12601 (7.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8268\n",
      "INFO:tensorflow:loss = 0.16383204, step = 12701 (5.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6627\n",
      "INFO:tensorflow:loss = 0.28071666, step = 12801 (6.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1005\n",
      "INFO:tensorflow:loss = 0.119679146, step = 12901 (7.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5229\n",
      "INFO:tensorflow:loss = 0.1423207, step = 13001 (5.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2849\n",
      "INFO:tensorflow:loss = 0.15234719, step = 13101 (7.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5729\n",
      "INFO:tensorflow:loss = 0.3396297, step = 13201 (6.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7915\n",
      "INFO:tensorflow:loss = 0.13993178, step = 13301 (6.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7246\n",
      "INFO:tensorflow:loss = 0.14805126, step = 13401 (6.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1901\n",
      "INFO:tensorflow:loss = 0.08647241, step = 13501 (6.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.18\n",
      "INFO:tensorflow:loss = 0.15065715, step = 13601 (5.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3202\n",
      "INFO:tensorflow:loss = 0.21929988, step = 13701 (7.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8208\n",
      "INFO:tensorflow:loss = 0.16278464, step = 13801 (5.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5733\n",
      "INFO:tensorflow:loss = 0.14661676, step = 13901 (6.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2819\n",
      "INFO:tensorflow:loss = 0.111120075, step = 14001 (7.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4173\n",
      "INFO:tensorflow:loss = 0.27729982, step = 14101 (5.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0508\n",
      "INFO:tensorflow:loss = 0.110700436, step = 14201 (6.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.633\n",
      "INFO:tensorflow:loss = 0.07546778, step = 14301 (6.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9401\n",
      "INFO:tensorflow:loss = 0.15034346, step = 14401 (5.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7158\n",
      "INFO:tensorflow:loss = 0.163347, step = 14501 (7.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.573\n",
      "INFO:tensorflow:loss = 0.07234891, step = 14601 (5.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7858\n",
      "INFO:tensorflow:loss = 0.15934902, step = 14701 (6.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8586\n",
      "INFO:tensorflow:loss = 0.071025014, step = 14801 (6.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5831\n",
      "INFO:tensorflow:loss = 0.17890598, step = 14901 (5.685 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 13.0916\n",
      "INFO:tensorflow:loss = 0.13788596, step = 15001 (7.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6395\n",
      "INFO:tensorflow:loss = 0.11842463, step = 15101 (5.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7296\n",
      "INFO:tensorflow:loss = 0.08229959, step = 15201 (6.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9662\n",
      "INFO:tensorflow:loss = 0.10862084, step = 15301 (7.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3867\n",
      "INFO:tensorflow:loss = 0.11852706, step = 15401 (5.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6148\n",
      "INFO:tensorflow:loss = 0.08802329, step = 15501 (7.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 18\n",
      "INFO:tensorflow:loss = 0.13354497, step = 15601 (5.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.407\n",
      "INFO:tensorflow:loss = 0.15665507, step = 15701 (6.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1333\n",
      "INFO:tensorflow:loss = 0.11645973, step = 15801 (7.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3352\n",
      "INFO:tensorflow:loss = 0.10839909, step = 15901 (5.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5418\n",
      "INFO:tensorflow:loss = 0.058093905, step = 16001 (7.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3486\n",
      "INFO:tensorflow:loss = 0.118138194, step = 16101 (5.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3175\n",
      "INFO:tensorflow:loss = 0.07605679, step = 16201 (6.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2579\n",
      "INFO:tensorflow:loss = 0.21055181, step = 16301 (6.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5449\n",
      "INFO:tensorflow:loss = 0.112975925, step = 16401 (6.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0331\n",
      "INFO:tensorflow:loss = 0.17869991, step = 16501 (6.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7059\n",
      "INFO:tensorflow:loss = 0.12738614, step = 16601 (7.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3635\n",
      "INFO:tensorflow:loss = 0.1005056, step = 16701 (5.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1181\n",
      "INFO:tensorflow:loss = 0.1542013, step = 16801 (7.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9977\n",
      "INFO:tensorflow:loss = 0.099914454, step = 16901 (7.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0588\n",
      "INFO:tensorflow:loss = 0.13543913, step = 17001 (6.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9606\n",
      "INFO:tensorflow:loss = 0.13363227, step = 17101 (6.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1283\n",
      "INFO:tensorflow:loss = 0.16855782, step = 17201 (6.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0289\n",
      "INFO:tensorflow:loss = 0.11253208, step = 17301 (6.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0395\n",
      "INFO:tensorflow:loss = 0.1124581, step = 17401 (6.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9822\n",
      "INFO:tensorflow:loss = 0.11673731, step = 17501 (6.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.85\n",
      "INFO:tensorflow:loss = 0.1220212, step = 17601 (6.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7231\n",
      "INFO:tensorflow:loss = 0.11993271, step = 17701 (6.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3923\n",
      "INFO:tensorflow:loss = 0.063810326, step = 17801 (5.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3552\n",
      "INFO:tensorflow:loss = 0.09742581, step = 17901 (6.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8871\n",
      "INFO:tensorflow:loss = 0.13064769, step = 18001 (7.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3999\n",
      "INFO:tensorflow:loss = 0.14670745, step = 18101 (5.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0203\n",
      "INFO:tensorflow:loss = 0.08502853, step = 18201 (6.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6347\n",
      "INFO:tensorflow:loss = 0.05313166, step = 18301 (6.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0525\n",
      "INFO:tensorflow:loss = 0.13320732, step = 18401 (5.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6657\n",
      "INFO:tensorflow:loss = 0.15244195, step = 18501 (6.817 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18544 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4665\n",
      "INFO:tensorflow:loss = 0.13987517, step = 18601 (6.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2724\n",
      "INFO:tensorflow:loss = 0.080874234, step = 18701 (5.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6653\n",
      "INFO:tensorflow:loss = 0.17110375, step = 18801 (7.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3233\n",
      "INFO:tensorflow:loss = 0.11953631, step = 18901 (5.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6295\n",
      "INFO:tensorflow:loss = 0.13802813, step = 19001 (6.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3272\n",
      "INFO:tensorflow:loss = 0.099582896, step = 19101 (8.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9948\n",
      "INFO:tensorflow:loss = 0.1063497, step = 19201 (6.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8019\n",
      "INFO:tensorflow:loss = 0.1120478, step = 19301 (7.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5617\n",
      "INFO:tensorflow:loss = 0.13491571, step = 19401 (7.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8795\n",
      "INFO:tensorflow:loss = 0.12219373, step = 19501 (9.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4414\n",
      "INFO:tensorflow:loss = 0.16812634, step = 19601 (7.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7394\n",
      "INFO:tensorflow:loss = 0.11310622, step = 19701 (9.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6256\n",
      "INFO:tensorflow:loss = 0.073310845, step = 19801 (6.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4698\n",
      "INFO:tensorflow:loss = 0.1196831, step = 19901 (8.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4167\n",
      "INFO:tensorflow:loss = 0.12049557, step = 20001 (6.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3553\n",
      "INFO:tensorflow:loss = 0.1359083, step = 20101 (6.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3964\n",
      "INFO:tensorflow:loss = 0.14867473, step = 20201 (8.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9906\n",
      "INFO:tensorflow:loss = 0.2266074, step = 20301 (5.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0642\n",
      "INFO:tensorflow:loss = 0.12151467, step = 20401 (7.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2719\n",
      "INFO:tensorflow:loss = 0.1138605, step = 20501 (6.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0179\n",
      "INFO:tensorflow:loss = 0.1272277, step = 20601 (5.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0739\n",
      "INFO:tensorflow:loss = 0.034470893, step = 20701 (7.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.825\n",
      "INFO:tensorflow:loss = 0.07556691, step = 20801 (5.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5066\n",
      "INFO:tensorflow:loss = 0.07496771, step = 20901 (6.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9738\n",
      "INFO:tensorflow:loss = 0.115695626, step = 21001 (7.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5878\n",
      "INFO:tensorflow:loss = 0.11019763, step = 21101 (6.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2897\n",
      "INFO:tensorflow:loss = 0.16551009, step = 21201 (6.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3077\n",
      "INFO:tensorflow:loss = 0.100841194, step = 21301 (7.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7398\n",
      "INFO:tensorflow:loss = 0.13478991, step = 21401 (6.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1968\n",
      "INFO:tensorflow:loss = 0.09140912, step = 21501 (5.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9423\n",
      "INFO:tensorflow:loss = 0.10781123, step = 21601 (7.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4444\n",
      "INFO:tensorflow:loss = 0.12358429, step = 21701 (6.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1959\n",
      "INFO:tensorflow:loss = 0.10367428, step = 21801 (7.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6858\n",
      "INFO:tensorflow:loss = 0.17503482, step = 21901 (6.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2524\n",
      "INFO:tensorflow:loss = 0.081263915, step = 22001 (5.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4928\n",
      "INFO:tensorflow:loss = 0.07730122, step = 22101 (6.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8172\n",
      "INFO:tensorflow:loss = 0.2317449, step = 22201 (6.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1503\n",
      "INFO:tensorflow:loss = 0.15464252, step = 22301 (5.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1868\n",
      "INFO:tensorflow:loss = 0.100459725, step = 22401 (8.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9525\n",
      "INFO:tensorflow:loss = 0.16574654, step = 22501 (5.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9071\n",
      "INFO:tensorflow:loss = 0.12558003, step = 22601 (6.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0159\n",
      "INFO:tensorflow:loss = 0.06360598, step = 22701 (7.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8292\n",
      "INFO:tensorflow:loss = 0.1479571, step = 22801 (5.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2851\n",
      "INFO:tensorflow:loss = 0.061421406, step = 22901 (7.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.13934757, step = 23001 (6.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.639\n",
      "INFO:tensorflow:loss = 0.11273081, step = 23101 (6.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7613\n",
      "INFO:tensorflow:loss = 0.109908305, step = 23201 (7.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7223\n",
      "INFO:tensorflow:loss = 0.07927288, step = 23301 (5.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5118\n",
      "INFO:tensorflow:loss = 0.1433799, step = 23401 (7.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.772\n",
      "INFO:tensorflow:loss = 0.10300407, step = 23501 (6.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3146\n",
      "INFO:tensorflow:loss = 0.12920997, step = 23601 (6.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1452\n",
      "INFO:tensorflow:loss = 0.12028912, step = 23701 (7.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.462\n",
      "INFO:tensorflow:loss = 0.12050682, step = 23801 (7.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3543\n",
      "INFO:tensorflow:loss = 0.07724108, step = 23901 (6.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2636\n",
      "INFO:tensorflow:loss = 0.056320153, step = 24001 (7.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0464\n",
      "INFO:tensorflow:loss = 0.12523094, step = 24101 (9.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2385\n",
      "INFO:tensorflow:loss = 0.092925265, step = 24201 (7.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.045\n",
      "INFO:tensorflow:loss = 0.07916479, step = 24301 (5.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7501\n",
      "INFO:tensorflow:loss = 0.10124906, step = 24401 (7.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.015\n",
      "INFO:tensorflow:loss = 0.1550016, step = 24501 (7.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8736\n",
      "INFO:tensorflow:loss = 0.071790926, step = 24601 (6.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8707\n",
      "INFO:tensorflow:loss = 0.11174226, step = 24701 (7.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0319\n",
      "INFO:tensorflow:loss = 0.06817583, step = 24801 (5.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1521\n",
      "INFO:tensorflow:loss = 0.078586474, step = 24901 (7.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9859\n",
      "INFO:tensorflow:loss = 0.10379577, step = 25001 (7.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6052\n",
      "INFO:tensorflow:loss = 0.14220709, step = 25101 (7.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2855\n",
      "INFO:tensorflow:loss = 0.16137251, step = 25201 (9.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.988\n",
      "INFO:tensorflow:loss = 0.14667317, step = 25301 (7.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8949\n",
      "INFO:tensorflow:loss = 0.093552485, step = 25401 (9.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2779\n",
      "INFO:tensorflow:loss = 0.098460525, step = 25501 (7.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1911\n",
      "INFO:tensorflow:loss = 0.14046788, step = 25601 (7.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7685\n",
      "INFO:tensorflow:loss = 0.15925854, step = 25701 (9.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8904\n",
      "INFO:tensorflow:loss = 0.1293937, step = 25801 (7.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7938\n",
      "INFO:tensorflow:loss = 0.105091386, step = 25901 (7.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1031\n",
      "INFO:tensorflow:loss = 0.09855003, step = 26001 (7.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3991\n",
      "INFO:tensorflow:loss = 0.108733505, step = 26101 (6.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3432\n",
      "INFO:tensorflow:loss = 0.041812755, step = 26201 (6.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.933\n",
      "INFO:tensorflow:loss = 0.10327275, step = 26301 (7.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9276\n",
      "INFO:tensorflow:loss = 0.10069506, step = 26401 (5.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2084\n",
      "INFO:tensorflow:loss = 0.07842551, step = 26501 (6.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1409\n",
      "INFO:tensorflow:loss = 0.12307706, step = 26601 (8.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8653\n",
      "INFO:tensorflow:loss = 0.07548627, step = 26701 (6.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5635\n",
      "INFO:tensorflow:loss = 0.08722235, step = 26801 (7.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8815\n",
      "INFO:tensorflow:loss = 0.10873868, step = 26901 (6.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5807\n",
      "INFO:tensorflow:loss = 0.12214491, step = 27001 (5.688 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27101 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 13.9618\n",
      "INFO:tensorflow:loss = 0.07250179, step = 27101 (7.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2883\n",
      "INFO:tensorflow:loss = 0.14472663, step = 27201 (7.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1895\n",
      "INFO:tensorflow:loss = 0.07484546, step = 27301 (6.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0899\n",
      "INFO:tensorflow:loss = 0.07007659, step = 27401 (5.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8832\n",
      "INFO:tensorflow:loss = 0.05093371, step = 27501 (7.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7426\n",
      "INFO:tensorflow:loss = 0.06773719, step = 27601 (6.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9623\n",
      "INFO:tensorflow:loss = 0.13306157, step = 27701 (5.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3577\n",
      "INFO:tensorflow:loss = 0.06628448, step = 27801 (7.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8401\n",
      "INFO:tensorflow:loss = 0.07872246, step = 27901 (6.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8361\n",
      "INFO:tensorflow:loss = 0.2170775, step = 28001 (6.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4376\n",
      "INFO:tensorflow:loss = 0.12888984, step = 28101 (7.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8285\n",
      "INFO:tensorflow:loss = 0.06846125, step = 28201 (5.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9024\n",
      "INFO:tensorflow:loss = 0.097535565, step = 28301 (6.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4483\n",
      "INFO:tensorflow:loss = 0.18032464, step = 28401 (7.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8009\n",
      "INFO:tensorflow:loss = 0.18972471, step = 28501 (5.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9315\n",
      "INFO:tensorflow:loss = 0.10375354, step = 28601 (7.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5541\n",
      "INFO:tensorflow:loss = 0.071996935, step = 28701 (6.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1464\n",
      "INFO:tensorflow:loss = 0.080440685, step = 28801 (5.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7348\n",
      "INFO:tensorflow:loss = 0.10403416, step = 28901 (7.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7834\n",
      "INFO:tensorflow:loss = 0.14852539, step = 29001 (5.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3845\n",
      "INFO:tensorflow:loss = 0.12532704, step = 29101 (6.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6803\n",
      "INFO:tensorflow:loss = 0.08747757, step = 29201 (7.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5883\n",
      "INFO:tensorflow:loss = 0.076211475, step = 29301 (6.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5653\n",
      "INFO:tensorflow:loss = 0.08470417, step = 29401 (6.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.092\n",
      "INFO:tensorflow:loss = 0.08886984, step = 29501 (7.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8857\n",
      "INFO:tensorflow:loss = 0.16354476, step = 29601 (5.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5306\n",
      "INFO:tensorflow:loss = 0.06372128, step = 29701 (7.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5734\n",
      "INFO:tensorflow:loss = 0.15239768, step = 29801 (6.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8204\n",
      "INFO:tensorflow:loss = 0.23320037, step = 29901 (6.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6468\n",
      "INFO:tensorflow:loss = 0.16133852, step = 30001 (7.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4064\n",
      "INFO:tensorflow:loss = 0.12441625, step = 30101 (8.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6941\n",
      "INFO:tensorflow:loss = 0.115880586, step = 30201 (9.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3924\n",
      "INFO:tensorflow:loss = 0.10355094, step = 30301 (6.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3622\n",
      "INFO:tensorflow:loss = 0.20117088, step = 30401 (8.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4229\n",
      "INFO:tensorflow:loss = 0.063817576, step = 30501 (8.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3898\n",
      "INFO:tensorflow:loss = 0.097789824, step = 30601 (6.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8575\n",
      "INFO:tensorflow:loss = 0.063283905, step = 30701 (6.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2729\n",
      "INFO:tensorflow:loss = 0.13556963, step = 30801 (7.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8846\n",
      "INFO:tensorflow:loss = 0.07592389, step = 30901 (5.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.12999436, step = 31001 (8.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0914\n",
      "INFO:tensorflow:loss = 0.22739545, step = 31101 (6.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7606\n",
      "INFO:tensorflow:loss = 0.10614897, step = 31201 (7.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1367\n",
      "INFO:tensorflow:loss = 0.19777289, step = 31301 (7.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9414\n",
      "INFO:tensorflow:loss = 0.092063494, step = 31401 (6.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.544\n",
      "INFO:tensorflow:loss = 0.18354432, step = 31501 (7.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8775\n",
      "INFO:tensorflow:loss = 0.12232187, step = 31601 (6.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5858\n",
      "INFO:tensorflow:loss = 0.10676724, step = 31701 (5.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3987\n",
      "INFO:tensorflow:loss = 0.10281861, step = 31801 (8.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3157\n",
      "INFO:tensorflow:loss = 0.06834589, step = 31901 (6.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9417\n",
      "INFO:tensorflow:loss = 0.17456222, step = 32001 (7.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2205\n",
      "INFO:tensorflow:loss = 0.099682964, step = 32101 (5.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6553\n",
      "INFO:tensorflow:loss = 0.18308416, step = 32201 (7.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7467\n",
      "INFO:tensorflow:loss = 0.1760099, step = 32301 (5.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.653\n",
      "INFO:tensorflow:loss = 0.14088812, step = 32401 (6.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4731\n",
      "INFO:tensorflow:loss = 0.08369042, step = 32501 (7.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4925\n",
      "INFO:tensorflow:loss = 0.054484725, step = 32601 (5.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1244\n",
      "INFO:tensorflow:loss = 0.05920752, step = 32701 (7.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2104\n",
      "INFO:tensorflow:loss = 0.09080626, step = 32801 (5.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1122\n",
      "INFO:tensorflow:loss = 0.10230145, step = 32901 (6.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8005\n",
      "INFO:tensorflow:loss = 0.057358958, step = 33001 (7.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3492\n",
      "INFO:tensorflow:loss = 0.07450547, step = 33101 (5.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8319\n",
      "INFO:tensorflow:loss = 0.07189891, step = 33201 (7.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5695\n",
      "INFO:tensorflow:loss = 0.08954562, step = 33301 (5.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8736\n",
      "INFO:tensorflow:loss = 0.117542304, step = 33401 (6.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.916\n",
      "INFO:tensorflow:loss = 0.07272917, step = 33501 (7.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4334\n",
      "INFO:tensorflow:loss = 0.069554076, step = 33601 (5.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4239\n",
      "INFO:tensorflow:loss = 0.06605912, step = 33701 (7.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4967\n",
      "INFO:tensorflow:loss = 0.10202128, step = 33801 (6.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3855\n",
      "INFO:tensorflow:loss = 0.06936496, step = 33901 (5.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4318\n",
      "INFO:tensorflow:loss = 0.13666126, step = 34001 (8.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8699\n",
      "INFO:tensorflow:loss = 0.084682725, step = 34101 (6.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2435\n",
      "INFO:tensorflow:loss = 0.1934658, step = 34201 (6.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5191\n",
      "INFO:tensorflow:loss = 0.058833957, step = 34301 (6.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.13\n",
      "INFO:tensorflow:loss = 0.08411926, step = 34401 (7.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.264\n",
      "INFO:tensorflow:loss = 0.13831556, step = 34501 (5.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2671\n",
      "INFO:tensorflow:loss = 0.1341114, step = 34601 (7.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7984\n",
      "INFO:tensorflow:loss = 0.15802327, step = 34701 (5.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8444\n",
      "INFO:tensorflow:loss = 0.07152537, step = 34801 (5.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5435\n",
      "INFO:tensorflow:loss = 0.084740855, step = 34901 (7.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2115\n",
      "INFO:tensorflow:loss = 0.11793744, step = 35001 (5.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.94\n",
      "INFO:tensorflow:loss = 0.07662112, step = 35101 (7.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4341\n",
      "INFO:tensorflow:loss = 0.06838852, step = 35201 (6.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2431\n",
      "INFO:tensorflow:loss = 0.108983934, step = 35301 (5.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0926\n",
      "INFO:tensorflow:loss = 0.05878742, step = 35401 (7.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1256\n",
      "INFO:tensorflow:loss = 0.111690015, step = 35501 (5.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0313\n",
      "INFO:tensorflow:loss = 0.19054508, step = 35601 (7.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5086\n",
      "INFO:tensorflow:loss = 0.08638628, step = 35701 (6.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.11\n",
      "INFO:tensorflow:loss = 0.07477781, step = 35801 (5.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9236\n",
      "INFO:tensorflow:loss = 0.10085113, step = 35901 (7.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7526\n",
      "INFO:tensorflow:loss = 0.13633657, step = 36001 (6.349 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36047 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 17.187\n",
      "INFO:tensorflow:loss = 0.1484589, step = 36101 (5.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6202\n",
      "INFO:tensorflow:loss = 0.07275461, step = 36201 (7.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8935\n",
      "INFO:tensorflow:loss = 0.061755836, step = 36301 (5.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2976\n",
      "INFO:tensorflow:loss = 0.08735317, step = 36401 (7.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6957\n",
      "INFO:tensorflow:loss = 0.09015593, step = 36501 (6.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3452\n",
      "INFO:tensorflow:loss = 0.10162246, step = 36601 (5.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6086\n",
      "INFO:tensorflow:loss = 0.084985085, step = 36701 (6.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1261\n",
      "INFO:tensorflow:loss = 0.11221784, step = 36801 (7.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.324\n",
      "INFO:tensorflow:loss = 0.11013193, step = 36901 (5.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2922\n",
      "INFO:tensorflow:loss = 0.21135235, step = 37001 (7.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8063\n",
      "INFO:tensorflow:loss = 0.08492861, step = 37101 (5.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9224\n",
      "INFO:tensorflow:loss = 0.09215624, step = 37201 (5.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6772\n",
      "INFO:tensorflow:loss = 0.2082374, step = 37301 (7.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3448\n",
      "INFO:tensorflow:loss = 0.14049774, step = 37401 (5.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9165\n",
      "INFO:tensorflow:loss = 0.075146765, step = 37501 (8.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1116\n",
      "INFO:tensorflow:loss = 0.1161869, step = 37601 (6.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.123\n",
      "INFO:tensorflow:loss = 0.07865976, step = 37701 (6.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0358\n",
      "INFO:tensorflow:loss = 0.07251331, step = 37801 (7.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7127\n",
      "INFO:tensorflow:loss = 0.15722677, step = 37901 (5.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5554\n",
      "INFO:tensorflow:loss = 0.08811826, step = 38001 (7.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8612\n",
      "INFO:tensorflow:loss = 0.08119786, step = 38101 (5.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8541\n",
      "INFO:tensorflow:loss = 0.094922714, step = 38201 (7.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8634\n",
      "INFO:tensorflow:loss = 0.07755051, step = 38301 (5.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1541\n",
      "INFO:tensorflow:loss = 0.1337285, step = 38401 (6.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3859\n",
      "INFO:tensorflow:loss = 0.12463423, step = 38501 (6.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1265\n",
      "INFO:tensorflow:loss = 0.08914912, step = 38601 (5.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9529\n",
      "INFO:tensorflow:loss = 0.10801472, step = 38701 (6.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8766\n",
      "INFO:tensorflow:loss = 0.115988016, step = 38801 (7.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7245\n",
      "INFO:tensorflow:loss = 0.08762361, step = 38901 (6.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.921\n",
      "INFO:tensorflow:loss = 0.058227874, step = 39001 (7.739 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 17.8444\n",
      "INFO:tensorflow:loss = 0.06782308, step = 39101 (5.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3202\n",
      "INFO:tensorflow:loss = 0.076270014, step = 39201 (6.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.946\n",
      "INFO:tensorflow:loss = 0.15743813, step = 39301 (7.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0423\n",
      "INFO:tensorflow:loss = 0.08565939, step = 39401 (5.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1142\n",
      "INFO:tensorflow:loss = 0.08614284, step = 39501 (7.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8304\n",
      "INFO:tensorflow:loss = 0.15888311, step = 39601 (6.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5094\n",
      "INFO:tensorflow:loss = 0.058164403, step = 39701 (5.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3459\n",
      "INFO:tensorflow:loss = 0.07594635, step = 39801 (6.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4731\n",
      "INFO:tensorflow:loss = 0.17855248, step = 39901 (6.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1782\n",
      "INFO:tensorflow:loss = 0.07562367, step = 40001 (5.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7773\n",
      "INFO:tensorflow:loss = 0.05674559, step = 40101 (7.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5191\n",
      "INFO:tensorflow:loss = 0.13885401, step = 40201 (5.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0473\n",
      "INFO:tensorflow:loss = 0.07113546, step = 40301 (5.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0922\n",
      "INFO:tensorflow:loss = 0.07921865, step = 40401 (7.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8748\n",
      "INFO:tensorflow:loss = 0.10932477, step = 40501 (5.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5657\n",
      "INFO:tensorflow:loss = 0.15234889, step = 40601 (6.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8996\n",
      "INFO:tensorflow:loss = 0.18772404, step = 40701 (7.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3034\n",
      "INFO:tensorflow:loss = 0.06162777, step = 40801 (5.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3013\n",
      "INFO:tensorflow:loss = 0.09991196, step = 40901 (6.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3443\n",
      "INFO:tensorflow:loss = 0.082021676, step = 41001 (6.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1458\n",
      "INFO:tensorflow:loss = 0.11471167, step = 41101 (5.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1783\n",
      "INFO:tensorflow:loss = 0.07350121, step = 41201 (7.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9578\n",
      "INFO:tensorflow:loss = 0.071173854, step = 41301 (5.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4245\n",
      "INFO:tensorflow:loss = 0.04242727, step = 41401 (6.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.485\n",
      "INFO:tensorflow:loss = 0.0775456, step = 41501 (7.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8593\n",
      "INFO:tensorflow:loss = 0.05077983, step = 41601 (5.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9623\n",
      "INFO:tensorflow:loss = 0.08396684, step = 41701 (6.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.479\n",
      "INFO:tensorflow:loss = 0.076816015, step = 41801 (6.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3382\n",
      "INFO:tensorflow:loss = 0.15905963, step = 41901 (5.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9207\n",
      "INFO:tensorflow:loss = 0.10181644, step = 42001 (7.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4903\n",
      "INFO:tensorflow:loss = 0.101740435, step = 42101 (5.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0491\n",
      "INFO:tensorflow:loss = 0.11091286, step = 42201 (6.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8906\n",
      "INFO:tensorflow:loss = 0.08912191, step = 42301 (7.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9007\n",
      "INFO:tensorflow:loss = 0.13580786, step = 42401 (5.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6921\n",
      "INFO:tensorflow:loss = 0.101500034, step = 42501 (6.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2\n",
      "INFO:tensorflow:loss = 0.08794041, step = 42601 (7.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2355\n",
      "INFO:tensorflow:loss = 0.07939147, step = 42701 (5.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9461\n",
      "INFO:tensorflow:loss = 0.1373251, step = 42801 (7.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0236\n",
      "INFO:tensorflow:loss = 0.1344347, step = 42901 (6.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9866\n",
      "INFO:tensorflow:loss = 0.11973302, step = 43001 (5.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0762\n",
      "INFO:tensorflow:loss = 0.053083517, step = 43101 (8.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9667\n",
      "INFO:tensorflow:loss = 0.081180915, step = 43201 (5.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7173\n",
      "INFO:tensorflow:loss = 0.13107407, step = 43301 (6.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7732\n",
      "INFO:tensorflow:loss = 0.13601768, step = 43401 (7.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5398\n",
      "INFO:tensorflow:loss = 0.207004, step = 43501 (6.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6982\n",
      "INFO:tensorflow:loss = 0.13190633, step = 43601 (5.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.411\n",
      "INFO:tensorflow:loss = 0.045507714, step = 43701 (8.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.917\n",
      "INFO:tensorflow:loss = 0.081726514, step = 43801 (5.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2715\n",
      "INFO:tensorflow:loss = 0.17148253, step = 43901 (6.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0027\n",
      "INFO:tensorflow:loss = 0.07887383, step = 44001 (7.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.107\n",
      "INFO:tensorflow:loss = 0.20680358, step = 44101 (5.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.837\n",
      "INFO:tensorflow:loss = 0.051441662, step = 44201 (7.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6848\n",
      "INFO:tensorflow:loss = 0.16751347, step = 44301 (6.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3839\n",
      "INFO:tensorflow:loss = 0.096241795, step = 44401 (5.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0508\n",
      "INFO:tensorflow:loss = 0.047687665, step = 44501 (7.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5064\n",
      "INFO:tensorflow:loss = 0.1435202, step = 44601 (6.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8009\n",
      "INFO:tensorflow:loss = 0.07914165, step = 44701 (5.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3533\n",
      "INFO:tensorflow:loss = 0.06099071, step = 44801 (7.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1578\n",
      "INFO:tensorflow:loss = 0.13695812, step = 44901 (5.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1479\n",
      "INFO:tensorflow:loss = 0.099092536, step = 45001 (6.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5696\n",
      "INFO:tensorflow:loss = 0.12782325, step = 45101 (6.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1344\n",
      "INFO:tensorflow:loss = 0.11696678, step = 45201 (5.513 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45248 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5456\n",
      "INFO:tensorflow:loss = 0.119157024, step = 45301 (6.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6857\n",
      "INFO:tensorflow:loss = 0.06668518, step = 45401 (6.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5145\n",
      "INFO:tensorflow:loss = 0.071094185, step = 45501 (5.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0521\n",
      "INFO:tensorflow:loss = 0.12507363, step = 45601 (7.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9288\n",
      "INFO:tensorflow:loss = 0.095644556, step = 45701 (6.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9887\n",
      "INFO:tensorflow:loss = 0.08658591, step = 45801 (6.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8244\n",
      "INFO:tensorflow:loss = 0.105146214, step = 45901 (7.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2015\n",
      "INFO:tensorflow:loss = 0.12507832, step = 46001 (5.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6337\n",
      "INFO:tensorflow:loss = 0.17273916, step = 46101 (6.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1592\n",
      "INFO:tensorflow:loss = 0.082830295, step = 46201 (6.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2002\n",
      "INFO:tensorflow:loss = 0.121459246, step = 46301 (5.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2995\n",
      "INFO:tensorflow:loss = 0.10279317, step = 46401 (6.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4938\n",
      "INFO:tensorflow:loss = 0.0637345, step = 46501 (6.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6363\n",
      "INFO:tensorflow:loss = 0.14280213, step = 46601 (6.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7335\n",
      "INFO:tensorflow:loss = 0.07605256, step = 46701 (6.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9017\n",
      "INFO:tensorflow:loss = 0.08735159, step = 46801 (7.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5531\n",
      "INFO:tensorflow:loss = 0.07277635, step = 46901 (5.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4022\n",
      "INFO:tensorflow:loss = 0.059330083, step = 47001 (6.941 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 14.5782\n",
      "INFO:tensorflow:loss = 0.078153744, step = 47101 (6.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8786\n",
      "INFO:tensorflow:loss = 0.08470464, step = 47201 (5.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5765\n",
      "INFO:tensorflow:loss = 0.08085772, step = 47301 (7.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8132\n",
      "INFO:tensorflow:loss = 0.106475644, step = 47401 (6.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4563\n",
      "INFO:tensorflow:loss = 0.1081992, step = 47501 (5.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0827\n",
      "INFO:tensorflow:loss = 0.13401146, step = 47601 (7.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7147\n",
      "INFO:tensorflow:loss = 0.08443218, step = 47701 (5.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0417\n",
      "INFO:tensorflow:loss = 0.12223603, step = 47801 (8.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5913\n",
      "INFO:tensorflow:loss = 0.104453936, step = 47901 (5.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8469\n",
      "INFO:tensorflow:loss = 0.11621338, step = 48001 (6.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9619\n",
      "INFO:tensorflow:loss = 0.066176124, step = 48101 (7.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4601\n",
      "INFO:tensorflow:loss = 0.08398168, step = 48201 (5.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5124\n",
      "INFO:tensorflow:loss = 0.09300007, step = 48301 (7.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5959\n",
      "INFO:tensorflow:loss = 0.11960073, step = 48401 (6.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5841\n",
      "INFO:tensorflow:loss = 0.12445563, step = 48501 (6.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.118\n",
      "INFO:tensorflow:loss = 0.07880639, step = 48601 (7.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6774\n",
      "INFO:tensorflow:loss = 0.16683906, step = 48701 (6.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0718\n",
      "INFO:tensorflow:loss = 0.12130089, step = 48801 (6.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6874\n",
      "INFO:tensorflow:loss = 0.07388989, step = 48901 (7.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9405\n",
      "INFO:tensorflow:loss = 0.09993259, step = 49001 (5.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8476\n",
      "INFO:tensorflow:loss = 0.094735, step = 49101 (6.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.827\n",
      "INFO:tensorflow:loss = 0.07279471, step = 49201 (6.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5112\n",
      "INFO:tensorflow:loss = 0.07012743, step = 49301 (5.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8057\n",
      "INFO:tensorflow:loss = 0.06342425, step = 49401 (7.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4019\n",
      "INFO:tensorflow:loss = 0.10030775, step = 49501 (5.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7305\n",
      "INFO:tensorflow:loss = 0.07709615, step = 49601 (6.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0344\n",
      "INFO:tensorflow:loss = 0.11126793, step = 49701 (6.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3649\n",
      "INFO:tensorflow:loss = 0.049477167, step = 49801 (5.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6049\n",
      "INFO:tensorflow:loss = 0.12586944, step = 49901 (7.930 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50000 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.06813752.\n",
      "Tensor(\"one_hot:0\", shape=(?, 15), dtype=int32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 100, 20, 1), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\11514\\AppData\\Local\\Temp\\tmp1nu516dc\\model.ckpt-50000\n",
      "Accuracy:0.900194\n",
      "0.9001941497289154\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "classifier=learn.SKCompat(learn.Estimator(model_fn=cnn_model))\n",
    "\n",
    "# 训练和预测\n",
    "classifier.fit(x_train,y_train,steps=50000) \n",
    "y_predicted=classifier.predict(x_test)['class'] \n",
    "score=metrics.accuracy_score(y_test,y_predicted) \n",
    "print('Accuracy:{0:f}'.format(score))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-engine",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "tutorial-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用RNN完成文本分类\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers.python.layers import encoders\n",
    "\n",
    "learn = tf.contrib.learn\n",
    "\n",
    "FALGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "premier-builder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 93968\n"
     ]
    }
   ],
   "source": [
    "MAX_DOCUMENT_LENGTH=100\n",
    "MIN_WORD_FREQUENCE=1\n",
    "EMBEDDING_SIZE=50\n",
    "global n_words\n",
    "\n",
    "# 处理词汇\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH\n",
    "                                                          ,min_frequency=MIN_WORD_FREQUENCE)\n",
    "x_train = np.array(list(vocab_processor.fit_transform(train_data)))\n",
    "x_test = np.array(list(vocab_processor.transform(test_data))) \n",
    "n_words = len(vocab_processor.vocabulary_)\n",
    "print('Total words: %d' % n_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "scheduled-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\11514\\AppData\\Local\\Temp\\tmpjy18imnf\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000240B06A0320>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\11514\\\\AppData\\\\Local\\\\Temp\\\\tmpjy18imnf'}\n",
      "WARNING:tensorflow:From <ipython-input-50-b895101a923f>:29: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
      "WARNING:tensorflow:From d:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:398: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From d:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:151: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From <ipython-input-50-b895101a923f>:33: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmpjy18imnf\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.711597, step = 1\n",
      "INFO:tensorflow:global_step/sec: 6.69137\n",
      "INFO:tensorflow:loss = 0.5595878, step = 101 (14.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.70662\n",
      "INFO:tensorflow:loss = 0.42636502, step = 201 (14.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25302\n",
      "INFO:tensorflow:loss = 0.4312436, step = 301 (15.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.38869\n",
      "INFO:tensorflow:loss = 0.42857674, step = 401 (15.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97185\n",
      "INFO:tensorflow:loss = 0.4364819, step = 501 (16.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.20671\n",
      "INFO:tensorflow:loss = 0.3911922, step = 601 (19.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.59177\n",
      "INFO:tensorflow:loss = 0.3500206, step = 701 (17.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00128\n",
      "INFO:tensorflow:loss = 0.3326236, step = 801 (16.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40417\n",
      "INFO:tensorflow:loss = 0.41510546, step = 901 (18.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.33665\n",
      "INFO:tensorflow:loss = 0.3418051, step = 1001 (15.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.55983\n",
      "INFO:tensorflow:loss = 0.34828854, step = 1101 (17.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.41571\n",
      "INFO:tensorflow:loss = 0.38303548, step = 1201 (15.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.83638\n",
      "INFO:tensorflow:loss = 0.3366229, step = 1301 (17.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.29197\n",
      "INFO:tensorflow:loss = 0.35001493, step = 1401 (15.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.83869\n",
      "INFO:tensorflow:loss = 0.41575587, step = 1501 (17.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.44522\n",
      "INFO:tensorflow:loss = 0.38332736, step = 1601 (15.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.53758\n",
      "INFO:tensorflow:loss = 0.23777261, step = 1701 (18.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39023\n",
      "INFO:tensorflow:loss = 0.39403614, step = 1801 (18.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.89865\n",
      "INFO:tensorflow:loss = 0.41266555, step = 1901 (16.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.57182\n",
      "INFO:tensorflow:loss = 0.44511107, step = 2001 (17.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.44789\n",
      "INFO:tensorflow:loss = 0.26788533, step = 2101 (15.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.87988\n",
      "INFO:tensorflow:loss = 0.3963697, step = 2201 (17.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.98551\n",
      "INFO:tensorflow:loss = 0.3084158, step = 2301 (16.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.45992\n",
      "INFO:tensorflow:loss = 0.3222934, step = 2401 (15.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.53343\n",
      "INFO:tensorflow:loss = 0.35555476, step = 2501 (18.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.95756\n",
      "INFO:tensorflow:loss = 0.36793578, step = 2601 (16.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.92533\n",
      "INFO:tensorflow:loss = 0.30102092, step = 2701 (20.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20914\n",
      "INFO:tensorflow:loss = 0.3830717, step = 2801 (16.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.43224\n",
      "INFO:tensorflow:loss = 0.29637772, step = 2901 (15.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.32673\n",
      "INFO:tensorflow:loss = 0.22773677, step = 3001 (15.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.85097\n",
      "INFO:tensorflow:loss = 0.27843493, step = 3101 (14.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.94046\n",
      "INFO:tensorflow:loss = 0.2579849, step = 3201 (16.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.54004\n",
      "INFO:tensorflow:loss = 0.2659394, step = 3301 (15.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.65325\n",
      "INFO:tensorflow:loss = 0.39680654, step = 3401 (17.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.82158\n",
      "INFO:tensorflow:loss = 0.19748405, step = 3501 (14.655 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3591 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmpjy18imnf\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.28511\n",
      "INFO:tensorflow:loss = 0.17983738, step = 3601 (18.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.78761\n",
      "INFO:tensorflow:loss = 0.21501943, step = 3701 (14.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.83719\n",
      "INFO:tensorflow:loss = 0.24589793, step = 3801 (17.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.79858\n",
      "INFO:tensorflow:loss = 0.24754396, step = 3901 (14.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.1552\n",
      "INFO:tensorflow:loss = 0.26712728, step = 4001 (16.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.33029\n",
      "INFO:tensorflow:loss = 0.34406847, step = 4101 (15.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.7896\n",
      "INFO:tensorflow:loss = 0.22033772, step = 4201 (14.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.39976\n",
      "INFO:tensorflow:loss = 0.15603417, step = 4301 (15.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.80001\n",
      "INFO:tensorflow:loss = 0.2819299, step = 4401 (17.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.93816\n",
      "INFO:tensorflow:loss = 0.23536694, step = 4501 (14.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13587\n",
      "INFO:tensorflow:loss = 0.25371373, step = 4601 (16.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.47603\n",
      "INFO:tensorflow:loss = 0.2599876, step = 4701 (15.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.17773\n",
      "INFO:tensorflow:loss = 0.24656174, step = 4801 (16.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.91067\n",
      "INFO:tensorflow:loss = 0.1695952, step = 4901 (14.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97887\n",
      "INFO:tensorflow:loss = 0.19172387, step = 5001 (16.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.76405\n",
      "INFO:tensorflow:loss = 0.2080722, step = 5101 (14.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13852\n",
      "INFO:tensorflow:loss = 0.25161332, step = 5201 (16.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.91744\n",
      "INFO:tensorflow:loss = 0.21619749, step = 5301 (14.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.96709\n",
      "INFO:tensorflow:loss = 0.3131749, step = 5401 (16.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.63341\n",
      "INFO:tensorflow:loss = 0.20443955, step = 5501 (15.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09355\n",
      "INFO:tensorflow:loss = 0.19967297, step = 5601 (16.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.35728\n",
      "INFO:tensorflow:loss = 0.15269014, step = 5701 (15.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.53087\n",
      "INFO:tensorflow:loss = 0.25519973, step = 5801 (18.090 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.5948\n",
      "INFO:tensorflow:loss = 0.18228172, step = 5901 (15.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.48899\n",
      "INFO:tensorflow:loss = 0.25545007, step = 6001 (18.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.47464\n",
      "INFO:tensorflow:loss = 0.18225029, step = 6101 (15.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.77006\n",
      "INFO:tensorflow:loss = 0.15238424, step = 6201 (17.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.80629\n",
      "INFO:tensorflow:loss = 0.17592523, step = 6301 (17.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.93745\n",
      "INFO:tensorflow:loss = 0.1776825, step = 6401 (16.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.7768\n",
      "INFO:tensorflow:loss = 0.19227983, step = 6501 (20.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.00126\n",
      "INFO:tensorflow:loss = 0.17498635, step = 6601 (16.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.75572\n",
      "INFO:tensorflow:loss = 0.16656892, step = 6701 (21.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.50573\n",
      "INFO:tensorflow:loss = 0.17243163, step = 6801 (15.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.69804\n",
      "INFO:tensorflow:loss = 0.18132284, step = 6901 (17.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.97611\n",
      "INFO:tensorflow:loss = 0.21064562, step = 7001 (16.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.57853\n",
      "INFO:tensorflow:loss = 0.22969736, step = 7101 (17.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21137\n",
      "INFO:tensorflow:loss = 0.24826474, step = 7201 (16.102 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7247 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmpjy18imnf\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.94086\n",
      "INFO:tensorflow:loss = 0.11694075, step = 7301 (16.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.61686\n",
      "INFO:tensorflow:loss = 0.19383778, step = 7401 (17.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.45728\n",
      "INFO:tensorflow:loss = 0.26109034, step = 7501 (15.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.28269\n",
      "INFO:tensorflow:loss = 0.29114628, step = 7601 (18.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.18668\n",
      "INFO:tensorflow:loss = 0.14637518, step = 7701 (16.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.79955\n",
      "INFO:tensorflow:loss = 0.2711991, step = 7801 (17.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.92072\n",
      "INFO:tensorflow:loss = 0.27493173, step = 7901 (16.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.49541\n",
      "INFO:tensorflow:loss = 0.24354354, step = 8001 (18.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.40701\n",
      "INFO:tensorflow:loss = 0.19247249, step = 8101 (15.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.90981\n",
      "INFO:tensorflow:loss = 0.3059371, step = 8201 (16.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.13702\n",
      "INFO:tensorflow:loss = 0.19582167, step = 8301 (16.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11835\n",
      "INFO:tensorflow:loss = 0.26881123, step = 8401 (16.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.09026\n",
      "INFO:tensorflow:loss = 0.2516878, step = 8501 (16.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.82096\n",
      "INFO:tensorflow:loss = 0.24902405, step = 8601 (17.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.16576\n",
      "INFO:tensorflow:loss = 0.21438086, step = 8701 (19.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.21255\n",
      "INFO:tensorflow:loss = 0.089032724, step = 8801 (16.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.15224\n",
      "INFO:tensorflow:loss = 0.26668912, step = 8901 (19.409 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into C:\\Users\\11514\\AppData\\Local\\Temp\\tmpjy18imnf\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.16491172.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\11514\\AppData\\Local\\Temp\\tmpjy18imnf\\model.ckpt-9000\n",
      "Accuracy:0.864401\n"
     ]
    }
   ],
   "source": [
    "def rnn_model(features,target): \n",
    "    \"\"\"\n",
    "    用RNN模型（这里用的是GRU）完成文本分类\n",
    "    \"\"\"\n",
    "    # Convert indexes of words into embeddings.\n",
    "    # This creates embeddings matrix of [n_words, EMBEDDING_SIZE] and then\n",
    "    # maps word indexes of the sequence into [batch_size,sequence_length,\n",
    "    # EMBEDDING_SIZE].\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(features\n",
    "                                                    ,vocab_size=n_words\n",
    "                                                    ,embed_dim=EMBEDDING_SIZE\n",
    "                                                    ,scope='words')\n",
    "    # Split into list of embedding per word, while removing doc length dim。\n",
    "    # word_list results to be a list of tensors [batch_size,EMBEDDING_SIZE].\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "    \n",
    "    # Create a Gated Recurrent Unit cell with hidden size of EMBEDDING_SIZE.\n",
    "    cell = tf.contrib.rnn.GRUCell(EMBEDDING_SIZE)\n",
    "    \n",
    "    # Create an unrolled Recurrent Neural Networks to length of\n",
    "    # MAX_DOCUMENT_LENGTH and passes word_list as inputs for each unit.\n",
    "    _, encoding = tf.contrib.rnn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "    \n",
    "    # Given encoding of RNN, take encoding of last step (e.g hidden size of the\n",
    "    # neural network of last step) and pass it as features for logistic\n",
    "    # regression over output classes.\n",
    "    target = tf.one_hot(target, 15, 1, 0)\n",
    "    logits = tf.contrib.layers.fully_connected(encoding, 15, activation_fn=None)\n",
    "    loss = tf.contrib.losses.softmax_cross_entropy(logits, target)\n",
    "    # Create a training op.\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss,\n",
    "            tf.contrib.framework.get_global_step(),\n",
    "            optimizer='Adam',\n",
    "            learning_rate=0.01)\n",
    "    return ({\n",
    "            'class': tf.argmax(logits, 1),\n",
    "            'prob': tf.nn.softmax(logits)\n",
    "    }, loss, train_op)\n",
    "\n",
    "model_fn = rnn_model \n",
    "# 初始化注意取消\n",
    "# result_rnn=pd.DataFrame(columns=('step','loss_train','loss_test','score'))\n",
    "# result_rnn.to_csv(\"./DL_model/rnn_loss.csv\",index=False)\n",
    "\n",
    "# result_rnn = pd.read_csv(\"./DL_model/rnn_loss.csv\")\n",
    "classifier=learn.SKCompat(learn.Estimator(model_fn=model_fn))\n",
    "#Train and predict\n",
    "classifier.fit(x_train,y_train,steps=9000) \n",
    "y_predicted=classifier.predict(x_test)['class']\n",
    "score=metrics.accuracy_score(y_test,y_predicted)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "automated-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A0F251320>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.011134097, step = 5001\n",
      "INFO:tensorflow:Saving checkpoints for 5100 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.017118284.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5100\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:01:41\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5100\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:02:22\n",
      "INFO:tensorflow:Saving dict for global step 5100: global_step = 5100, loss = 1.7297435\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:02:33\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5100\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:02:47\n",
      "INFO:tensorflow:Saving dict for global step 5100: global_step = 5100, loss = 1.7693002\n",
      "我存了第0次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A41F12B38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5100\n",
      "INFO:tensorflow:Saving checkpoints for 5101 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.036168486, step = 5101\n",
      "INFO:tensorflow:Saving checkpoints for 5200 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.02111713.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A0F0CC710>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5200\n",
      "INFO:tensorflow:Saving checkpoints for 5201 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.007907595, step = 5201\n",
      "INFO:tensorflow:Saving checkpoints for 5300 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.05832271.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5300\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:04:15\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5300\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:05:00\n",
      "INFO:tensorflow:Saving dict for global step 5300: global_step = 5300, loss = 1.7620724\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:05:10\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5300\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:05:23\n",
      "INFO:tensorflow:Saving dict for global step 5300: global_step = 5300, loss = 1.8099918\n",
      "我存了第2次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A41F12BA8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5300\n",
      "INFO:tensorflow:Saving checkpoints for 5301 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.01173254, step = 5301\n",
      "INFO:tensorflow:Saving checkpoints for 5400 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.019931663.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A41A1B6D8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5400\n",
      "INFO:tensorflow:Saving checkpoints for 5401 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.013084378, step = 5401\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.027122535.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:06:52\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:07:35\n",
      "INFO:tensorflow:Saving dict for global step 5500: global_step = 5500, loss = 1.5792755\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:07:45\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:07:58\n",
      "INFO:tensorflow:Saving dict for global step 5500: global_step = 5500, loss = 1.6223388\n",
      "我存了第4次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A3D528EB8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5500\n",
      "INFO:tensorflow:Saving checkpoints for 5501 into ./DL_model/rnn_model\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0059621804, step = 5501\n",
      "INFO:tensorflow:Saving checkpoints for 5600 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.016434975.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A46A53B38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5600\n",
      "INFO:tensorflow:Saving checkpoints for 5601 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0073946323, step = 5601\n",
      "INFO:tensorflow:Saving checkpoints for 5700 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.016385108.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5700\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:09:25\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5700\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:10:06\n",
      "INFO:tensorflow:Saving dict for global step 5700: global_step = 5700, loss = 1.6984601\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:10:16\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5700\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:10:30\n",
      "INFO:tensorflow:Saving dict for global step 5700: global_step = 5700, loss = 1.7421048\n",
      "我存了第6次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A3BD81208>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5700\n",
      "INFO:tensorflow:Saving checkpoints for 5701 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0051681027, step = 5701\n",
      "INFO:tensorflow:Saving checkpoints for 5800 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015718877.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A42BCC550>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5800\n",
      "INFO:tensorflow:Saving checkpoints for 5801 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0037483706, step = 5801\n",
      "INFO:tensorflow:Saving checkpoints for 5900 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015966058.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5900\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:11:52\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5900\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:12:34\n",
      "INFO:tensorflow:Saving dict for global step 5900: global_step = 5900, loss = 1.8297547\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:12:43\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5900\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:12:57\n",
      "INFO:tensorflow:Saving dict for global step 5900: global_step = 5900, loss = 1.8771957\n",
      "我存了第8次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A471AB400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-5900\n",
      "INFO:tensorflow:Saving checkpoints for 5901 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0041372804, step = 5901\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015917799.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A0F43FE10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0035944774, step = 6001\n",
      "INFO:tensorflow:Saving checkpoints for 6100 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015807923.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6100\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:14:22\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6100\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:15:07\n",
      "INFO:tensorflow:Saving dict for global step 6100: global_step = 6100, loss = 1.9060384\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:15:19\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6100\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:15:33\n",
      "INFO:tensorflow:Saving dict for global step 6100: global_step = 6100, loss = 1.9573623\n",
      "我存了第10次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A4815BF98>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6100\n",
      "INFO:tensorflow:Saving checkpoints for 6101 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0035379804, step = 6101\n",
      "INFO:tensorflow:Saving checkpoints for 6200 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015610561.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A47466438>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6200\n",
      "INFO:tensorflow:Saving checkpoints for 6201 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0035714125, step = 6201\n",
      "INFO:tensorflow:Saving checkpoints for 6300 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.017943554.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6300\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:16:58\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6300\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:17:42\n",
      "INFO:tensorflow:Saving dict for global step 6300: global_step = 6300, loss = 1.9562646\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:17:52\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6300\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:18:04\n",
      "INFO:tensorflow:Saving dict for global step 6300: global_step = 6300, loss = 2.0111754\n",
      "我存了第12次\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A447CFB70>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6300\n",
      "INFO:tensorflow:Saving checkpoints for 6301 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.004339765, step = 6301\n",
      "INFO:tensorflow:Saving checkpoints for 6400 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015873143.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027A4413BA90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './DL_model/rnn_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6400\n",
      "INFO:tensorflow:Saving checkpoints for 6401 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0036867626, step = 6401\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into ./DL_model/rnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.015708975.\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6500\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:19:31\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6500\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-09-15:20:15\n",
      "INFO:tensorflow:Saving dict for global step 6500: global_step = 6500, loss = 2.002041\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-09-15:20:24\n",
      "INFO:tensorflow:Restoring parameters from ./DL_model/rnn_model\\model.ckpt-6500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-30f750509595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         result_rnn = result_rnn.append({\"loss_test\":loss_test[\"loss\"],\n\u001b[0;32m     12\u001b[0m                                                             \u001b[1;34m\"loss_train\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 instructions)\n\u001b[1;32m--> 316\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    318\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, input_fn, feed_fn, batch_size, steps, metrics, name, checkpoint_path, hooks, log_progress)\u001b[0m\n\u001b[0;32m    553\u001b[0m     \u001b[0m_verify_input_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mSKCompat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, x, y, batch_size, steps, metrics, name)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   1455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_results\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m       \u001b[0meval_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'global_step'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[1;34m(self, input_fn, steps, feed_fn, metrics, name, checkpoint_path, hooks, log_progress)\u001b[0m\n\u001b[0;32m    882\u001b[0m           \u001b[0mfinal_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m           config=self._session_config)\n\u001b[0m\u001b[0;32m    885\u001b[0m       \u001b[0mcurrent_global_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mglobal_step_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[1;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    893\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\datamining\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    classifier2=learn.Estimator(model_fn=model_fn,model_dir='./DL_model/rnn_model')\n",
    "    #Train and predict\n",
    "    classifier2_skl = learn.SKCompat(classifier2)\n",
    "    classifier2_skl.fit(x_train,y_train,steps=100)\n",
    "    if i%2==0 :\n",
    "        y_predicted=classifier2_skl.predict(x_test)['class']\n",
    "        score=metrics.accuracy_score(y_test,y_predicted)\n",
    "        loss_train = classifier2.evaluate(x_train,y_train)\n",
    "        loss_test = classifier2.evaluate(x_test,y_test) \n",
    "        result_rnn = result_rnn.append({\"loss_test\":loss_test[\"loss\"],\n",
    "                                                            \"loss_train\":loss_train[\"loss\"],\n",
    "                                                            \"score\":score,\n",
    "                                                            \"step\":loss_train[\"global_step\"]\n",
    "                                                            },ignore_index=True)\n",
    "        result_rnn.to_csv(\"./DL_model/rnn_loss.csv\",index=False)\n",
    "        print(\"我存了第%d次\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "biblical-editing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.689098</td>\n",
       "      <td>0.689096</td>\n",
       "      <td>0.551554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.650221</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>0.678445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.602337</td>\n",
       "      <td>0.616072</td>\n",
       "      <td>0.747839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.857544</td>\n",
       "      <td>0.878631</td>\n",
       "      <td>0.739936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900.0</td>\n",
       "      <td>1.052216</td>\n",
       "      <td>1.078539</td>\n",
       "      <td>0.737479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.091040</td>\n",
       "      <td>1.120810</td>\n",
       "      <td>0.736117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>1.207862</td>\n",
       "      <td>1.241585</td>\n",
       "      <td>0.733121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.322826</td>\n",
       "      <td>1.363286</td>\n",
       "      <td>0.732911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1700.0</td>\n",
       "      <td>1.323175</td>\n",
       "      <td>1.364141</td>\n",
       "      <td>0.733419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900.0</td>\n",
       "      <td>1.303353</td>\n",
       "      <td>1.334746</td>\n",
       "      <td>0.726668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2100.0</td>\n",
       "      <td>1.400095</td>\n",
       "      <td>1.435923</td>\n",
       "      <td>0.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2300.0</td>\n",
       "      <td>1.349991</td>\n",
       "      <td>1.385149</td>\n",
       "      <td>0.722003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>1.572923</td>\n",
       "      <td>1.613785</td>\n",
       "      <td>0.729350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2700.0</td>\n",
       "      <td>1.607881</td>\n",
       "      <td>1.652217</td>\n",
       "      <td>0.726644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2900.0</td>\n",
       "      <td>1.629199</td>\n",
       "      <td>1.674930</td>\n",
       "      <td>0.722728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3100.0</td>\n",
       "      <td>1.380606</td>\n",
       "      <td>1.416057</td>\n",
       "      <td>0.723397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3300.0</td>\n",
       "      <td>1.501900</td>\n",
       "      <td>1.539920</td>\n",
       "      <td>0.732589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>1.615683</td>\n",
       "      <td>1.657292</td>\n",
       "      <td>0.728537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3700.0</td>\n",
       "      <td>1.690008</td>\n",
       "      <td>1.735754</td>\n",
       "      <td>0.727763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3900.0</td>\n",
       "      <td>1.795067</td>\n",
       "      <td>1.846130</td>\n",
       "      <td>0.727739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4100.0</td>\n",
       "      <td>1.848376</td>\n",
       "      <td>1.902008</td>\n",
       "      <td>0.727473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4300.0</td>\n",
       "      <td>1.884592</td>\n",
       "      <td>1.937628</td>\n",
       "      <td>0.728674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>1.917674</td>\n",
       "      <td>1.969267</td>\n",
       "      <td>0.726909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4700.0</td>\n",
       "      <td>1.387980</td>\n",
       "      <td>1.425044</td>\n",
       "      <td>0.726031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4900.0</td>\n",
       "      <td>1.489746</td>\n",
       "      <td>1.531501</td>\n",
       "      <td>0.729858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5100.0</td>\n",
       "      <td>1.729743</td>\n",
       "      <td>1.769300</td>\n",
       "      <td>0.728521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5300.0</td>\n",
       "      <td>1.762072</td>\n",
       "      <td>1.809992</td>\n",
       "      <td>0.722575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5500.0</td>\n",
       "      <td>1.579275</td>\n",
       "      <td>1.622339</td>\n",
       "      <td>0.727562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5700.0</td>\n",
       "      <td>1.698460</td>\n",
       "      <td>1.742105</td>\n",
       "      <td>0.726611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5900.0</td>\n",
       "      <td>1.829755</td>\n",
       "      <td>1.877196</td>\n",
       "      <td>0.727715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6100.0</td>\n",
       "      <td>1.906038</td>\n",
       "      <td>1.957362</td>\n",
       "      <td>0.727361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6300.0</td>\n",
       "      <td>1.956265</td>\n",
       "      <td>2.011175</td>\n",
       "      <td>0.727385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step  loss_train  loss_test     score\n",
       "0    100.0    0.689098   0.689096  0.551554\n",
       "1    300.0    0.650221   0.650369  0.678445\n",
       "2    500.0    0.602337   0.616072  0.747839\n",
       "3    700.0    0.857544   0.878631  0.739936\n",
       "4    900.0    1.052216   1.078539  0.737479\n",
       "5   1100.0    1.091040   1.120810  0.736117\n",
       "6   1300.0    1.207862   1.241585  0.733121\n",
       "7   1500.0    1.322826   1.363286  0.732911\n",
       "8   1700.0    1.323175   1.364141  0.733419\n",
       "9   1900.0    1.303353   1.334746  0.726668\n",
       "10  2100.0    1.400095   1.435923  0.723300\n",
       "11  2300.0    1.349991   1.385149  0.722003\n",
       "12  2500.0    1.572923   1.613785  0.729350\n",
       "13  2700.0    1.607881   1.652217  0.726644\n",
       "14  2900.0    1.629199   1.674930  0.722728\n",
       "15  3100.0    1.380606   1.416057  0.723397\n",
       "16  3300.0    1.501900   1.539920  0.732589\n",
       "17  3500.0    1.615683   1.657292  0.728537\n",
       "18  3700.0    1.690008   1.735754  0.727763\n",
       "19  3900.0    1.795067   1.846130  0.727739\n",
       "20  4100.0    1.848376   1.902008  0.727473\n",
       "21  4300.0    1.884592   1.937628  0.728674\n",
       "22  4500.0    1.917674   1.969267  0.726909\n",
       "23  4700.0    1.387980   1.425044  0.726031\n",
       "24  4900.0    1.489746   1.531501  0.729858\n",
       "25  5100.0    1.729743   1.769300  0.728521\n",
       "26  5300.0    1.762072   1.809992  0.722575\n",
       "27  5500.0    1.579275   1.622339  0.727562\n",
       "28  5700.0    1.698460   1.742105  0.726611\n",
       "29  5900.0    1.829755   1.877196  0.727715\n",
       "30  6100.0    1.906038   1.957362  0.727361\n",
       "31  6300.0    1.956265   2.011175  0.727385"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rnn=pd.read_csv(\"./DL_model/rnn_loss.csv\")\n",
    "result_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vietnamese-algebra",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b92e778e4149>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nlike'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'好精彩的电影！'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'烂片啊！'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-b92e778e4149>\u001b[0m in \u001b[0;36mpred\u001b[1;34m(commment)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcommment\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unknown'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx_tt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_text' is not defined"
     ]
    }
   ],
   "source": [
    "def pred(commment):\n",
    "    sentences=[]\n",
    "    preprocess_text([commment] ,sentences, 'unknown')\n",
    "    x,y=zip(*sentences)\n",
    "    x_tt = np.array(list(vocab_processor.transform([x[0]])))\n",
    "    \n",
    "    if classifier.predict(x_tt)['class'][0]:\n",
    "        print('like')\n",
    "    else:\n",
    "        print('nlike')\n",
    "pred('好精彩的电影！')\n",
    "pred('烂片啊！')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
